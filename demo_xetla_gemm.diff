diff --git a/examples/01_gemm_universal/gemm_universal.cpp b/examples/01_gemm_universal/gemm_universal.cpp
index 94c44764..cd67fed4 100644
--- a/examples/01_gemm_universal/gemm_universal.cpp
+++ b/examples/01_gemm_universal/gemm_universal.cpp
@@ -17,18 +17,18 @@
 #include "xetla.hpp"
 
 enum class kslicing_impl_t : uint8_t { none = 0, global = 1, local = 2 };
-
-inline size_t time_event(sycl::event &e) {
-    // get start and end times
-    cl_ulong start_time = e.template get_profiling_info<
-            sycl::info::event_profiling::command_start>();
-
-    cl_ulong end_time = e.template get_profiling_info<
-            sycl::info::event_profiling::command_end>();
-
-    // return the delta
-    return static_cast<size_t>(end_time - start_time);
-}
+// redefinition of 'time_event'
+// inline size_t time_event(sycl::event &e) {
+//     // get start and end times
+//     cl_ulong start_time = e.template get_profiling_info<
+//             sycl::info::event_profiling::command_start>();
+
+//     cl_ulong end_time = e.template get_profiling_info<
+//             sycl::info::event_profiling::command_end>();
+
+//     // return the delta
+//     return static_cast<size_t>(end_time - start_time);
+// }
 
 template <int m, int n, int k,
         kslicing_impl_t kslicing_type = kslicing_impl_t::none>
diff --git a/tests/integration/gemm/bf16/common.hpp b/tests/integration/gemm/bf16/common.hpp
index 602f2e9a..60e13191 100644
--- a/tests/integration/gemm/bf16/common.hpp
+++ b/tests/integration/gemm/bf16/common.hpp
@@ -266,11 +266,11 @@ public:
     static constexpr size_t mat_m = 1024;
     static constexpr size_t mat_k = 28672;
     static constexpr size_t mat_n = 8192;
-    static constexpr size_t wg_m = 64;
-    static constexpr size_t wg_n = 512;
+    static constexpr size_t wg_m = 256;
+    static constexpr size_t wg_n = 256;
     static constexpr size_t sg_m = 32;
-    static constexpr size_t sg_n = 32;
-    static constexpr size_t sg_k = 16;
+    static constexpr size_t sg_n = 64;
+    static constexpr size_t sg_k = 32;
     static constexpr uint32_t local_kslicing = 1;
     static constexpr uint32_t global_kslicing = 1;
     static constexpr mem_layout layout_a = mem_layout::row_major;
diff --git a/tests/integration/gemm/bf16/habana_tests.hpp b/tests/integration/gemm/bf16/habana_tests.hpp
index b408b5c8..12157bbf 100644
--- a/tests/integration/gemm/bf16/habana_tests.hpp
+++ b/tests/integration/gemm/bf16/habana_tests.hpp
@@ -45,7 +45,7 @@ public:
 class Habana_Test1 : public TestBase {
 public:
     static constexpr size_t mat_m = 512;
-    static constexpr size_t mat_k = 8912;
+    static constexpr size_t mat_k = 8192;
     static constexpr size_t mat_n = 32768;
     static constexpr size_t wg_m = 256;
     static constexpr size_t wg_n = 256;
@@ -66,7 +66,7 @@ class Habana_Test2 : public TestBase {
 public:
     static constexpr size_t mat_m = 512;
     static constexpr size_t mat_k = 32768;
-    static constexpr size_t mat_n = 8912;
+    static constexpr size_t mat_n = 8192;
     static constexpr size_t wg_m = 256;
     static constexpr size_t wg_n = 256;
     static constexpr size_t sg_m = 32;
diff --git a/tests/integration/gemm/bf16_stream_k/main.cpp b/tests/integration/gemm/bf16_stream_k/main.cpp
index b9f19201..c164756c 100644
--- a/tests/integration/gemm/bf16_stream_k/main.cpp
+++ b/tests/integration/gemm/bf16_stream_k/main.cpp
@@ -21,6 +21,8 @@ using namespace gpu::xetla;
 //The number of times the kernel is executed
 constexpr int ITER = 1;
 
+#define CACHE_FLUSH 1
+
 template <typename data_type_a, typename data_type_b, typename data_type_c,
         typename data_type_d, typename data_type_acc = float>
 int gemm_result_validate(data_type_a *A_device, data_type_b *B_device,
@@ -351,6 +353,19 @@ void stream_k_gemm_run(uint32_t iter) {
     long ops = 2 * static_cast<long>(matrix_m) * matrix_n * matrix_k;
     profiling_helper prof("stream_k_universal_gemm", ops, "gflops");
 
+#ifdef CACHE_FLUSH
+        auto size = 256*1024*1024;
+        auto host_ptr = static_cast<int8_t *>(
+                malloc(size * sizeof(int8_t)));
+
+        for (size_t i = 0; i < size; ++i) {
+            host_ptr[i] = 0;
+        }
+        auto device_ptr = static_cast<int8_t *>(
+                aligned_alloc_device(DEVICE_MEM_ALIGNMENT,
+                        size * sizeof(int8_t), device, context));
+#endif
+
     if constexpr (postop_enable) {
 
         // [ReLuBias] define the shape of matrix bias, which should be identitcal to C
@@ -378,6 +393,9 @@ void stream_k_gemm_run(uint32_t iter) {
         }
 
         for (uint32_t i = 0; i < iter + warmup; i++) {
+#ifdef CACHE_FLUSH
+            queue.memset((void *)(device_ptr), 0, size * sizeof(int8_t)).wait();
+#endif
             if (i >= warmup) { prof.cpu_start(); }
             auto gpu_event = queue.submit([&](handler &cgh) {
                 // GPU kernel
@@ -414,6 +432,9 @@ void stream_k_gemm_run(uint32_t iter) {
         cl::sycl::nd_range<3> NDRange = gemm_op_t::get_nd_range(gemm_arg);
 
         for (uint32_t i = 0; i < iter + warmup; i++) {
+#ifdef CACHE_FLUSH
+            queue.memset((void *)(device_ptr), 0, size * sizeof(int8_t)).wait();
+#endif
             if (i >= warmup) { prof.cpu_start(); }
             auto gpu_event = queue.submit([&](handler &cgh) {
                 // GPU kernel
@@ -432,6 +453,9 @@ void stream_k_gemm_run(uint32_t iter) {
             }
         }
     }
+#ifdef CACHE_FLUSH
+        free(host_ptr);
+#endif
 
     unsetenv("SYCL_PROGRAM_COMPILE_OPTIONS");
 
diff --git a/tests/utils/execution.hpp b/tests/utils/execution.hpp
index 260b503a..dc306e8c 100644
--- a/tests/utils/execution.hpp
+++ b/tests/utils/execution.hpp
@@ -75,11 +75,7 @@ void gemm_exec(const std::string &compile_str, size_t batch = 1) {
     using data_type_acc = typename Test::data_type_acc;
 
     int iter = 10, warmup = 10;
-#ifdef CACHE_FLUSH
-    batch = iter + warmup;
-#else
     batch = 1;
-#endif
     constexpr size_t matrix_m = Test::mat_m;
     constexpr size_t matrix_n = Test::mat_n;
     constexpr size_t matrix_k = Test::mat_k;
@@ -161,28 +157,33 @@ void gemm_exec(const std::string &compile_str, size_t batch = 1) {
         // }
         cl::sycl::nd_range<3> nd_range = gemm_op_t::get_nd_range(arg);
 
+#ifdef CACHE_FLUSH
+        auto size = 256*1024*1024;
+        auto host_ptr = static_cast<int8_t *>(
+                malloc(size * sizeof(int8_t)));
+
+        for (size_t i = 0; i < size; ++i) {
+            host_ptr[i] = 0;
+        }
+        auto device_ptr = static_cast<int8_t *>(
+                aligned_alloc_device(DEVICE_MEM_ALIGNMENT,
+                        size * sizeof(int8_t), device, context));
+#endif
+
         std::vector<float> event_times(iter + warmup);
         for (uint32_t j = 0; j < iter + warmup; j++) {
-
+#ifdef CACHE_FLUSH
+            queue.memset((void *)(device_ptr), 0, size * sizeof(int8_t)).wait();
+#endif
             auto e_esimd = queue.submit([&](handler &cgh) {
                 cgh.use_kernel_bundle(exeBundle);
                 cgh.parallel_for<Test>(
                         nd_range, [=](nd_item<3> item) KERNEL_MAIN {
-                // int batch_idx = item.get_workgroup(0);
-#ifdef CACHE_FLUSH
-                            int batch_idx = j;
-                            auto A_ptr = A + batch_idx * size_a;
-                            auto B_ptr = B + batch_idx * size_b;
-                            auto C_ptr = C + batch_idx * size_c;
-                            auto Acc_ptr = Acc + batch_idx * size_acc;
-                            auto Cnt_ptr = Cnt + batch_idx * size_cnt;
-#else
                             auto A_ptr = A;
                             auto B_ptr = B;
                             auto C_ptr = C;
                             auto Acc_ptr = Acc;
                             auto Cnt_ptr = Cnt;
-#endif
                             gpu::xetla::xetla_local_init<SLMSIZE>();
                             gpu::xetla::xetla_nbarrier_init<BARNUM>();
                             KERNEL::run(item, A_ptr, B_ptr, C_ptr, matrix_m,
@@ -193,6 +194,9 @@ void gemm_exec(const std::string &compile_str, size_t batch = 1) {
             e_esimd.wait();
             event_times[j] = time_event(e_esimd) / 1e9;
         }
+#ifdef CACHE_FLUSH
+        free(host_ptr);
+#endif
         auto best = 999.f;
         auto worst = 0.f;
         double average = 0.f;
diff --git a/tools/scripts/env.sh b/tools/scripts/env.sh
index 36c5cf1e..68c92ef5 100755
--- a/tools/scripts/env.sh
+++ b/tools/scripts/env.sh
@@ -6,7 +6,7 @@ source ${script_dir}/clang_format.sh
 # ONEAPI_INSTALL_PATH below assumes you installed to the default folder /opt/intel/oneapi
 # If you customized the installation folder, please update ONEAPI_INSTALL_PATH to your custom folder
 ONEAPI_INSTALL_PATH=/opt/intel/oneapi
-source ${ONEAPI_INSTALL_PATH}/setvars.sh
+source ${ONEAPI_INSTALL_PATH}/setvars.sh --force
 
 # Export environment variables
 export CC=icx
