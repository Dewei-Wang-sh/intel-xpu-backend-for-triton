// -----// IR Dump Before Inliner (inline) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = tt.call @cdiv____0cconstexpr_4096__1cconstexpr_256_() : () -> i32 loc(#loc)
    %2 = tt.call @cdiv____0cconstexpr_4096__1cconstexpr_256_() : () -> i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %3 = arith.muli %2, %c4_i32 : i32 loc(#loc)
    %4 = arith.divsi %0, %3 : i32 loc(#loc)
    %c4_i32_0 = arith.constant 4 : i32 loc(#loc)
    %5 = arith.muli %4, %c4_i32_0 : i32 loc(#loc)
    %6 = arith.subi %1, %5 : i32 loc(#loc)
    %7 = tt.call @minimum__i32__1cconstexpr_4__2cconstexpr_PROPAGATE_NAN_d_NONE_(%6) : (i32) -> i32 loc(#loc)
    %8 = arith.remsi %0, %7 : i32 loc(#loc)
    %9 = arith.addi %5, %8 : i32 loc(#loc)
    %10 = arith.remsi %0, %3 : i32 loc(#loc)
    %11 = arith.divsi %10, %7 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %12 = arith.muli %9, %c256_i32 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_1 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_2 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %13 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64_1], [%c4096_i64_2, %c1_i64], [%12, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %c256_i32_3 = arith.constant 256 : i32 loc(#loc)
    %14 = arith.muli %11, %c256_i32_3 : i32 loc(#loc)
    %c4096_i64_4 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_5 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_6 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64_7 = arith.constant 1 : i64 loc(#loc)
    %c0_i32_8 = arith.constant 0 : i32 loc(#loc)
    %15 = tt.make_tensor_ptr %arg1, [%c4096_i64_4, %c4096_i64_5], [%c4096_i64_6, %c1_i64_7], [%c0_i32_8, %14] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %16 = tt.call @"zeros____0cconstexpr_(constexpr_256_, constexpr_256_)__1cconstexpr_fp32_"() : () -> tensor<256x256xf32> loc(#loc)
    %c0_i32_9 = arith.constant 0 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %17 = arith.bitcast %c0_i32_9 : i32 to i32 loc(#loc)
    %18 = arith.bitcast %c4096_i32 : i32 to i32 loc(#loc)
    %19 = arith.bitcast %c32_i32 : i32 to i32 loc(#loc)
    %20 = llvm.mlir.undef : i32 loc(#loc)
    %21:3 = scf.for %arg6 = %17 to %18 step %19 iter_args(%arg7 = %16, %arg8 = %13, %arg9 = %15) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %25 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %26 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %cst = arith.constant 0.000000e+00 : f32 loc(#loc)
      %cst_16 = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
      %27 = tt.dot %25, %26, %cst_16 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %28 = arith.addf %arg7, %27 : tensor<256x256xf32> loc(#loc)
      %c0_i32_17 = arith.constant 0 : i32 loc(#loc)
      %c32_i32_18 = arith.constant 32 : i32 loc(#loc)
      %29 = tt.advance %arg8, [%c0_i32_17, %c32_i32_18] : <tensor<256x32xf16>, 1> loc(#loc)
      %c32_i32_19 = arith.constant 32 : i32 loc(#loc)
      %c0_i32_20 = arith.constant 0 : i32 loc(#loc)
      %30 = tt.advance %arg9, [%c32_i32_19, %c0_i32_20] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %28, %29, %30 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %c256_i32_10 = arith.constant 256 : i32 loc(#loc)
    %22 = arith.muli %9, %c256_i32_10 : i32 loc(#loc)
    %c256_i32_11 = arith.constant 256 : i32 loc(#loc)
    %23 = arith.muli %11, %c256_i32_11 : i32 loc(#loc)
    %c4096_i64_12 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_13 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_14 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64_15 = arith.constant 1 : i64 loc(#loc)
    %24 = tt.make_tensor_ptr %arg2, [%c4096_i64_12, %c4096_i64_13], [%c4096_i64_14, %c1_i64_15], [%22, %23] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %24, %21#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
  tt.func private @cdiv____0cconstexpr_4096__1cconstexpr_256_() -> i32 attributes {noinline = false} {
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    tt.return %c16_i32 : i32 loc(#loc)
  } loc(#loc)
  tt.func private @minimum__i32__1cconstexpr_4__2cconstexpr_PROPAGATE_NAN_d_NONE_(%arg0: i32 loc(unknown)) -> i32 attributes {noinline = false} {
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = arith.minsi %arg0, %c4_i32 : i32 loc(#loc)
    tt.return %0 : i32 loc(#loc)
  } loc(#loc)
  tt.func private @"zeros____0cconstexpr_(constexpr_256_, constexpr_256_)__1cconstexpr_fp32_"() -> tensor<256x256xf32> attributes {noinline = false} {
    %cst = arith.constant 0.000000e+00 : f32 loc(#loc)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    tt.return %cst_0 : tensor<256x256xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before Canonicalizer (canonicalize) ('tt.func' operation: @cdiv____0cconstexpr_4096__1cconstexpr_256_) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = tt.call @cdiv____0cconstexpr_4096__1cconstexpr_256_() : () -> i32 loc(#loc)
    %2 = tt.call @cdiv____0cconstexpr_4096__1cconstexpr_256_() : () -> i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %3 = arith.muli %2, %c4_i32 : i32 loc(#loc)
    %4 = arith.divsi %0, %3 : i32 loc(#loc)
    %c4_i32_0 = arith.constant 4 : i32 loc(#loc)
    %5 = arith.muli %4, %c4_i32_0 : i32 loc(#loc)
    %6 = arith.subi %1, %5 : i32 loc(#loc)
    %7 = tt.call @minimum__i32__1cconstexpr_4__2cconstexpr_PROPAGATE_NAN_d_NONE_(%6) : (i32) -> i32 loc(#loc)
    %8 = arith.remsi %0, %7 : i32 loc(#loc)
    %9 = arith.addi %5, %8 : i32 loc(#loc)
    %10 = arith.remsi %0, %3 : i32 loc(#loc)
    %11 = arith.divsi %10, %7 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %12 = arith.muli %9, %c256_i32 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_1 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_2 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %13 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64_1], [%c4096_i64_2, %c1_i64], [%12, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %c256_i32_3 = arith.constant 256 : i32 loc(#loc)
    %14 = arith.muli %11, %c256_i32_3 : i32 loc(#loc)
    %c4096_i64_4 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_5 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_6 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64_7 = arith.constant 1 : i64 loc(#loc)
    %c0_i32_8 = arith.constant 0 : i32 loc(#loc)
    %15 = tt.make_tensor_ptr %arg1, [%c4096_i64_4, %c4096_i64_5], [%c4096_i64_6, %c1_i64_7], [%c0_i32_8, %14] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %16 = tt.call @"zeros____0cconstexpr_(constexpr_256_, constexpr_256_)__1cconstexpr_fp32_"() : () -> tensor<256x256xf32> loc(#loc)
    %c0_i32_9 = arith.constant 0 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %17 = arith.bitcast %c0_i32_9 : i32 to i32 loc(#loc)
    %18 = arith.bitcast %c4096_i32 : i32 to i32 loc(#loc)
    %19 = arith.bitcast %c32_i32 : i32 to i32 loc(#loc)
    %20 = llvm.mlir.undef : i32 loc(#loc)
    %21:3 = scf.for %arg6 = %17 to %18 step %19 iter_args(%arg7 = %16, %arg8 = %13, %arg9 = %15) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %25 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %26 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %cst = arith.constant 0.000000e+00 : f32 loc(#loc)
      %cst_16 = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
      %27 = tt.dot %25, %26, %cst_16 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %28 = arith.addf %arg7, %27 : tensor<256x256xf32> loc(#loc)
      %c0_i32_17 = arith.constant 0 : i32 loc(#loc)
      %c32_i32_18 = arith.constant 32 : i32 loc(#loc)
      %29 = tt.advance %arg8, [%c0_i32_17, %c32_i32_18] : <tensor<256x32xf16>, 1> loc(#loc)
      %c32_i32_19 = arith.constant 32 : i32 loc(#loc)
      %c0_i32_20 = arith.constant 0 : i32 loc(#loc)
      %30 = tt.advance %arg9, [%c32_i32_19, %c0_i32_20] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %28, %29, %30 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %c256_i32_10 = arith.constant 256 : i32 loc(#loc)
    %22 = arith.muli %9, %c256_i32_10 : i32 loc(#loc)
    %c256_i32_11 = arith.constant 256 : i32 loc(#loc)
    %23 = arith.muli %11, %c256_i32_11 : i32 loc(#loc)
    %c4096_i64_12 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_13 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_14 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64_15 = arith.constant 1 : i64 loc(#loc)
    %24 = tt.make_tensor_ptr %arg2, [%c4096_i64_12, %c4096_i64_13], [%c4096_i64_14, %c1_i64_15], [%22, %23] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %24, %21#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
  tt.func private @cdiv____0cconstexpr_4096__1cconstexpr_256_() -> i32 attributes {noinline = false} {
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    tt.return %c16_i32 : i32 loc(#loc)
  } loc(#loc)
  tt.func private @minimum__i32__1cconstexpr_4__2cconstexpr_PROPAGATE_NAN_d_NONE_(%arg0: i32 loc(unknown)) -> i32 attributes {noinline = false} {
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = arith.minsi %arg0, %c4_i32 : i32 loc(#loc)
    tt.return %0 : i32 loc(#loc)
  } loc(#loc)
  tt.func private @"zeros____0cconstexpr_(constexpr_256_, constexpr_256_)__1cconstexpr_fp32_"() -> tensor<256x256xf32> attributes {noinline = false} {
    %cst = arith.constant 0.000000e+00 : f32 loc(#loc)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    tt.return %cst_0 : tensor<256x256xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before Canonicalizer (canonicalize) ('tt.func' operation: @minimum__i32__1cconstexpr_4__2cconstexpr_PROPAGATE_NAN_d_NONE_) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = tt.call @cdiv____0cconstexpr_4096__1cconstexpr_256_() : () -> i32 loc(#loc)
    %2 = tt.call @cdiv____0cconstexpr_4096__1cconstexpr_256_() : () -> i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %3 = arith.muli %2, %c4_i32 : i32 loc(#loc)
    %4 = arith.divsi %0, %3 : i32 loc(#loc)
    %c4_i32_0 = arith.constant 4 : i32 loc(#loc)
    %5 = arith.muli %4, %c4_i32_0 : i32 loc(#loc)
    %6 = arith.subi %1, %5 : i32 loc(#loc)
    %7 = tt.call @minimum__i32__1cconstexpr_4__2cconstexpr_PROPAGATE_NAN_d_NONE_(%6) : (i32) -> i32 loc(#loc)
    %8 = arith.remsi %0, %7 : i32 loc(#loc)
    %9 = arith.addi %5, %8 : i32 loc(#loc)
    %10 = arith.remsi %0, %3 : i32 loc(#loc)
    %11 = arith.divsi %10, %7 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %12 = arith.muli %9, %c256_i32 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_1 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_2 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %13 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64_1], [%c4096_i64_2, %c1_i64], [%12, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %c256_i32_3 = arith.constant 256 : i32 loc(#loc)
    %14 = arith.muli %11, %c256_i32_3 : i32 loc(#loc)
    %c4096_i64_4 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_5 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_6 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64_7 = arith.constant 1 : i64 loc(#loc)
    %c0_i32_8 = arith.constant 0 : i32 loc(#loc)
    %15 = tt.make_tensor_ptr %arg1, [%c4096_i64_4, %c4096_i64_5], [%c4096_i64_6, %c1_i64_7], [%c0_i32_8, %14] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %16 = tt.call @"zeros____0cconstexpr_(constexpr_256_, constexpr_256_)__1cconstexpr_fp32_"() : () -> tensor<256x256xf32> loc(#loc)
    %c0_i32_9 = arith.constant 0 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %17 = arith.bitcast %c0_i32_9 : i32 to i32 loc(#loc)
    %18 = arith.bitcast %c4096_i32 : i32 to i32 loc(#loc)
    %19 = arith.bitcast %c32_i32 : i32 to i32 loc(#loc)
    %20 = llvm.mlir.undef : i32 loc(#loc)
    %21:3 = scf.for %arg6 = %17 to %18 step %19 iter_args(%arg7 = %16, %arg8 = %13, %arg9 = %15) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %25 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %26 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %cst = arith.constant 0.000000e+00 : f32 loc(#loc)
      %cst_16 = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
      %27 = tt.dot %25, %26, %cst_16 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %28 = arith.addf %arg7, %27 : tensor<256x256xf32> loc(#loc)
      %c0_i32_17 = arith.constant 0 : i32 loc(#loc)
      %c32_i32_18 = arith.constant 32 : i32 loc(#loc)
      %29 = tt.advance %arg8, [%c0_i32_17, %c32_i32_18] : <tensor<256x32xf16>, 1> loc(#loc)
      %c32_i32_19 = arith.constant 32 : i32 loc(#loc)
      %c0_i32_20 = arith.constant 0 : i32 loc(#loc)
      %30 = tt.advance %arg9, [%c32_i32_19, %c0_i32_20] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %28, %29, %30 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %c256_i32_10 = arith.constant 256 : i32 loc(#loc)
    %22 = arith.muli %9, %c256_i32_10 : i32 loc(#loc)
    %c256_i32_11 = arith.constant 256 : i32 loc(#loc)
    %23 = arith.muli %11, %c256_i32_11 : i32 loc(#loc)
    %c4096_i64_12 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_13 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_14 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64_15 = arith.constant 1 : i64 loc(#loc)
    %24 = tt.make_tensor_ptr %arg2, [%c4096_i64_12, %c4096_i64_13], [%c4096_i64_14, %c1_i64_15], [%22, %23] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %24, %21#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
  tt.func private @cdiv____0cconstexpr_4096__1cconstexpr_256_() -> i32 attributes {noinline = false} {
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    tt.return %c16_i32 : i32 loc(#loc)
  } loc(#loc)
  tt.func private @minimum__i32__1cconstexpr_4__2cconstexpr_PROPAGATE_NAN_d_NONE_(%arg0: i32 loc(unknown)) -> i32 attributes {noinline = false} {
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = arith.minsi %arg0, %c4_i32 : i32 loc(#loc)
    tt.return %0 : i32 loc(#loc)
  } loc(#loc)
  tt.func private @"zeros____0cconstexpr_(constexpr_256_, constexpr_256_)__1cconstexpr_fp32_"() -> tensor<256x256xf32> attributes {noinline = false} {
    %cst = arith.constant 0.000000e+00 : f32 loc(#loc)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    tt.return %cst_0 : tensor<256x256xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before Canonicalizer (canonicalize) ('tt.func' operation: @zeros____0cconstexpr_(constexpr_256_, constexpr_256_)__1cconstexpr_fp32_) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = tt.call @cdiv____0cconstexpr_4096__1cconstexpr_256_() : () -> i32 loc(#loc)
    %2 = tt.call @cdiv____0cconstexpr_4096__1cconstexpr_256_() : () -> i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %3 = arith.muli %2, %c4_i32 : i32 loc(#loc)
    %4 = arith.divsi %0, %3 : i32 loc(#loc)
    %c4_i32_0 = arith.constant 4 : i32 loc(#loc)
    %5 = arith.muli %4, %c4_i32_0 : i32 loc(#loc)
    %6 = arith.subi %1, %5 : i32 loc(#loc)
    %7 = tt.call @minimum__i32__1cconstexpr_4__2cconstexpr_PROPAGATE_NAN_d_NONE_(%6) : (i32) -> i32 loc(#loc)
    %8 = arith.remsi %0, %7 : i32 loc(#loc)
    %9 = arith.addi %5, %8 : i32 loc(#loc)
    %10 = arith.remsi %0, %3 : i32 loc(#loc)
    %11 = arith.divsi %10, %7 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %12 = arith.muli %9, %c256_i32 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_1 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_2 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %13 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64_1], [%c4096_i64_2, %c1_i64], [%12, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %c256_i32_3 = arith.constant 256 : i32 loc(#loc)
    %14 = arith.muli %11, %c256_i32_3 : i32 loc(#loc)
    %c4096_i64_4 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_5 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_6 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64_7 = arith.constant 1 : i64 loc(#loc)
    %c0_i32_8 = arith.constant 0 : i32 loc(#loc)
    %15 = tt.make_tensor_ptr %arg1, [%c4096_i64_4, %c4096_i64_5], [%c4096_i64_6, %c1_i64_7], [%c0_i32_8, %14] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %16 = tt.call @"zeros____0cconstexpr_(constexpr_256_, constexpr_256_)__1cconstexpr_fp32_"() : () -> tensor<256x256xf32> loc(#loc)
    %c0_i32_9 = arith.constant 0 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %17 = arith.bitcast %c0_i32_9 : i32 to i32 loc(#loc)
    %18 = arith.bitcast %c4096_i32 : i32 to i32 loc(#loc)
    %19 = arith.bitcast %c32_i32 : i32 to i32 loc(#loc)
    %20 = llvm.mlir.undef : i32 loc(#loc)
    %21:3 = scf.for %arg6 = %17 to %18 step %19 iter_args(%arg7 = %16, %arg8 = %13, %arg9 = %15) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %25 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %26 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %cst = arith.constant 0.000000e+00 : f32 loc(#loc)
      %cst_16 = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
      %27 = tt.dot %25, %26, %cst_16 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %28 = arith.addf %arg7, %27 : tensor<256x256xf32> loc(#loc)
      %c0_i32_17 = arith.constant 0 : i32 loc(#loc)
      %c32_i32_18 = arith.constant 32 : i32 loc(#loc)
      %29 = tt.advance %arg8, [%c0_i32_17, %c32_i32_18] : <tensor<256x32xf16>, 1> loc(#loc)
      %c32_i32_19 = arith.constant 32 : i32 loc(#loc)
      %c0_i32_20 = arith.constant 0 : i32 loc(#loc)
      %30 = tt.advance %arg9, [%c32_i32_19, %c0_i32_20] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %28, %29, %30 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %c256_i32_10 = arith.constant 256 : i32 loc(#loc)
    %22 = arith.muli %9, %c256_i32_10 : i32 loc(#loc)
    %c256_i32_11 = arith.constant 256 : i32 loc(#loc)
    %23 = arith.muli %11, %c256_i32_11 : i32 loc(#loc)
    %c4096_i64_12 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_13 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_14 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64_15 = arith.constant 1 : i64 loc(#loc)
    %24 = tt.make_tensor_ptr %arg2, [%c4096_i64_12, %c4096_i64_13], [%c4096_i64_14, %c1_i64_15], [%22, %23] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %24, %21#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
  tt.func private @cdiv____0cconstexpr_4096__1cconstexpr_256_() -> i32 attributes {noinline = false} {
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    tt.return %c16_i32 : i32 loc(#loc)
  } loc(#loc)
  tt.func private @minimum__i32__1cconstexpr_4__2cconstexpr_PROPAGATE_NAN_d_NONE_(%arg0: i32 loc(unknown)) -> i32 attributes {noinline = false} {
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = arith.minsi %arg0, %c4_i32 : i32 loc(#loc)
    tt.return %0 : i32 loc(#loc)
  } loc(#loc)
  tt.func private @"zeros____0cconstexpr_(constexpr_256_, constexpr_256_)__1cconstexpr_fp32_"() -> tensor<256x256xf32> attributes {noinline = false} {
    %cst = arith.constant 0.000000e+00 : f32 loc(#loc)
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    tt.return %cst_0 : tensor<256x256xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before Canonicalizer (canonicalize) ('tt.func' operation: @matmul_kernel_with_block_pointers_0d1d2d3d4d5d) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = tt.call @cdiv____0cconstexpr_4096__1cconstexpr_256_() : () -> i32 loc(#loc)
    %2 = tt.call @cdiv____0cconstexpr_4096__1cconstexpr_256_() : () -> i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %3 = arith.muli %2, %c4_i32 : i32 loc(#loc)
    %4 = arith.divsi %0, %3 : i32 loc(#loc)
    %c4_i32_0 = arith.constant 4 : i32 loc(#loc)
    %5 = arith.muli %4, %c4_i32_0 : i32 loc(#loc)
    %6 = arith.subi %1, %5 : i32 loc(#loc)
    %7 = tt.call @minimum__i32__1cconstexpr_4__2cconstexpr_PROPAGATE_NAN_d_NONE_(%6) : (i32) -> i32 loc(#loc)
    %8 = arith.remsi %0, %7 : i32 loc(#loc)
    %9 = arith.addi %5, %8 : i32 loc(#loc)
    %10 = arith.remsi %0, %3 : i32 loc(#loc)
    %11 = arith.divsi %10, %7 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %12 = arith.muli %9, %c256_i32 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_1 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_2 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %13 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64_1], [%c4096_i64_2, %c1_i64], [%12, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %c256_i32_3 = arith.constant 256 : i32 loc(#loc)
    %14 = arith.muli %11, %c256_i32_3 : i32 loc(#loc)
    %c4096_i64_4 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_5 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_6 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64_7 = arith.constant 1 : i64 loc(#loc)
    %c0_i32_8 = arith.constant 0 : i32 loc(#loc)
    %15 = tt.make_tensor_ptr %arg1, [%c4096_i64_4, %c4096_i64_5], [%c4096_i64_6, %c1_i64_7], [%c0_i32_8, %14] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %16 = tt.call @"zeros____0cconstexpr_(constexpr_256_, constexpr_256_)__1cconstexpr_fp32_"() : () -> tensor<256x256xf32> loc(#loc)
    %c0_i32_9 = arith.constant 0 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %17 = arith.bitcast %c0_i32_9 : i32 to i32 loc(#loc)
    %18 = arith.bitcast %c4096_i32 : i32 to i32 loc(#loc)
    %19 = arith.bitcast %c32_i32 : i32 to i32 loc(#loc)
    %20 = llvm.mlir.undef : i32 loc(#loc)
    %21:3 = scf.for %arg6 = %17 to %18 step %19 iter_args(%arg7 = %16, %arg8 = %13, %arg9 = %15) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %25 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %26 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %cst = arith.constant 0.000000e+00 : f32 loc(#loc)
      %cst_16 = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
      %27 = tt.dot %25, %26, %cst_16 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %28 = arith.addf %arg7, %27 : tensor<256x256xf32> loc(#loc)
      %c0_i32_17 = arith.constant 0 : i32 loc(#loc)
      %c32_i32_18 = arith.constant 32 : i32 loc(#loc)
      %29 = tt.advance %arg8, [%c0_i32_17, %c32_i32_18] : <tensor<256x32xf16>, 1> loc(#loc)
      %c32_i32_19 = arith.constant 32 : i32 loc(#loc)
      %c0_i32_20 = arith.constant 0 : i32 loc(#loc)
      %30 = tt.advance %arg9, [%c32_i32_19, %c0_i32_20] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %28, %29, %30 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %c256_i32_10 = arith.constant 256 : i32 loc(#loc)
    %22 = arith.muli %9, %c256_i32_10 : i32 loc(#loc)
    %c256_i32_11 = arith.constant 256 : i32 loc(#loc)
    %23 = arith.muli %11, %c256_i32_11 : i32 loc(#loc)
    %c4096_i64_12 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_13 = arith.constant 4096 : i64 loc(#loc)
    %c4096_i64_14 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64_15 = arith.constant 1 : i64 loc(#loc)
    %24 = tt.make_tensor_ptr %arg2, [%c4096_i64_12, %c4096_i64_13], [%c4096_i64_14, %c1_i64_15], [%22, %23] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %24, %21#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
  tt.func private @cdiv____0cconstexpr_4096__1cconstexpr_256_() -> i32 attributes {noinline = false} {
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    tt.return %c16_i32 : i32 loc(#loc)
  } loc(#loc)
  tt.func private @minimum__i32__1cconstexpr_4__2cconstexpr_PROPAGATE_NAN_d_NONE_(%arg0: i32 loc(unknown)) -> i32 attributes {noinline = false} {
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = arith.minsi %arg0, %c4_i32 : i32 loc(#loc)
    tt.return %0 : i32 loc(#loc)
  } loc(#loc)
  tt.func private @"zeros____0cconstexpr_(constexpr_256_, constexpr_256_)__1cconstexpr_fp32_"() -> tensor<256x256xf32> attributes {noinline = false} {
    %cst = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    tt.return %cst : tensor<256x256xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before Canonicalizer (canonicalize) ('tt.func' operation: @matmul_kernel_with_block_pointers_0d1d2d3d4d5d) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = tt.get_program_id x : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c16_i32_0 = arith.constant 16 : i32 loc(#loc)
    %1 = arith.muli %c16_i32_0, %c4_i32 : i32 loc(#loc)
    %2 = arith.divsi %0, %1 : i32 loc(#loc)
    %3 = arith.muli %2, %c4_i32 : i32 loc(#loc)
    %4 = arith.subi %c16_i32, %3 : i32 loc(#loc)
    %c4_i32_1 = arith.constant 4 : i32 loc(#loc)
    %5 = arith.minsi %4, %c4_i32_1 : i32 loc(#loc)
    %6 = arith.remsi %0, %5 : i32 loc(#loc)
    %7 = arith.addi %3, %6 : i32 loc(#loc)
    %8 = arith.remsi %0, %1 : i32 loc(#loc)
    %9 = arith.divsi %8, %5 : i32 loc(#loc)
    %10 = arith.muli %7, %c256_i32 : i32 loc(#loc)
    %11 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%10, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %12 = arith.muli %9, %c256_i32 : i32 loc(#loc)
    %13 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %12] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    %14:3 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst_2, %arg8 = %11, %arg9 = %13) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %18 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %19 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %20 = tt.dot %18, %19, %cst {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %21 = arith.addf %arg7, %20 : tensor<256x256xf32> loc(#loc)
      %22 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<256x32xf16>, 1> loc(#loc)
      %23 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %21, %22, %23 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %15 = arith.muli %7, %c256_i32 : i32 loc(#loc)
    %16 = arith.muli %9, %c256_i32 : i32 loc(#loc)
    %17 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%15, %16] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %17, %14#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
  tt.func private @cdiv____0cconstexpr_4096__1cconstexpr_256_() -> i32 attributes {noinline = false} loc(#loc)
  tt.func private @minimum__i32__1cconstexpr_4__2cconstexpr_PROPAGATE_NAN_d_NONE_(i32) -> i32 attributes {noinline = false} loc(#loc)
  tt.func private @"zeros____0cconstexpr_(constexpr_256_, constexpr_256_)__1cconstexpr_fp32_"() -> tensor<256x256xf32> attributes {noinline = false} loc(#loc)
} loc(#loc)


// -----// IR Dump Before TritonCombineOps (triton-combine) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = arith.divsi %0, %c64_i32 : i32 loc(#loc)
    %2 = arith.muli %1, %c4_i32 : i32 loc(#loc)
    %3 = arith.subi %c16_i32, %2 : i32 loc(#loc)
    %4 = arith.minsi %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.remsi %0, %4 : i32 loc(#loc)
    %6 = arith.addi %2, %5 : i32 loc(#loc)
    %7 = arith.remsi %0, %c64_i32 : i32 loc(#loc)
    %8 = arith.divsi %7, %4 : i32 loc(#loc)
    %9 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %10 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %11] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %13:3 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %10, %arg9 = %12) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %17 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %18 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %19 = tt.dot %17, %18, %cst {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %20 = arith.addf %arg7, %19 : tensor<256x256xf32> loc(#loc)
      %21 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<256x32xf16>, 1> loc(#loc)
      %22 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %20, %21, %22 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %14 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %15 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %16 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%14, %15] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %16, %13#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = arith.divsi %0, %c64_i32 : i32 loc(#loc)
    %2 = arith.muli %1, %c4_i32 : i32 loc(#loc)
    %3 = arith.subi %c16_i32, %2 : i32 loc(#loc)
    %4 = arith.minsi %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.remsi %0, %4 : i32 loc(#loc)
    %6 = arith.addi %2, %5 : i32 loc(#loc)
    %7 = arith.remsi %0, %c64_i32 : i32 loc(#loc)
    %8 = arith.divsi %7, %4 : i32 loc(#loc)
    %9 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %10 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %11] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %13:3 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %10, %arg9 = %12) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %17 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %18 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %19 = tt.dot %17, %18, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %20 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<256x32xf16>, 1> loc(#loc)
      %21 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %19, %20, %21 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %14 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %15 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %16 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%14, %15] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %16, %13#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before TritonReorderBroadcast (triton-reorder-broadcast) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = arith.divsi %0, %c64_i32 : i32 loc(#loc)
    %2 = arith.muli %1, %c4_i32 : i32 loc(#loc)
    %3 = arith.subi %c16_i32, %2 : i32 loc(#loc)
    %4 = arith.minsi %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.remsi %0, %4 : i32 loc(#loc)
    %6 = arith.addi %2, %5 : i32 loc(#loc)
    %7 = arith.remsi %0, %c64_i32 : i32 loc(#loc)
    %8 = arith.divsi %7, %4 : i32 loc(#loc)
    %9 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %10 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %11] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %13:3 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %10, %arg9 = %12) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %17 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %18 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %19 = tt.dot %17, %18, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %20 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<256x32xf16>, 1> loc(#loc)
      %21 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %19, %20, %21 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %14 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %15 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %16 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%14, %15] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %16, %13#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = arith.divsi %0, %c64_i32 : i32 loc(#loc)
    %2 = arith.muli %1, %c4_i32 : i32 loc(#loc)
    %3 = arith.subi %c16_i32, %2 : i32 loc(#loc)
    %4 = arith.minsi %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.remsi %0, %4 : i32 loc(#loc)
    %6 = arith.addi %2, %5 : i32 loc(#loc)
    %7 = arith.remsi %0, %c64_i32 : i32 loc(#loc)
    %8 = arith.divsi %7, %4 : i32 loc(#loc)
    %9 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %10 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %11] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %13:3 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %10, %arg9 = %12) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %17 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %18 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %19 = tt.dot %17, %18, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %20 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<256x32xf16>, 1> loc(#loc)
      %21 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %19, %20, %21 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %14 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %15 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %16 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%14, %15] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %16, %13#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before LoopInvariantCodeMotion (loop-invariant-code-motion) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = arith.divsi %0, %c64_i32 : i32 loc(#loc)
    %2 = arith.muli %1, %c4_i32 : i32 loc(#loc)
    %3 = arith.subi %c16_i32, %2 : i32 loc(#loc)
    %4 = arith.minsi %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.remsi %0, %4 : i32 loc(#loc)
    %6 = arith.addi %2, %5 : i32 loc(#loc)
    %7 = arith.remsi %0, %c64_i32 : i32 loc(#loc)
    %8 = arith.divsi %7, %4 : i32 loc(#loc)
    %9 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %10 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %11] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %13:3 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %10, %arg9 = %12) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %15 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %16 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %17 = tt.dot %15, %16, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %18 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<256x32xf16>, 1> loc(#loc)
      %19 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %17, %18, %19 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %14 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %11] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %14, %13#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before SymbolDCE (symbol-dce) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = arith.divsi %0, %c64_i32 : i32 loc(#loc)
    %2 = arith.muli %1, %c4_i32 : i32 loc(#loc)
    %3 = arith.subi %c16_i32, %2 : i32 loc(#loc)
    %4 = arith.minsi %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.remsi %0, %4 : i32 loc(#loc)
    %6 = arith.addi %2, %5 : i32 loc(#loc)
    %7 = arith.remsi %0, %c64_i32 : i32 loc(#loc)
    %8 = arith.divsi %7, %4 : i32 loc(#loc)
    %9 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %10 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %11] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %13:3 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %10, %arg9 = %12) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %15 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %16 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %17 = tt.dot %15, %16, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %18 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<256x32xf16>, 1> loc(#loc)
      %19 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %17, %18, %19 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %14 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %11] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %14, %13#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before ConvertTritonToTritonGPUWarp (convert-triton-to-tritongpu-warp) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<256x256xf32> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = arith.divsi %0, %c64_i32 : i32 loc(#loc)
    %2 = arith.muli %1, %c4_i32 : i32 loc(#loc)
    %3 = arith.subi %c16_i32, %2 : i32 loc(#loc)
    %4 = arith.minsi %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.remsi %0, %4 : i32 loc(#loc)
    %6 = arith.addi %2, %5 : i32 loc(#loc)
    %7 = arith.remsi %0, %c64_i32 : i32 loc(#loc)
    %8 = arith.divsi %7, %4 : i32 loc(#loc)
    %9 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %10 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1> loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %11] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1> loc(#loc)
    %13:3 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %10, %arg9 = %12) -> (tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1>)  : i32 {
      %15 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16> loc(#loc)
      %16 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16> loc(#loc)
      %17 = tt.dot %15, %16, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32> loc(#loc)
      %18 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<256x32xf16>, 1> loc(#loc)
      %19 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x256xf16>, 1> loc(#loc)
      scf.yield %17, %18, %19 : tensor<256x256xf32>, !tt.ptr<tensor<256x32xf16>, 1>, !tt.ptr<tensor<32x256xf16>, 1> loc(#loc)
    } loc(#loc)
    %14 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %11] {order = array<i32: 1, 0>} : <tensor<256x256xf32>, 1> loc(#loc)
    tt.store %14, %13#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32>, 1>, tensor<256x256xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


%17 = tt.dot %15, %16, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32>
%15 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16>
<block argument> of type '!tt.ptr<tensor<256x32xf16>, 1>' at index: 2
%10 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16>, 1>
%15 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16>, 1> -> tensor<256x32xf16>
%18 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<256x32xf16>, 1>
%16 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16>
<block argument> of type '!tt.ptr<tensor<32x256xf16>, 1>' at index: 3
%12 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %11] {order = array<i32: 1, 0>} : <tensor<32x256xf16>, 1>
%16 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16>, 1> -> tensor<32x256xf16>
%19 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x256xf16>, 1>
%cst = arith.constant dense<0.000000e+00> : tensor<256x256xf32>
<block argument> of type 'tensor<256x256xf32>' at index: 1
%17 = tt.dot %15, %16, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16> * tensor<32x256xf16> -> tensor<256x256xf32>
// -----// IR Dump Before TritonGPUPrefetchBlock (tritongpu-prefetch-block) ('builtin.module' operation) //----- //
#blocked = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<256x256xf32, #blocked> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = arith.divsi %0, %c64_i32 : i32 loc(#loc)
    %2 = arith.muli %1, %c4_i32 : i32 loc(#loc)
    %3 = arith.subi %c16_i32, %2 : i32 loc(#loc)
    %4 = arith.minsi %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.remsi %0, %4 : i32 loc(#loc)
    %6 = arith.addi %2, %5 : i32 loc(#loc)
    %7 = arith.remsi %0, %c64_i32 : i32 loc(#loc)
    %8 = arith.divsi %7, %4 : i32 loc(#loc)
    %9 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %10 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>>, 1> loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %11] {order = array<i32: 1, 0>} : <tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>>, 1> loc(#loc)
    %13:3 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %10, %arg9 = %12) -> (tensor<256x256xf32, #blocked>, !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>>, 1>)  : i32 {
      %15 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>>, 1> -> tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>> loc(#loc)
      %16 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>>, 1> -> tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>> loc(#loc)
      %17 = tt.dot %15, %16, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>> * tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>> -> tensor<256x256xf32, #blocked> loc(#loc)
      %18 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>>, 1> loc(#loc)
      %19 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>>, 1> loc(#loc)
      scf.yield %17, %18, %19 : tensor<256x256xf32, #blocked>, !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>>, 1> loc(#loc)
    } {triton_gpu.workload = 3 : i32} loc(#loc)
    %14 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %11] {order = array<i32: 1, 0>} : <tensor<256x256xf32, #blocked>, 1> loc(#loc)
    tt.store %14, %13#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32, #blocked>, 1>, tensor<256x256xf32, #blocked> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


%31:5 = "scf.for"(%5, %2, %4, %3, %24, %30, %23, %29) ({
^bb0(%arg6: i32, %arg7: tensor<256x256xf32, #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>>, %arg8: !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, %arg9: !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, %arg10: !tt.ptr<tensor<256x32xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [32, 1], order = [1, 0]}>>, 1>, %arg11: !tt.ptr<tensor<32x256xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [4, 8], order = [1, 0]}>>, 1>):
  %34 = "tt.load"(%arg8) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>) -> tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>
  %35 = "tt.load"(%arg9) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>) -> tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>
  %36 = "tt.dot"(%34, %35, %arg7) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, tensor<256x256xf32, #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>>) -> tensor<256x256xf32, #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>>
  %37 = "tt.advance"(%arg8, %5, %4) : (!tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, i32, i32) -> !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>
  %38 = "tt.advance"(%arg9, %4, %5) : (!tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, i32, i32) -> !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>
  "scf.yield"(%36, %37, %38) : (tensor<256x256xf32, #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>>, !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>) -> ()
}) : (i32, i32, i32, tensor<256x256xf32, #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>>, !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<256x32xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [32, 1], order = [1, 0]}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [4, 8], order = [1, 0]}>>, 1>) -> (tensor<256x256xf32, #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>>, !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<256x32xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [32, 1], order = [1, 0]}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [4, 8], order = [1, 0]}>>, 1>)
%21:5 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %14, %arg9 = %20, %arg10 = %13, %arg11 = %19) -> (tensor<256x256xf32, #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>>, !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<256x32xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [32, 1], order = [1, 0]}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [4, 8], order = [1, 0]}>>, 1>)  : i32 {
  gpu.barrier
  %23 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1> -> tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>
  %24 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1> -> tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>
  %25 = tt.dot %23, %24, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>> * tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>> -> tensor<256x256xf32, #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>>
  tt.prefetch %arg10 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [32, 1], order = [1, 0]}>>, 1>
  %26 = tt.advance %arg10, [%c0_i32, %c32_i32] : <tensor<256x32xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [32, 1], order = [1, 0]}>>, 1>
  %27 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>
  tt.prefetch %arg11 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [4, 8], order = [1, 0]}>>, 1>
  %28 = tt.advance %arg11, [%c32_i32, %c0_i32] : <tensor<32x256xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [4, 8], order = [1, 0]}>>, 1>
  %29 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>
  scf.yield %25, %27, %29, %26, %28 : tensor<256x256xf32, #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>>, !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<256x32xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [32, 1], order = [1, 0]}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [4, 8], order = [1, 0]}>>, 1>
}
// -----// IR Dump Before TritonGPUDistributeToWarps (tritongpu-distribute-to-warps) ('builtin.module' operation) //----- //
#blocked = #triton_gpu.blocked<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], warpsPerCTA = [8, 4], order = [1, 0]}>
#blocked1 = #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [32, 1], order = [1, 0]}>
#blocked2 = #triton_gpu.blocked<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], warpsPerCTA = [4, 8], order = [1, 0]}>
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<256x256xf32, #blocked> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %0 = tt.get_program_id x : i32 loc(#loc)
    %1 = arith.divsi %0, %c64_i32 : i32 loc(#loc)
    %2 = arith.muli %1, %c4_i32 : i32 loc(#loc)
    %3 = arith.subi %c16_i32, %2 : i32 loc(#loc)
    %4 = arith.minsi %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.remsi %0, %4 : i32 loc(#loc)
    %6 = arith.addi %2, %5 : i32 loc(#loc)
    %7 = arith.remsi %0, %c64_i32 : i32 loc(#loc)
    %8 = arith.divsi %7, %4 : i32 loc(#loc)
    %9 = arith.muli %6, %c256_i32 : i32 loc(#loc)
    %10 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16, #blocked1>, 1> loc(#loc)
    tt.prefetch %10 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16, #blocked1>, 1> loc(#loc)
    %11 = tt.advance %10, [%c0_i32, %c32_i32] : <tensor<256x32xf16, #blocked1>, 1> loc(#loc)
    tt.prefetch %11 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16, #blocked1>, 1> loc(#loc)
    %12 = tt.advance %11, [%c0_i32, %c32_i32] : <tensor<256x32xf16, #blocked1>, 1> loc(#loc)
    tt.prefetch %12 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16, #blocked1>, 1> loc(#loc)
    %13 = tt.advance %12, [%c0_i32, %c32_i32] : <tensor<256x32xf16, #blocked1>, 1> loc(#loc)
    %14 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %c0_i32] {order = array<i32: 1, 0>} : <tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>>, 1> loc(#loc)
    %15 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %16 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %15] {order = array<i32: 1, 0>} : <tensor<32x256xf16, #blocked2>, 1> loc(#loc)
    tt.prefetch %16 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16, #blocked2>, 1> loc(#loc)
    %17 = tt.advance %16, [%c32_i32, %c0_i32] : <tensor<32x256xf16, #blocked2>, 1> loc(#loc)
    tt.prefetch %17 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16, #blocked2>, 1> loc(#loc)
    %18 = tt.advance %17, [%c32_i32, %c0_i32] : <tensor<32x256xf16, #blocked2>, 1> loc(#loc)
    tt.prefetch %18 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16, #blocked2>, 1> loc(#loc)
    %19 = tt.advance %18, [%c32_i32, %c0_i32] : <tensor<32x256xf16, #blocked2>, 1> loc(#loc)
    %20 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %15] {order = array<i32: 1, 0>} : <tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>>, 1> loc(#loc)
    %21:5 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %14, %arg9 = %20, %arg10 = %13, %arg11 = %19) -> (tensor<256x256xf32, #blocked>, !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>>, 1>, !tt.ptr<tensor<256x32xf16, #blocked1>, 1>, !tt.ptr<tensor<32x256xf16, #blocked2>, 1>)  : i32 {
      gpu.barrier loc(#loc)
      %23 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>>, 1> -> tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>> loc(#loc)
      %24 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>>, 1> -> tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>> loc(#loc)
      %25 = tt.dot %23, %24, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>> * tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>> -> tensor<256x256xf32, #blocked> loc(#loc)
      tt.prefetch %arg10 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<256x32xf16, #blocked1>, 1> loc(#loc)
      %26 = tt.advance %arg10, [%c0_i32, %c32_i32] : <tensor<256x32xf16, #blocked1>, 1> loc(#loc)
      %27 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>>, 1> loc(#loc)
      tt.prefetch %arg11 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x256xf16, #blocked2>, 1> loc(#loc)
      %28 = tt.advance %arg11, [%c32_i32, %c0_i32] : <tensor<32x256xf16, #blocked2>, 1> loc(#loc)
      %29 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>>, 1> loc(#loc)
      scf.yield %25, %27, %29, %26, %28 : tensor<256x256xf32, #blocked>, !tt.ptr<tensor<256x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #blocked}>>, 1>, !tt.ptr<tensor<32x256xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #blocked}>>, 1>, !tt.ptr<tensor<256x32xf16, #blocked1>, 1>, !tt.ptr<tensor<32x256xf16, #blocked2>, 1> loc(#loc)
    } loc(#loc)
    %22 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%9, %15] {order = array<i32: 1, 0>} : <tensor<256x256xf32, #blocked>, 1> loc(#loc)
    tt.store %22, %21#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<256x256xf32, #blocked>, 1>, tensor<256x256xf32, #blocked> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before TritonGPUMatchTargetSize (tritongpu-match-target-size) ('builtin.module' operation) //----- //
#loc = loc(unknown)
#warp = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>
#warp1 = #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %0 = gpu.subgroup_id : index loc(#loc)
    %1 = arith.index_cast %0 : index to i32 loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<32x64xf32, #warp> loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %2 = tt.get_program_id x : i32 loc(#loc)
    %3 = arith.divsi %2, %c64_i32 : i32 loc(#loc)
    %4 = arith.muli %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.subi %c16_i32, %4 : i32 loc(#loc)
    %6 = arith.minsi %5, %c4_i32 : i32 loc(#loc)
    %7 = arith.remsi %2, %6 : i32 loc(#loc)
    %8 = arith.addi %4, %7 : i32 loc(#loc)
    %9 = arith.remsi %2, %c64_i32 : i32 loc(#loc)
    %10 = arith.divsi %9, %6 : i32 loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %12 = arith.muli %1, %c8_i32 : i32 loc(#loc)
    %13 = arith.addi %12, %11 : i32 loc(#loc)
    %14 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c0_i32] {order = array<i32: 1, 0>} : <tensor<8x32xf16, #warp1>, 1> loc(#loc)
    tt.prefetch %14 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x32xf16, #warp1>, 1> loc(#loc)
    %15 = tt.advance %14, [%c0_i32, %c32_i32] : <tensor<8x32xf16, #warp1>, 1> loc(#loc)
    tt.prefetch %15 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x32xf16, #warp1>, 1> loc(#loc)
    %16 = tt.advance %15, [%c0_i32, %c32_i32] : <tensor<8x32xf16, #warp1>, 1> loc(#loc)
    tt.prefetch %16 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x32xf16, #warp1>, 1> loc(#loc)
    %17 = tt.advance %16, [%c0_i32, %c32_i32] : <tensor<8x32xf16, #warp1>, 1> loc(#loc)
    %c4_i32_0 = arith.constant 4 : i32 loc(#loc)
    %18 = arith.divsi %1, %c4_i32_0 : i32 loc(#loc)
    %c8_i32_1 = arith.constant 8 : i32 loc(#loc)
    %19 = arith.remsi %18, %c8_i32_1 : i32 loc(#loc)
    %c32_i32_2 = arith.constant 32 : i32 loc(#loc)
    %20 = arith.muli %19, %c32_i32_2 : i32 loc(#loc)
    %21 = arith.addi %20, %11 : i32 loc(#loc)
    %c4_i32_3 = arith.constant 4 : i32 loc(#loc)
    %22 = arith.remsi %1, %c4_i32_3 : i32 loc(#loc)
    %23 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%21, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #warp}>>, 1> loc(#loc)
    %24 = arith.muli %10, %c256_i32 : i32 loc(#loc)
    %c8_i32_4 = arith.constant 8 : i32 loc(#loc)
    %25 = arith.divsi %1, %c8_i32_4 : i32 loc(#loc)
    %c4_i32_5 = arith.constant 4 : i32 loc(#loc)
    %26 = arith.remsi %25, %c4_i32_5 : i32 loc(#loc)
    %c8_i32_6 = arith.constant 8 : i32 loc(#loc)
    %27 = arith.muli %26, %c8_i32_6 : i32 loc(#loc)
    %28 = arith.addi %27, %c0_i32 : i32 loc(#loc)
    %c8_i32_7 = arith.constant 8 : i32 loc(#loc)
    %29 = arith.remsi %1, %c8_i32_7 : i32 loc(#loc)
    %c8_i32_8 = arith.constant 8 : i32 loc(#loc)
    %30 = arith.remsi %29, %c8_i32_8 : i32 loc(#loc)
    %c32_i32_9 = arith.constant 32 : i32 loc(#loc)
    %31 = arith.muli %30, %c32_i32_9 : i32 loc(#loc)
    %32 = arith.addi %31, %24 : i32 loc(#loc)
    %33 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%28, %32] {order = array<i32: 1, 0>} : <tensor<8x32xf16, #warp1>, 1> loc(#loc)
    tt.prefetch %33 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x32xf16, #warp1>, 1> loc(#loc)
    %34 = tt.advance %33, [%c32_i32, %c0_i32] : <tensor<8x32xf16, #warp1>, 1> loc(#loc)
    tt.prefetch %34 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x32xf16, #warp1>, 1> loc(#loc)
    %35 = tt.advance %34, [%c32_i32, %c0_i32] : <tensor<8x32xf16, #warp1>, 1> loc(#loc)
    tt.prefetch %35 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x32xf16, #warp1>, 1> loc(#loc)
    %36 = tt.advance %35, [%c32_i32, %c0_i32] : <tensor<8x32xf16, #warp1>, 1> loc(#loc)
    %c4_i32_10 = arith.constant 4 : i32 loc(#loc)
    %37 = arith.divsi %1, %c4_i32_10 : i32 loc(#loc)
    %c4_i32_11 = arith.constant 4 : i32 loc(#loc)
    %38 = arith.remsi %1, %c4_i32_11 : i32 loc(#loc)
    %c4_i32_12 = arith.constant 4 : i32 loc(#loc)
    %39 = arith.remsi %38, %c4_i32_12 : i32 loc(#loc)
    %c64_i32_13 = arith.constant 64 : i32 loc(#loc)
    %40 = arith.muli %39, %c64_i32_13 : i32 loc(#loc)
    %41 = arith.addi %40, %24 : i32 loc(#loc)
    %42 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %41] {order = array<i32: 1, 0>} : <tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #warp}>>, 1> loc(#loc)
    %43:5 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %23, %arg9 = %42, %arg10 = %17, %arg11 = %36) -> (tensor<32x64xf32, #warp>, !tt.ptr<tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #warp}>>, 1>, !tt.ptr<tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #warp}>>, 1>, !tt.ptr<tensor<8x32xf16, #warp1>, 1>, !tt.ptr<tensor<8x32xf16, #warp1>, 1>)  : i32 {
      gpu.barrier loc(#loc)
      %53 = tt.load %arg8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #warp}>>, 1> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #warp}>> loc(#loc)
      %54 = tt.load %arg9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #warp}>>, 1> -> tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #warp}>> loc(#loc)
      %55 = tt.dot %53, %54, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #warp}>> * tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #warp}>> -> tensor<32x64xf32, #warp> loc(#loc)
      tt.prefetch %arg10 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x32xf16, #warp1>, 1> loc(#loc)
      %56 = tt.advance %arg10, [%c0_i32, %c32_i32] : <tensor<8x32xf16, #warp1>, 1> loc(#loc)
      %57 = tt.advance %arg8, [%c0_i32, %c32_i32] : <tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #warp}>>, 1> loc(#loc)
      tt.prefetch %arg11 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x32xf16, #warp1>, 1> loc(#loc)
      %58 = tt.advance %arg11, [%c32_i32, %c0_i32] : <tensor<8x32xf16, #warp1>, 1> loc(#loc)
      %59 = tt.advance %arg9, [%c32_i32, %c0_i32] : <tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #warp}>>, 1> loc(#loc)
      scf.yield %55, %57, %59, %56, %58 : tensor<32x64xf32, #warp>, !tt.ptr<tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #warp}>>, 1>, !tt.ptr<tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #warp}>>, 1>, !tt.ptr<tensor<8x32xf16, #warp1>, 1>, !tt.ptr<tensor<8x32xf16, #warp1>, 1> loc(#loc)
    } loc(#loc)
    %c4_i32_14 = arith.constant 4 : i32 loc(#loc)
    %44 = arith.divsi %1, %c4_i32_14 : i32 loc(#loc)
    %c8_i32_15 = arith.constant 8 : i32 loc(#loc)
    %45 = arith.remsi %44, %c8_i32_15 : i32 loc(#loc)
    %c32_i32_16 = arith.constant 32 : i32 loc(#loc)
    %46 = arith.muli %45, %c32_i32_16 : i32 loc(#loc)
    %47 = arith.addi %46, %11 : i32 loc(#loc)
    %c4_i32_17 = arith.constant 4 : i32 loc(#loc)
    %48 = arith.remsi %1, %c4_i32_17 : i32 loc(#loc)
    %c4_i32_18 = arith.constant 4 : i32 loc(#loc)
    %49 = arith.remsi %48, %c4_i32_18 : i32 loc(#loc)
    %c64_i32_19 = arith.constant 64 : i32 loc(#loc)
    %50 = arith.muli %49, %c64_i32_19 : i32 loc(#loc)
    %51 = arith.addi %50, %24 : i32 loc(#loc)
    %52 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%47, %51] {order = array<i32: 1, 0>} : <tensor<32x64xf32, #warp>, 1> loc(#loc)
    tt.store %52, %43#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<32x64xf32, #warp>, 1>, tensor<32x64xf32, #warp> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32}, %arg4: i32 {tt.divisibility = 16 : i32}, %arg5: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
    %0 = gpu.subgroup_id : index
    %1 = arith.index_cast %0 : index to i32
    %c64_i32 = arith.constant 64 : i32
    %c16_i32 = arith.constant 16 : i32
    %c4096_i32 = arith.constant 4096 : i32
    %cst = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_2 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_3 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_4 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_5 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_6 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_7 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_8 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_9 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_10 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_11 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_12 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_13 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %cst_14 = arith.constant dense<0.000000e+00> : tensor<8x16xf32>
    %2 = tt.glue %cst, %cst_0, %cst_1, %cst_2, %cst_3, %cst_4, %cst_5, %cst_6, %cst_7, %cst_8, %cst_9, %cst_10, %cst_11, %cst_12, %cst_13, %cst_14 : tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32> -> tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>
    %c32_i32 = arith.constant 32 : i32
    %c0_i32 = arith.constant 0 : i32
    %c1_i64 = arith.constant 1 : i64
    %c4096_i64 = arith.constant 4096 : i64
    %c256_i32 = arith.constant 256 : i32
    %c4_i32 = arith.constant 4 : i32
    %3 = tt.get_program_id x : i32
    %4 = arith.divsi %3, %c64_i32 : i32
    %5 = arith.muli %4, %c4_i32 : i32
    %6 = arith.subi %c16_i32, %5 : i32
    %7 = arith.minsi %6, %c4_i32 : i32
    %8 = arith.remsi %3, %7 : i32
    %9 = arith.addi %5, %8 : i32
    %10 = arith.remsi %3, %c64_i32 : i32
    %11 = arith.divsi %10, %7 : i32
    %12 = arith.muli %9, %c256_i32 : i32
    %c8_i32 = arith.constant 8 : i32
    %13 = arith.muli %1, %c8_i32 : i32
    %14 = arith.addi %13, %12 : i32
    %15 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%14, %c0_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1>
    %c16_i32_15 = arith.constant 16 : i32
    %16 = arith.addi %c0_i32, %c16_i32_15 : i32
    %17 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%14, %16] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1>
    %18 = tt.glue %15, %17 : !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> -> !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>
    %19 = tt.extract %18, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    tt.prefetch %19 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
    %20 = tt.extract %18, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    tt.prefetch %20 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
    %21 = tt.extract %18, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    %22 = tt.advance %21, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1>
    %23 = tt.extract %18, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    %24 = tt.advance %23, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1>
    %25 = tt.glue %22, %24 : !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> -> !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>
    %26 = tt.extract %25, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    tt.prefetch %26 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
    %27 = tt.extract %25, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    tt.prefetch %27 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
    %28 = tt.extract %25, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    %29 = tt.advance %28, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1>
    %30 = tt.extract %25, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    %31 = tt.advance %30, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1>
    %32 = tt.glue %29, %31 : !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> -> !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>
    %33 = tt.extract %32, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    tt.prefetch %33 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
    %34 = tt.extract %32, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    tt.prefetch %34 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
    %35 = tt.extract %32, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    %36 = tt.advance %35, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1>
    %37 = tt.extract %32, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    %38 = tt.advance %37, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1>
    %39 = tt.glue %36, %38 : !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> -> !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>
    %c4_i32_16 = arith.constant 4 : i32
    %40 = arith.divsi %1, %c4_i32_16 : i32
    %c8_i32_17 = arith.constant 8 : i32
    %41 = arith.remsi %40, %c8_i32_17 : i32
    %c32_i32_18 = arith.constant 32 : i32
    %42 = arith.muli %41, %c32_i32_18 : i32
    %43 = arith.addi %42, %12 : i32
    %c4_i32_19 = arith.constant 4 : i32
    %44 = arith.remsi %1, %c4_i32_19 : i32
    %45 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%43, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1>
    %46 = tt.glue %45 : !tt.ptr<tensor<32x32xf16>, 1> -> !tt.ptr<tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1>
    %47 = arith.muli %11, %c256_i32 : i32
    %c8_i32_20 = arith.constant 8 : i32
    %48 = arith.divsi %1, %c8_i32_20 : i32
    %c4_i32_21 = arith.constant 4 : i32
    %49 = arith.remsi %48, %c4_i32_21 : i32
    %c8_i32_22 = arith.constant 8 : i32
    %50 = arith.muli %49, %c8_i32_22 : i32
    %51 = arith.addi %50, %c0_i32 : i32
    %c8_i32_23 = arith.constant 8 : i32
    %52 = arith.remsi %1, %c8_i32_23 : i32
    %c8_i32_24 = arith.constant 8 : i32
    %53 = arith.remsi %52, %c8_i32_24 : i32
    %c32_i32_25 = arith.constant 32 : i32
    %54 = arith.muli %53, %c32_i32_25 : i32
    %55 = arith.addi %54, %47 : i32
    %56 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %55] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1>
    %c16_i32_26 = arith.constant 16 : i32
    %57 = arith.addi %55, %c16_i32_26 : i32
    %58 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1>
    %59 = tt.glue %56, %58 : !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> -> !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>
    %60 = tt.extract %59, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    tt.prefetch %60 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
    %61 = tt.extract %59, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    tt.prefetch %61 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
    %62 = tt.extract %59, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    %63 = tt.advance %62, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1>
    %64 = tt.extract %59, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    %65 = tt.advance %64, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1>
    %66 = tt.glue %63, %65 : !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> -> !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>
    %67 = tt.extract %66, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    tt.prefetch %67 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
    %68 = tt.extract %66, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    tt.prefetch %68 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
    %69 = tt.extract %66, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    %70 = tt.advance %69, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1>
    %71 = tt.extract %66, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    %72 = tt.advance %71, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1>
    %73 = tt.glue %70, %72 : !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> -> !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>
    %74 = tt.extract %73, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    tt.prefetch %74 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
    %75 = tt.extract %73, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    tt.prefetch %75 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
    %76 = tt.extract %73, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    %77 = tt.advance %76, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1>
    %78 = tt.extract %73, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
    %79 = tt.advance %78, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1>
    %80 = tt.glue %77, %79 : !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> -> !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>
    %c4_i32_27 = arith.constant 4 : i32
    %81 = arith.divsi %1, %c4_i32_27 : i32
    %c4_i32_28 = arith.constant 4 : i32
    %82 = arith.remsi %1, %c4_i32_28 : i32
    %c4_i32_29 = arith.constant 4 : i32
    %83 = arith.remsi %82, %c4_i32_29 : i32
    %c64_i32_30 = arith.constant 64 : i32
    %84 = arith.muli %83, %c64_i32_30 : i32
    %85 = arith.addi %84, %47 : i32
    %86 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %85] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1>
    %c32_i32_31 = arith.constant 32 : i32
    %87 = arith.addi %85, %c32_i32_31 : i32
    %88 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %87] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1>
    %89 = tt.glue %86, %88 : !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1> -> !tt.ptr<tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1>
    %90:5 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %2, %arg8 = %46, %arg9 = %89, %arg10 = %39, %arg11 = %80) -> (tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, !tt.ptr<tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>, !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>)  : i32 {
      gpu.barrier
      %172 = tt.extract %arg8, 0 : !tt.ptr<tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1> -> !tt.ptr<tensor<32x32xf16>, 1>
      %173 = tt.load %172 {DotIdx = 0 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16>
      %174 = tt.glue %173 : tensor<32x32xf16> -> tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>
      %175 = tt.extract %arg9, 0 : !tt.ptr<tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1> -> !tt.ptr<tensor<32x32xf16>, 1>
      %176 = tt.load %175 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16>
      %177 = tt.extract %arg9, 1 : !tt.ptr<tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1> -> !tt.ptr<tensor<32x32xf16>, 1>
      %178 = tt.load %177 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16>
      %179 = tt.glue %176, %178 : tensor<32x32xf16>, tensor<32x32xf16> -> tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>
      %180 = tt.extract %arg7, 0 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %181 = tt.extract %180, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %182 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %183 = tt.extract %182, 0 : tensor<32x32xf16> -> tensor<8x16xf16>
      %184 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %185 = tt.extract %184, 0 : tensor<32x32xf16> -> tensor<16x16xf16>
      %186 = tt.dot %183, %185, %181 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %187 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %188 = tt.extract %187, 4 : tensor<32x32xf16> -> tensor<8x16xf16>
      %189 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %190 = tt.extract %189, 1 : tensor<32x32xf16> -> tensor<16x16xf16>
      %191 = tt.dot %188, %190, %186 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %192 = tt.glue %191 : tensor<8x16xf32> -> tensor<8x16xf32>
      %193 = tt.extract %arg7, 1 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %194 = tt.extract %193, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %195 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %196 = tt.extract %195, 1 : tensor<32x32xf16> -> tensor<8x16xf16>
      %197 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %198 = tt.extract %197, 0 : tensor<32x32xf16> -> tensor<16x16xf16>
      %199 = tt.dot %196, %198, %194 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %200 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %201 = tt.extract %200, 5 : tensor<32x32xf16> -> tensor<8x16xf16>
      %202 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %203 = tt.extract %202, 1 : tensor<32x32xf16> -> tensor<16x16xf16>
      %204 = tt.dot %201, %203, %199 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %205 = tt.glue %204 : tensor<8x16xf32> -> tensor<8x16xf32>
      %206 = tt.extract %arg7, 2 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %207 = tt.extract %206, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %208 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %209 = tt.extract %208, 2 : tensor<32x32xf16> -> tensor<8x16xf16>
      %210 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %211 = tt.extract %210, 0 : tensor<32x32xf16> -> tensor<16x16xf16>
      %212 = tt.dot %209, %211, %207 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %213 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %214 = tt.extract %213, 6 : tensor<32x32xf16> -> tensor<8x16xf16>
      %215 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %216 = tt.extract %215, 1 : tensor<32x32xf16> -> tensor<16x16xf16>
      %217 = tt.dot %214, %216, %212 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %218 = tt.glue %217 : tensor<8x16xf32> -> tensor<8x16xf32>
      %219 = tt.extract %arg7, 3 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %220 = tt.extract %219, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %221 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %222 = tt.extract %221, 3 : tensor<32x32xf16> -> tensor<8x16xf16>
      %223 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %224 = tt.extract %223, 0 : tensor<32x32xf16> -> tensor<16x16xf16>
      %225 = tt.dot %222, %224, %220 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %226 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %227 = tt.extract %226, 7 : tensor<32x32xf16> -> tensor<8x16xf16>
      %228 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %229 = tt.extract %228, 1 : tensor<32x32xf16> -> tensor<16x16xf16>
      %230 = tt.dot %227, %229, %225 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %231 = tt.glue %230 : tensor<8x16xf32> -> tensor<8x16xf32>
      %232 = tt.extract %arg7, 4 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %233 = tt.extract %232, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %234 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %235 = tt.extract %234, 0 : tensor<32x32xf16> -> tensor<8x16xf16>
      %236 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %237 = tt.extract %236, 2 : tensor<32x32xf16> -> tensor<16x16xf16>
      %238 = tt.dot %235, %237, %233 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %239 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %240 = tt.extract %239, 4 : tensor<32x32xf16> -> tensor<8x16xf16>
      %241 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %242 = tt.extract %241, 3 : tensor<32x32xf16> -> tensor<16x16xf16>
      %243 = tt.dot %240, %242, %238 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %244 = tt.glue %243 : tensor<8x16xf32> -> tensor<8x16xf32>
      %245 = tt.extract %arg7, 5 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %246 = tt.extract %245, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %247 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %248 = tt.extract %247, 1 : tensor<32x32xf16> -> tensor<8x16xf16>
      %249 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %250 = tt.extract %249, 2 : tensor<32x32xf16> -> tensor<16x16xf16>
      %251 = tt.dot %248, %250, %246 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %252 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %253 = tt.extract %252, 5 : tensor<32x32xf16> -> tensor<8x16xf16>
      %254 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %255 = tt.extract %254, 3 : tensor<32x32xf16> -> tensor<16x16xf16>
      %256 = tt.dot %253, %255, %251 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %257 = tt.glue %256 : tensor<8x16xf32> -> tensor<8x16xf32>
      %258 = tt.extract %arg7, 6 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %259 = tt.extract %258, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %260 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %261 = tt.extract %260, 2 : tensor<32x32xf16> -> tensor<8x16xf16>
      %262 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %263 = tt.extract %262, 2 : tensor<32x32xf16> -> tensor<16x16xf16>
      %264 = tt.dot %261, %263, %259 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %265 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %266 = tt.extract %265, 6 : tensor<32x32xf16> -> tensor<8x16xf16>
      %267 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %268 = tt.extract %267, 3 : tensor<32x32xf16> -> tensor<16x16xf16>
      %269 = tt.dot %266, %268, %264 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %270 = tt.glue %269 : tensor<8x16xf32> -> tensor<8x16xf32>
      %271 = tt.extract %arg7, 7 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %272 = tt.extract %271, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %273 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %274 = tt.extract %273, 3 : tensor<32x32xf16> -> tensor<8x16xf16>
      %275 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %276 = tt.extract %275, 2 : tensor<32x32xf16> -> tensor<16x16xf16>
      %277 = tt.dot %274, %276, %272 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %278 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %279 = tt.extract %278, 7 : tensor<32x32xf16> -> tensor<8x16xf16>
      %280 = tt.extract %179, 0 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %281 = tt.extract %280, 3 : tensor<32x32xf16> -> tensor<16x16xf16>
      %282 = tt.dot %279, %281, %277 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %283 = tt.glue %282 : tensor<8x16xf32> -> tensor<8x16xf32>
      %284 = tt.extract %arg7, 8 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %285 = tt.extract %284, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %286 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %287 = tt.extract %286, 0 : tensor<32x32xf16> -> tensor<8x16xf16>
      %288 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %289 = tt.extract %288, 0 : tensor<32x32xf16> -> tensor<16x16xf16>
      %290 = tt.dot %287, %289, %285 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %291 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %292 = tt.extract %291, 4 : tensor<32x32xf16> -> tensor<8x16xf16>
      %293 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %294 = tt.extract %293, 1 : tensor<32x32xf16> -> tensor<16x16xf16>
      %295 = tt.dot %292, %294, %290 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %296 = tt.glue %295 : tensor<8x16xf32> -> tensor<8x16xf32>
      %297 = tt.extract %arg7, 9 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %298 = tt.extract %297, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %299 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %300 = tt.extract %299, 1 : tensor<32x32xf16> -> tensor<8x16xf16>
      %301 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %302 = tt.extract %301, 0 : tensor<32x32xf16> -> tensor<16x16xf16>
      %303 = tt.dot %300, %302, %298 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %304 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %305 = tt.extract %304, 5 : tensor<32x32xf16> -> tensor<8x16xf16>
      %306 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %307 = tt.extract %306, 1 : tensor<32x32xf16> -> tensor<16x16xf16>
      %308 = tt.dot %305, %307, %303 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %309 = tt.glue %308 : tensor<8x16xf32> -> tensor<8x16xf32>
      %310 = tt.extract %arg7, 10 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %311 = tt.extract %310, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %312 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %313 = tt.extract %312, 2 : tensor<32x32xf16> -> tensor<8x16xf16>
      %314 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %315 = tt.extract %314, 0 : tensor<32x32xf16> -> tensor<16x16xf16>
      %316 = tt.dot %313, %315, %311 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %317 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %318 = tt.extract %317, 6 : tensor<32x32xf16> -> tensor<8x16xf16>
      %319 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %320 = tt.extract %319, 1 : tensor<32x32xf16> -> tensor<16x16xf16>
      %321 = tt.dot %318, %320, %316 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %322 = tt.glue %321 : tensor<8x16xf32> -> tensor<8x16xf32>
      %323 = tt.extract %arg7, 11 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %324 = tt.extract %323, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %325 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %326 = tt.extract %325, 3 : tensor<32x32xf16> -> tensor<8x16xf16>
      %327 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %328 = tt.extract %327, 0 : tensor<32x32xf16> -> tensor<16x16xf16>
      %329 = tt.dot %326, %328, %324 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %330 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %331 = tt.extract %330, 7 : tensor<32x32xf16> -> tensor<8x16xf16>
      %332 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %333 = tt.extract %332, 1 : tensor<32x32xf16> -> tensor<16x16xf16>
      %334 = tt.dot %331, %333, %329 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %335 = tt.glue %334 : tensor<8x16xf32> -> tensor<8x16xf32>
      %336 = tt.extract %arg7, 12 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %337 = tt.extract %336, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %338 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %339 = tt.extract %338, 0 : tensor<32x32xf16> -> tensor<8x16xf16>
      %340 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %341 = tt.extract %340, 2 : tensor<32x32xf16> -> tensor<16x16xf16>
      %342 = tt.dot %339, %341, %337 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %343 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %344 = tt.extract %343, 4 : tensor<32x32xf16> -> tensor<8x16xf16>
      %345 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %346 = tt.extract %345, 3 : tensor<32x32xf16> -> tensor<16x16xf16>
      %347 = tt.dot %344, %346, %342 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %348 = tt.glue %347 : tensor<8x16xf32> -> tensor<8x16xf32>
      %349 = tt.extract %arg7, 13 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %350 = tt.extract %349, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %351 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %352 = tt.extract %351, 1 : tensor<32x32xf16> -> tensor<8x16xf16>
      %353 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %354 = tt.extract %353, 2 : tensor<32x32xf16> -> tensor<16x16xf16>
      %355 = tt.dot %352, %354, %350 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %356 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %357 = tt.extract %356, 5 : tensor<32x32xf16> -> tensor<8x16xf16>
      %358 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %359 = tt.extract %358, 3 : tensor<32x32xf16> -> tensor<16x16xf16>
      %360 = tt.dot %357, %359, %355 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %361 = tt.glue %360 : tensor<8x16xf32> -> tensor<8x16xf32>
      %362 = tt.extract %arg7, 14 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %363 = tt.extract %362, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %364 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %365 = tt.extract %364, 2 : tensor<32x32xf16> -> tensor<8x16xf16>
      %366 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %367 = tt.extract %366, 2 : tensor<32x32xf16> -> tensor<16x16xf16>
      %368 = tt.dot %365, %367, %363 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %369 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %370 = tt.extract %369, 6 : tensor<32x32xf16> -> tensor<8x16xf16>
      %371 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %372 = tt.extract %371, 3 : tensor<32x32xf16> -> tensor<16x16xf16>
      %373 = tt.dot %370, %372, %368 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %374 = tt.glue %373 : tensor<8x16xf32> -> tensor<8x16xf32>
      %375 = tt.extract %arg7, 15 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
      %376 = tt.extract %375, 0 : tensor<8x16xf32> -> tensor<8x16xf32>
      %377 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %378 = tt.extract %377, 3 : tensor<32x32xf16> -> tensor<8x16xf16>
      %379 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %380 = tt.extract %379, 2 : tensor<32x32xf16> -> tensor<16x16xf16>
      %381 = tt.dot %378, %380, %376 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %382 = tt.extract %174, 0 : tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %383 = tt.extract %382, 7 : tensor<32x32xf16> -> tensor<8x16xf16>
      %384 = tt.extract %179, 1 : tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>> -> tensor<32x32xf16>
      %385 = tt.extract %384, 3 : tensor<32x32xf16> -> tensor<16x16xf16>
      %386 = tt.dot %383, %385, %381 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32>
      %387 = tt.glue %386 : tensor<8x16xf32> -> tensor<8x16xf32>
      %388 = tt.glue %192, %205, %218, %231, %244, %257, %270, %283, %296, %309, %322, %335, %348, %361, %374, %387 : tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32> -> tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>
      %389 = tt.extract %arg10, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
      tt.prefetch %389 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
      %390 = tt.extract %arg10, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
      tt.prefetch %390 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
      %391 = tt.extract %arg10, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
      %392 = tt.advance %391, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1>
      %393 = tt.extract %arg10, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
      %394 = tt.advance %393, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1>
      %395 = tt.glue %392, %394 : !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> -> !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>
      %396 = tt.extract %arg8, 0 : !tt.ptr<tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1> -> !tt.ptr<tensor<32x32xf16>, 1>
      %397 = tt.advance %396, [%c0_i32, %c32_i32] : <tensor<32x32xf16>, 1>
      %398 = tt.glue %397 : !tt.ptr<tensor<32x32xf16>, 1> -> !tt.ptr<tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1>
      %399 = tt.extract %arg11, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
      tt.prefetch %399 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
      %400 = tt.extract %arg11, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
      tt.prefetch %400 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1>
      %401 = tt.extract %arg11, 0 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
      %402 = tt.advance %401, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1>
      %403 = tt.extract %arg11, 1 : !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf16>, 1>
      %404 = tt.advance %403, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1>
      %405 = tt.glue %402, %404 : !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> -> !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>
      %406 = tt.extract %arg9, 0 : !tt.ptr<tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1> -> !tt.ptr<tensor<32x32xf16>, 1>
      %407 = tt.advance %406, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1>
      %408 = tt.extract %arg9, 1 : !tt.ptr<tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1> -> !tt.ptr<tensor<32x32xf16>, 1>
      %409 = tt.advance %408, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1>
      %410 = tt.glue %407, %409 : !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1> -> !tt.ptr<tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1>
      scf.yield %388, %398, %410, %395, %405 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, !tt.ptr<tensor<32x32xf16, #triton_gpu.dot_op<{opIdx = 0, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<32x64xf16, #triton_gpu.dot_op<{opIdx = 1, parent = #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>}>>, 1>, !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>, !tt.ptr<tensor<8x32xf16, #triton_gpu.warp<{sizePerThread = [8, 32], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>
    }
    %c4_i32_32 = arith.constant 4 : i32
    %91 = arith.divsi %1, %c4_i32_32 : i32
    %c8_i32_33 = arith.constant 8 : i32
    %92 = arith.remsi %91, %c8_i32_33 : i32
    %c32_i32_34 = arith.constant 32 : i32
    %93 = arith.muli %92, %c32_i32_34 : i32
    %94 = arith.addi %93, %12 : i32
    %c4_i32_35 = arith.constant 4 : i32
    %95 = arith.remsi %1, %c4_i32_35 : i32
    %c4_i32_36 = arith.constant 4 : i32
    %96 = arith.remsi %95, %c4_i32_36 : i32
    %c64_i32_37 = arith.constant 64 : i32
    %97 = arith.muli %96, %c64_i32_37 : i32
    %98 = arith.addi %97, %47 : i32
    %99 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%94, %98] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c8_i32_38 = arith.constant 8 : i32
    %100 = arith.addi %94, %c8_i32_38 : i32
    %101 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%100, %98] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c16_i32_39 = arith.constant 16 : i32
    %102 = arith.addi %94, %c16_i32_39 : i32
    %103 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%102, %98] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c24_i32 = arith.constant 24 : i32
    %104 = arith.addi %94, %c24_i32 : i32
    %105 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%104, %98] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c16_i32_40 = arith.constant 16 : i32
    %106 = arith.addi %98, %c16_i32_40 : i32
    %107 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%94, %106] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c8_i32_41 = arith.constant 8 : i32
    %108 = arith.addi %94, %c8_i32_41 : i32
    %c16_i32_42 = arith.constant 16 : i32
    %109 = arith.addi %98, %c16_i32_42 : i32
    %110 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%108, %109] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c16_i32_43 = arith.constant 16 : i32
    %111 = arith.addi %94, %c16_i32_43 : i32
    %c16_i32_44 = arith.constant 16 : i32
    %112 = arith.addi %98, %c16_i32_44 : i32
    %113 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%111, %112] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c24_i32_45 = arith.constant 24 : i32
    %114 = arith.addi %94, %c24_i32_45 : i32
    %c16_i32_46 = arith.constant 16 : i32
    %115 = arith.addi %98, %c16_i32_46 : i32
    %116 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%114, %115] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c32_i32_47 = arith.constant 32 : i32
    %117 = arith.addi %98, %c32_i32_47 : i32
    %118 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%94, %117] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c8_i32_48 = arith.constant 8 : i32
    %119 = arith.addi %94, %c8_i32_48 : i32
    %c32_i32_49 = arith.constant 32 : i32
    %120 = arith.addi %98, %c32_i32_49 : i32
    %121 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%119, %120] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c16_i32_50 = arith.constant 16 : i32
    %122 = arith.addi %94, %c16_i32_50 : i32
    %c32_i32_51 = arith.constant 32 : i32
    %123 = arith.addi %98, %c32_i32_51 : i32
    %124 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%122, %123] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c24_i32_52 = arith.constant 24 : i32
    %125 = arith.addi %94, %c24_i32_52 : i32
    %c32_i32_53 = arith.constant 32 : i32
    %126 = arith.addi %98, %c32_i32_53 : i32
    %127 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%125, %126] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c48_i32 = arith.constant 48 : i32
    %128 = arith.addi %98, %c48_i32 : i32
    %129 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%94, %128] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c8_i32_54 = arith.constant 8 : i32
    %130 = arith.addi %94, %c8_i32_54 : i32
    %c48_i32_55 = arith.constant 48 : i32
    %131 = arith.addi %98, %c48_i32_55 : i32
    %132 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%130, %131] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c16_i32_56 = arith.constant 16 : i32
    %133 = arith.addi %94, %c16_i32_56 : i32
    %c48_i32_57 = arith.constant 48 : i32
    %134 = arith.addi %98, %c48_i32_57 : i32
    %135 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%133, %134] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %c24_i32_58 = arith.constant 24 : i32
    %136 = arith.addi %94, %c24_i32_58 : i32
    %c48_i32_59 = arith.constant 48 : i32
    %137 = arith.addi %98, %c48_i32_59 : i32
    %138 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%136, %137] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1>
    %139 = tt.glue %99, %101, %103, %105, %107, %110, %113, %116, %118, %121, %124, %127, %129, %132, %135, %138 : !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1>, !tt.ptr<tensor<8x16xf32>, 1> -> !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1>
    %140 = tt.extract %139, 0 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %141 = tt.extract %90#0, 0 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %140, %141 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %142 = tt.extract %139, 1 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %143 = tt.extract %90#0, 1 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %142, %143 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %144 = tt.extract %139, 2 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %145 = tt.extract %90#0, 2 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %144, %145 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %146 = tt.extract %139, 3 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %147 = tt.extract %90#0, 3 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %146, %147 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %148 = tt.extract %139, 4 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %149 = tt.extract %90#0, 4 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %148, %149 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %150 = tt.extract %139, 5 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %151 = tt.extract %90#0, 5 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %150, %151 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %152 = tt.extract %139, 6 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %153 = tt.extract %90#0, 6 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %152, %153 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %154 = tt.extract %139, 7 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %155 = tt.extract %90#0, 7 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %154, %155 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %156 = tt.extract %139, 8 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %157 = tt.extract %90#0, 8 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %156, %157 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %158 = tt.extract %139, 9 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %159 = tt.extract %90#0, 9 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %158, %159 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %160 = tt.extract %139, 10 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %161 = tt.extract %90#0, 10 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %160, %161 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %162 = tt.extract %139, 11 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %163 = tt.extract %90#0, 11 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %162, %163 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %164 = tt.extract %139, 12 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %165 = tt.extract %90#0, 12 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %164, %165 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %166 = tt.extract %139, 13 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %167 = tt.extract %90#0, 13 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %166, %167 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %168 = tt.extract %139, 14 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %169 = tt.extract %90#0, 14 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %168, %169 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    %170 = tt.extract %139, 15 : !tt.ptr<tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>>, 1> -> !tt.ptr<tensor<8x16xf32>, 1>
    %171 = tt.extract %90#0, 15 : tensor<32x64xf32, #triton_gpu.warp<{sizePerThread = [32, 64], threadsPerWarp = [1, 1], order = [1, 0]}>> -> tensor<8x16xf32>
    tt.store %170, %171 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>
    tt.return
  }
}
// -----// IR Dump Before TritonGPUPrepareGenxLsc (tritongpu-prepare-genxlsc) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %c7_i32 = arith.constant 7 : i32 loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %c48_i32 = arith.constant 48 : i32 loc(#loc)
    %c24_i32 = arith.constant 24 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<8x16xf32> loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %0 = gpu.subgroup_id : index loc(#loc)
    %1 = arith.index_cast %0 : index to i32 loc(#loc)
    %2 = tt.get_program_id x : i32 loc(#loc)
    %3 = arith.divsi %2, %c64_i32 : i32 loc(#loc)
    %4 = arith.muli %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.subi %c16_i32, %4 : i32 loc(#loc)
    %6 = arith.minsi %5, %c4_i32 : i32 loc(#loc)
    %7 = arith.remsi %2, %6 : i32 loc(#loc)
    %8 = arith.addi %4, %7 : i32 loc(#loc)
    %9 = arith.andi %2, %c63_i32 : i32 loc(#loc)
    %10 = arith.divsi %9, %6 : i32 loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = arith.muli %1, %c8_i32 : i32 loc(#loc)
    %13 = arith.addi %12, %11 : i32 loc(#loc)
    %14 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c0_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %15 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c16_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %14 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %15 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %16 = tt.advance %14, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %17 = tt.advance %15, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %16 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %17 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %18 = tt.advance %16, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %19 = tt.advance %17, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %18 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %19 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %20 = tt.advance %18, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %21 = tt.advance %19, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %22 = arith.divsi %1, %c4_i32 : i32 loc(#loc)
    %23 = arith.andi %22, %c7_i32 : i32 loc(#loc)
    %24 = arith.muli %23, %c32_i32 : i32 loc(#loc)
    %25 = arith.addi %24, %11 : i32 loc(#loc)
    %26 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %27 = arith.muli %10, %c256_i32 : i32 loc(#loc)
    %28 = arith.divsi %1, %c8_i32 : i32 loc(#loc)
    %29 = arith.andi %28, %c3_i32 : i32 loc(#loc)
    %30 = arith.muli %29, %c8_i32 : i32 loc(#loc)
    %31 = arith.andi %1, %c7_i32 : i32 loc(#loc)
    %32 = arith.muli %31, %c32_i32 : i32 loc(#loc)
    %33 = arith.addi %32, %27 : i32 loc(#loc)
    %34 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %33] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %35 = arith.addi %33, %c16_i32 : i32 loc(#loc)
    %36 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %35] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %34 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %36 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %37 = tt.advance %34, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %38 = tt.advance %36, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %37 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %38 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %39 = tt.advance %37, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %40 = tt.advance %38, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %39 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %40 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %41 = tt.advance %39, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %42 = tt.advance %40, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %43 = arith.andi %1, %c3_i32 : i32 loc(#loc)
    %44 = arith.muli %43, %c64_i32 : i32 loc(#loc)
    %45 = arith.addi %44, %27 : i32 loc(#loc)
    %46 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %45] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %47 = arith.addi %45, %c32_i32 : i32 loc(#loc)
    %48 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %47] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %49:23 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %cst, %arg9 = %cst, %arg10 = %cst, %arg11 = %cst, %arg12 = %cst, %arg13 = %cst, %arg14 = %cst, %arg15 = %cst, %arg16 = %cst, %arg17 = %cst, %arg18 = %cst, %arg19 = %cst, %arg20 = %cst, %arg21 = %cst, %arg22 = %cst, %arg23 = %26, %arg24 = %46, %arg25 = %48, %arg26 = %20, %arg27 = %21, %arg28 = %41, %arg29 = %42) -> (tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>)  : i32 {
      gpu.barrier loc(#loc)
      %97 = tt.load %arg23 {DotIdx = 0 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %98 = tt.load %arg24 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %99 = tt.load %arg25 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %100 = tt.extract %97, 0 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %101 = tt.extract %98, 0 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %102 = tt.dot %100, %101, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %103 = tt.extract %97, 4 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %104 = tt.extract %98, 1 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %105 = tt.dot %103, %104, %102 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %106 = tt.glue %105 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %107 = tt.extract %97, 1 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %108 = tt.extract %98, 0 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %109 = tt.dot %107, %108, %arg8 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %110 = tt.extract %97, 5 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %111 = tt.extract %98, 1 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %112 = tt.dot %110, %111, %109 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %113 = tt.glue %112 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %114 = tt.extract %97, 2 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %115 = tt.extract %98, 0 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %116 = tt.dot %114, %115, %arg9 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %117 = tt.extract %97, 6 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %118 = tt.extract %98, 1 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %119 = tt.dot %117, %118, %116 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %120 = tt.glue %119 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %121 = tt.extract %97, 3 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %122 = tt.extract %98, 0 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %123 = tt.dot %121, %122, %arg10 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %124 = tt.extract %97, 7 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %125 = tt.extract %98, 1 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %126 = tt.dot %124, %125, %123 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %127 = tt.glue %126 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %128 = tt.extract %97, 0 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %129 = tt.extract %98, 2 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %130 = tt.dot %128, %129, %arg11 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %131 = tt.extract %97, 4 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %132 = tt.extract %98, 3 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %133 = tt.dot %131, %132, %130 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %134 = tt.glue %133 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %135 = tt.extract %97, 1 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %136 = tt.extract %98, 2 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %137 = tt.dot %135, %136, %arg12 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %138 = tt.extract %97, 5 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %139 = tt.extract %98, 3 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %140 = tt.dot %138, %139, %137 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %141 = tt.glue %140 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %142 = tt.extract %97, 2 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %143 = tt.extract %98, 2 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %144 = tt.dot %142, %143, %arg13 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %145 = tt.extract %97, 6 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %146 = tt.extract %98, 3 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %147 = tt.dot %145, %146, %144 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %148 = tt.glue %147 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %149 = tt.extract %97, 3 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %150 = tt.extract %98, 2 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %151 = tt.dot %149, %150, %arg14 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %152 = tt.extract %97, 7 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %153 = tt.extract %98, 3 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %154 = tt.dot %152, %153, %151 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %155 = tt.glue %154 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %156 = tt.extract %97, 0 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %157 = tt.extract %99, 0 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %158 = tt.dot %156, %157, %arg15 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %159 = tt.extract %97, 4 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %160 = tt.extract %99, 1 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %161 = tt.dot %159, %160, %158 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %162 = tt.glue %161 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %163 = tt.extract %97, 1 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %164 = tt.extract %99, 0 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %165 = tt.dot %163, %164, %arg16 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %166 = tt.extract %97, 5 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %167 = tt.extract %99, 1 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %168 = tt.dot %166, %167, %165 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %169 = tt.glue %168 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %170 = tt.extract %97, 2 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %171 = tt.extract %99, 0 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %172 = tt.dot %170, %171, %arg17 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %173 = tt.extract %97, 6 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %174 = tt.extract %99, 1 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %175 = tt.dot %173, %174, %172 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %176 = tt.glue %175 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %177 = tt.extract %97, 3 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %178 = tt.extract %99, 0 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %179 = tt.dot %177, %178, %arg18 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %180 = tt.extract %97, 7 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %181 = tt.extract %99, 1 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %182 = tt.dot %180, %181, %179 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %183 = tt.glue %182 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %184 = tt.extract %97, 0 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %185 = tt.extract %99, 2 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %186 = tt.dot %184, %185, %arg19 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %187 = tt.extract %97, 4 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %188 = tt.extract %99, 3 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %189 = tt.dot %187, %188, %186 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %190 = tt.glue %189 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %191 = tt.extract %97, 1 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %192 = tt.extract %99, 2 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %193 = tt.dot %191, %192, %arg20 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %194 = tt.extract %97, 5 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %195 = tt.extract %99, 3 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %196 = tt.dot %194, %195, %193 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %197 = tt.glue %196 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %198 = tt.extract %97, 2 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %199 = tt.extract %99, 2 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %200 = tt.dot %198, %199, %arg21 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %201 = tt.extract %97, 6 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %202 = tt.extract %99, 3 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %203 = tt.dot %201, %202, %200 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %204 = tt.glue %203 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %205 = tt.extract %97, 3 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %206 = tt.extract %99, 2 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %207 = tt.dot %205, %206, %arg22 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %208 = tt.extract %97, 7 : tensor<32x32xf16> -> tensor<8x16xf16> loc(#loc)
      %209 = tt.extract %99, 3 : tensor<32x32xf16> -> tensor<16x16xf16> loc(#loc)
      %210 = tt.dot %208, %209, %207 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %211 = tt.glue %210 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      tt.prefetch %arg26 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      tt.prefetch %arg27 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      %212 = tt.advance %arg26, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %213 = tt.advance %arg27, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %214 = tt.advance %arg23, [%c0_i32, %c32_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      tt.prefetch %arg28 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      tt.prefetch %arg29 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      %215 = tt.advance %arg28, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %216 = tt.advance %arg29, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %217 = tt.advance %arg24, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      %218 = tt.advance %arg25, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      scf.yield %106, %113, %120, %127, %134, %141, %148, %155, %162, %169, %176, %183, %190, %197, %204, %211, %214, %217, %218, %212, %213, %215, %216 : tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    } loc(#loc)
    %50 = arith.divsi %1, %c4_i32 : i32 loc(#loc)
    %51 = arith.andi %50, %c7_i32 : i32 loc(#loc)
    %52 = arith.muli %51, %c32_i32 : i32 loc(#loc)
    %53 = arith.addi %52, %11 : i32 loc(#loc)
    %54 = arith.andi %1, %c3_i32 : i32 loc(#loc)
    %55 = arith.muli %54, %c64_i32 : i32 loc(#loc)
    %56 = arith.addi %55, %27 : i32 loc(#loc)
    %57 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %56] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %58 = arith.addi %53, %c8_i32 : i32 loc(#loc)
    %59 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%58, %56] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %60 = arith.addi %53, %c16_i32 : i32 loc(#loc)
    %61 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%60, %56] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %62 = arith.addi %53, %c24_i32 : i32 loc(#loc)
    %63 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%62, %56] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %64 = arith.addi %56, %c16_i32 : i32 loc(#loc)
    %65 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %64] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %66 = arith.addi %53, %c8_i32 : i32 loc(#loc)
    %67 = arith.addi %56, %c16_i32 : i32 loc(#loc)
    %68 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%66, %67] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %69 = arith.addi %53, %c16_i32 : i32 loc(#loc)
    %70 = arith.addi %56, %c16_i32 : i32 loc(#loc)
    %71 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%69, %70] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %72 = arith.addi %53, %c24_i32 : i32 loc(#loc)
    %73 = arith.addi %56, %c16_i32 : i32 loc(#loc)
    %74 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%72, %73] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %75 = arith.addi %56, %c32_i32 : i32 loc(#loc)
    %76 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %75] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %77 = arith.addi %53, %c8_i32 : i32 loc(#loc)
    %78 = arith.addi %56, %c32_i32 : i32 loc(#loc)
    %79 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%77, %78] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %80 = arith.addi %53, %c16_i32 : i32 loc(#loc)
    %81 = arith.addi %56, %c32_i32 : i32 loc(#loc)
    %82 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%80, %81] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %83 = arith.addi %53, %c24_i32 : i32 loc(#loc)
    %84 = arith.addi %56, %c32_i32 : i32 loc(#loc)
    %85 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%83, %84] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %86 = arith.addi %56, %c48_i32 : i32 loc(#loc)
    %87 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %86] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %88 = arith.addi %53, %c8_i32 : i32 loc(#loc)
    %89 = arith.addi %56, %c48_i32 : i32 loc(#loc)
    %90 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%88, %89] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %91 = arith.addi %53, %c16_i32 : i32 loc(#loc)
    %92 = arith.addi %56, %c48_i32 : i32 loc(#loc)
    %93 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%91, %92] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %94 = arith.addi %53, %c24_i32 : i32 loc(#loc)
    %95 = arith.addi %56, %c48_i32 : i32 loc(#loc)
    %96 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%94, %95] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    tt.store %57, %49#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %59, %49#1 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %61, %49#2 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %63, %49#3 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %65, %49#4 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %68, %49#5 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %71, %49#6 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %74, %49#7 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %76, %49#8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %79, %49#9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %82, %49#10 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %85, %49#11 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %87, %49#12 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %90, %49#13 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %93, %49#14 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %96, %49#15 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %c7_i32 = arith.constant 7 : i32 loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %c48_i32 = arith.constant 48 : i32 loc(#loc)
    %c24_i32 = arith.constant 24 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<8x16xf32> loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %0 = gpu.subgroup_id : index loc(#loc)
    %1 = arith.index_cast %0 : index to i32 loc(#loc)
    %2 = tt.get_program_id x : i32 loc(#loc)
    %3 = arith.divsi %2, %c64_i32 : i32 loc(#loc)
    %4 = arith.muli %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.subi %c16_i32, %4 : i32 loc(#loc)
    %6 = arith.minsi %5, %c4_i32 : i32 loc(#loc)
    %7 = arith.remsi %2, %6 : i32 loc(#loc)
    %8 = arith.addi %4, %7 : i32 loc(#loc)
    %9 = arith.andi %2, %c63_i32 : i32 loc(#loc)
    %10 = arith.divsi %9, %6 : i32 loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = arith.muli %1, %c8_i32 : i32 loc(#loc)
    %13 = arith.addi %12, %11 : i32 loc(#loc)
    %14 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c0_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %15 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c16_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %14 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %15 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %16 = tt.advance %14, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %17 = tt.advance %15, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %16 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %17 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %18 = tt.advance %16, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %19 = tt.advance %17, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %18 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %19 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %20 = tt.advance %18, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %21 = tt.advance %19, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %22 = arith.divsi %1, %c4_i32 : i32 loc(#loc)
    %23 = arith.andi %22, %c7_i32 : i32 loc(#loc)
    %24 = arith.muli %23, %c32_i32 : i32 loc(#loc)
    %25 = arith.addi %24, %11 : i32 loc(#loc)
    %26 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %27 = arith.muli %10, %c256_i32 : i32 loc(#loc)
    %28 = arith.divsi %1, %c8_i32 : i32 loc(#loc)
    %29 = arith.andi %28, %c3_i32 : i32 loc(#loc)
    %30 = arith.muli %29, %c8_i32 : i32 loc(#loc)
    %31 = arith.andi %1, %c7_i32 : i32 loc(#loc)
    %32 = arith.muli %31, %c32_i32 : i32 loc(#loc)
    %33 = arith.addi %32, %27 : i32 loc(#loc)
    %34 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %33] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %35 = arith.addi %33, %c16_i32 : i32 loc(#loc)
    %36 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %35] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %34 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %36 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %37 = tt.advance %34, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %38 = tt.advance %36, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %37 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %38 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %39 = tt.advance %37, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %40 = tt.advance %38, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %39 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %40 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %41 = tt.advance %39, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %42 = tt.advance %40, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %43 = arith.andi %1, %c3_i32 : i32 loc(#loc)
    %44 = arith.muli %43, %c64_i32 : i32 loc(#loc)
    %45 = arith.addi %44, %27 : i32 loc(#loc)
    %46 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %45] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %47 = arith.addi %45, %c32_i32 : i32 loc(#loc)
    %48 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %47] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %49:23 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %cst, %arg9 = %cst, %arg10 = %cst, %arg11 = %cst, %arg12 = %cst, %arg13 = %cst, %arg14 = %cst, %arg15 = %cst, %arg16 = %cst, %arg17 = %cst, %arg18 = %cst, %arg19 = %cst, %arg20 = %cst, %arg21 = %cst, %arg22 = %cst, %arg23 = %26, %arg24 = %46, %arg25 = %48, %arg26 = %20, %arg27 = %21, %arg28 = %41, %arg29 = %42) -> (tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>)  : i32 {
      gpu.barrier loc(#loc)
      %97 = tt.load %arg23 {DotIdx = 0 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %98 = tt.load %arg24 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %99 = tt.load %arg25 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %100 = tt.cast %97 : tensor<32x32xf16> to tensor<32x32xi16> loc(#loc)
      %101 = tt.extract %100, 0 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %102 = tt.cast %101 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %103 = tt.cast %98 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
      %104 = tt.extract %103, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %105 = tt.cast %104 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %106 = tt.dot %102, %105, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %107 = tt.extract %100, 4 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %108 = tt.cast %107 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %109 = tt.extract %103, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %110 = tt.cast %109 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %111 = tt.dot %108, %110, %106 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %112 = tt.glue %111 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %113 = tt.extract %100, 1 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %114 = tt.cast %113 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %115 = tt.extract %103, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %116 = tt.cast %115 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %117 = tt.dot %114, %116, %arg8 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %118 = tt.extract %100, 5 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %119 = tt.cast %118 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %120 = tt.extract %103, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %121 = tt.cast %120 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %122 = tt.dot %119, %121, %117 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %123 = tt.glue %122 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %124 = tt.extract %100, 2 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %125 = tt.cast %124 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %126 = tt.extract %103, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %127 = tt.cast %126 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %128 = tt.dot %125, %127, %arg9 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %129 = tt.extract %100, 6 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %130 = tt.cast %129 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %131 = tt.extract %103, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %132 = tt.cast %131 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %133 = tt.dot %130, %132, %128 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %134 = tt.glue %133 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %135 = tt.extract %100, 3 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %136 = tt.cast %135 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %137 = tt.extract %103, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %138 = tt.cast %137 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %139 = tt.dot %136, %138, %arg10 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %140 = tt.extract %100, 7 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %141 = tt.cast %140 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %142 = tt.extract %103, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %143 = tt.cast %142 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %144 = tt.dot %141, %143, %139 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %145 = tt.glue %144 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %146 = tt.extract %100, 0 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %147 = tt.cast %146 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %148 = tt.extract %103, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %149 = tt.cast %148 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %150 = tt.dot %147, %149, %arg11 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %151 = tt.extract %100, 4 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %152 = tt.cast %151 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %153 = tt.extract %103, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %154 = tt.cast %153 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %155 = tt.dot %152, %154, %150 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %156 = tt.glue %155 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %157 = tt.extract %100, 1 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %158 = tt.cast %157 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %159 = tt.extract %103, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %160 = tt.cast %159 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %161 = tt.dot %158, %160, %arg12 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %162 = tt.extract %100, 5 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %163 = tt.cast %162 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %164 = tt.extract %103, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %165 = tt.cast %164 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %166 = tt.dot %163, %165, %161 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %167 = tt.glue %166 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %168 = tt.extract %100, 2 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %169 = tt.cast %168 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %170 = tt.extract %103, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %171 = tt.cast %170 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %172 = tt.dot %169, %171, %arg13 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %173 = tt.extract %100, 6 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %174 = tt.cast %173 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %175 = tt.extract %103, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %176 = tt.cast %175 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %177 = tt.dot %174, %176, %172 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %178 = tt.glue %177 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %179 = tt.extract %100, 3 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %180 = tt.cast %179 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %181 = tt.extract %103, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %182 = tt.cast %181 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %183 = tt.dot %180, %182, %arg14 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %184 = tt.extract %100, 7 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %185 = tt.cast %184 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %186 = tt.extract %103, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %187 = tt.cast %186 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %188 = tt.dot %185, %187, %183 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %189 = tt.glue %188 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %190 = tt.extract %100, 0 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %191 = tt.cast %190 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %192 = tt.cast %99 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
      %193 = tt.extract %192, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %194 = tt.cast %193 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %195 = tt.dot %191, %194, %arg15 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %196 = tt.extract %100, 4 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %197 = tt.cast %196 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %198 = tt.extract %192, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %199 = tt.cast %198 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %200 = tt.dot %197, %199, %195 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %201 = tt.glue %200 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %202 = tt.extract %100, 1 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %203 = tt.cast %202 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %204 = tt.extract %192, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %205 = tt.cast %204 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %206 = tt.dot %203, %205, %arg16 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %207 = tt.extract %100, 5 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %208 = tt.cast %207 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %209 = tt.extract %192, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %210 = tt.cast %209 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %211 = tt.dot %208, %210, %206 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %212 = tt.glue %211 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %213 = tt.extract %100, 2 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %214 = tt.cast %213 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %215 = tt.extract %192, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %216 = tt.cast %215 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %217 = tt.dot %214, %216, %arg17 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %218 = tt.extract %100, 6 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %219 = tt.cast %218 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %220 = tt.extract %192, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %221 = tt.cast %220 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %222 = tt.dot %219, %221, %217 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %223 = tt.glue %222 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %224 = tt.extract %100, 3 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %225 = tt.cast %224 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %226 = tt.extract %192, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %227 = tt.cast %226 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %228 = tt.dot %225, %227, %arg18 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %229 = tt.extract %100, 7 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %230 = tt.cast %229 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %231 = tt.extract %192, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %232 = tt.cast %231 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %233 = tt.dot %230, %232, %228 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %234 = tt.glue %233 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %235 = tt.extract %100, 0 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %236 = tt.cast %235 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %237 = tt.extract %192, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %238 = tt.cast %237 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %239 = tt.dot %236, %238, %arg19 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %240 = tt.extract %100, 4 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %241 = tt.cast %240 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %242 = tt.extract %192, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %243 = tt.cast %242 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %244 = tt.dot %241, %243, %239 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %245 = tt.glue %244 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %246 = tt.extract %100, 1 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %247 = tt.cast %246 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %248 = tt.extract %192, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %249 = tt.cast %248 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %250 = tt.dot %247, %249, %arg20 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %251 = tt.extract %100, 5 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %252 = tt.cast %251 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %253 = tt.extract %192, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %254 = tt.cast %253 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %255 = tt.dot %252, %254, %250 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %256 = tt.glue %255 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %257 = tt.extract %100, 2 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %258 = tt.cast %257 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %259 = tt.extract %192, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %260 = tt.cast %259 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %261 = tt.dot %258, %260, %arg21 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %262 = tt.extract %100, 6 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %263 = tt.cast %262 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %264 = tt.extract %192, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %265 = tt.cast %264 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %266 = tt.dot %263, %265, %261 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %267 = tt.glue %266 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %268 = tt.extract %100, 3 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %269 = tt.cast %268 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %270 = tt.extract %192, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %271 = tt.cast %270 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %272 = tt.dot %269, %271, %arg22 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %273 = tt.extract %100, 7 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %274 = tt.cast %273 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %275 = tt.extract %192, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %276 = tt.cast %275 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %277 = tt.dot %274, %276, %272 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %278 = tt.glue %277 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      tt.prefetch %arg26 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      tt.prefetch %arg27 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      %279 = tt.advance %arg26, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %280 = tt.advance %arg27, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %281 = tt.advance %arg23, [%c0_i32, %c32_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      tt.prefetch %arg28 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      tt.prefetch %arg29 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      %282 = tt.advance %arg28, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %283 = tt.advance %arg29, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %284 = tt.advance %arg24, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      %285 = tt.advance %arg25, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      scf.yield %112, %123, %134, %145, %156, %167, %178, %189, %201, %212, %223, %234, %245, %256, %267, %278, %281, %284, %285, %279, %280, %282, %283 : tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    } loc(#loc)
    %50 = arith.divsi %1, %c4_i32 : i32 loc(#loc)
    %51 = arith.andi %50, %c7_i32 : i32 loc(#loc)
    %52 = arith.muli %51, %c32_i32 : i32 loc(#loc)
    %53 = arith.addi %52, %11 : i32 loc(#loc)
    %54 = arith.andi %1, %c3_i32 : i32 loc(#loc)
    %55 = arith.muli %54, %c64_i32 : i32 loc(#loc)
    %56 = arith.addi %55, %27 : i32 loc(#loc)
    %57 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %56] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %58 = arith.addi %53, %c8_i32 : i32 loc(#loc)
    %59 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%58, %56] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %60 = arith.addi %53, %c16_i32 : i32 loc(#loc)
    %61 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%60, %56] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %62 = arith.addi %53, %c24_i32 : i32 loc(#loc)
    %63 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%62, %56] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %64 = arith.addi %56, %c16_i32 : i32 loc(#loc)
    %65 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %64] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %66 = arith.addi %53, %c8_i32 : i32 loc(#loc)
    %67 = arith.addi %56, %c16_i32 : i32 loc(#loc)
    %68 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%66, %67] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %69 = arith.addi %53, %c16_i32 : i32 loc(#loc)
    %70 = arith.addi %56, %c16_i32 : i32 loc(#loc)
    %71 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%69, %70] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %72 = arith.addi %53, %c24_i32 : i32 loc(#loc)
    %73 = arith.addi %56, %c16_i32 : i32 loc(#loc)
    %74 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%72, %73] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %75 = arith.addi %56, %c32_i32 : i32 loc(#loc)
    %76 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %75] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %77 = arith.addi %53, %c8_i32 : i32 loc(#loc)
    %78 = arith.addi %56, %c32_i32 : i32 loc(#loc)
    %79 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%77, %78] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %80 = arith.addi %53, %c16_i32 : i32 loc(#loc)
    %81 = arith.addi %56, %c32_i32 : i32 loc(#loc)
    %82 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%80, %81] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %83 = arith.addi %53, %c24_i32 : i32 loc(#loc)
    %84 = arith.addi %56, %c32_i32 : i32 loc(#loc)
    %85 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%83, %84] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %86 = arith.addi %56, %c48_i32 : i32 loc(#loc)
    %87 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %86] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %88 = arith.addi %53, %c8_i32 : i32 loc(#loc)
    %89 = arith.addi %56, %c48_i32 : i32 loc(#loc)
    %90 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%88, %89] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %91 = arith.addi %53, %c16_i32 : i32 loc(#loc)
    %92 = arith.addi %56, %c48_i32 : i32 loc(#loc)
    %93 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%91, %92] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %94 = arith.addi %53, %c24_i32 : i32 loc(#loc)
    %95 = arith.addi %56, %c48_i32 : i32 loc(#loc)
    %96 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%94, %95] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    tt.store %57, %49#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %59, %49#1 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %61, %49#2 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %63, %49#3 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %65, %49#4 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %68, %49#5 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %71, %49#6 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %74, %49#7 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %76, %49#8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %79, %49#9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %82, %49#10 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %85, %49#11 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %87, %49#12 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %90, %49#13 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %93, %49#14 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %96, %49#15 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %c7_i32 = arith.constant 7 : i32 loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %c48_i32 = arith.constant 48 : i32 loc(#loc)
    %c24_i32 = arith.constant 24 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<8x16xf32> loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %0 = gpu.subgroup_id : index loc(#loc)
    %1 = arith.index_cast %0 : index to i32 loc(#loc)
    %2 = tt.get_program_id x : i32 loc(#loc)
    %3 = arith.divsi %2, %c64_i32 : i32 loc(#loc)
    %4 = arith.muli %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.subi %c16_i32, %4 : i32 loc(#loc)
    %6 = arith.minsi %5, %c4_i32 : i32 loc(#loc)
    %7 = arith.remsi %2, %6 : i32 loc(#loc)
    %8 = arith.addi %4, %7 : i32 loc(#loc)
    %9 = arith.andi %2, %c63_i32 : i32 loc(#loc)
    %10 = arith.divsi %9, %6 : i32 loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = arith.muli %1, %c8_i32 : i32 loc(#loc)
    %13 = arith.addi %12, %11 : i32 loc(#loc)
    %14 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c0_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %15 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c16_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %14 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %15 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %16 = tt.advance %14, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %17 = tt.advance %15, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %16 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %17 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %18 = tt.advance %16, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %19 = tt.advance %17, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %18 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %19 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %20 = tt.advance %18, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %21 = tt.advance %19, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %22 = arith.divsi %1, %c4_i32 : i32 loc(#loc)
    %23 = arith.andi %22, %c7_i32 : i32 loc(#loc)
    %24 = arith.muli %23, %c32_i32 : i32 loc(#loc)
    %25 = arith.addi %24, %11 : i32 loc(#loc)
    %26 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %27 = arith.muli %10, %c256_i32 : i32 loc(#loc)
    %28 = arith.divsi %1, %c8_i32 : i32 loc(#loc)
    %29 = arith.andi %28, %c3_i32 : i32 loc(#loc)
    %30 = arith.muli %29, %c8_i32 : i32 loc(#loc)
    %31 = arith.andi %1, %c7_i32 : i32 loc(#loc)
    %32 = arith.muli %31, %c32_i32 : i32 loc(#loc)
    %33 = arith.addi %32, %27 : i32 loc(#loc)
    %34 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %33] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %35 = arith.addi %33, %c16_i32 : i32 loc(#loc)
    %36 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %35] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %34 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %36 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %37 = tt.advance %34, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %38 = tt.advance %36, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %37 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %38 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %39 = tt.advance %37, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %40 = tt.advance %38, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %39 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %40 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %41 = tt.advance %39, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %42 = tt.advance %40, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %43 = arith.andi %1, %c3_i32 : i32 loc(#loc)
    %44 = arith.muli %43, %c64_i32 : i32 loc(#loc)
    %45 = arith.addi %44, %27 : i32 loc(#loc)
    %46 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %45] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %47 = arith.addi %45, %c32_i32 : i32 loc(#loc)
    %48 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %47] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %49:23 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %cst, %arg9 = %cst, %arg10 = %cst, %arg11 = %cst, %arg12 = %cst, %arg13 = %cst, %arg14 = %cst, %arg15 = %cst, %arg16 = %cst, %arg17 = %cst, %arg18 = %cst, %arg19 = %cst, %arg20 = %cst, %arg21 = %cst, %arg22 = %cst, %arg23 = %26, %arg24 = %46, %arg25 = %48, %arg26 = %20, %arg27 = %21, %arg28 = %41, %arg29 = %42) -> (tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>)  : i32 {
      gpu.barrier loc(#loc)
      %71 = tt.load %arg23 {DotIdx = 0 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %72 = tt.load %arg24 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %73 = tt.load %arg25 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %74 = tt.cast %71 : tensor<32x32xf16> to tensor<32x32xi16> loc(#loc)
      %75 = tt.extract %74, 0 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %76 = tt.cast %75 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %77 = tt.cast %72 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
      %78 = tt.extract %77, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %79 = tt.cast %78 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %80 = tt.dot %76, %79, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %81 = tt.extract %74, 4 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %82 = tt.cast %81 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %83 = tt.extract %77, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %84 = tt.cast %83 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %85 = tt.dot %82, %84, %80 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %86 = tt.glue %85 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %87 = tt.extract %74, 1 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %88 = tt.cast %87 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %89 = tt.dot %88, %79, %arg8 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %90 = tt.extract %74, 5 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %91 = tt.cast %90 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %92 = tt.dot %91, %84, %89 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %93 = tt.glue %92 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %94 = tt.extract %74, 2 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %95 = tt.cast %94 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %96 = tt.dot %95, %79, %arg9 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %97 = tt.extract %74, 6 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %98 = tt.cast %97 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %99 = tt.dot %98, %84, %96 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %100 = tt.glue %99 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %101 = tt.extract %74, 3 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %102 = tt.cast %101 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %103 = tt.dot %102, %79, %arg10 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %104 = tt.extract %74, 7 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %105 = tt.cast %104 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %106 = tt.dot %105, %84, %103 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %107 = tt.glue %106 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %108 = tt.extract %77, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %109 = tt.cast %108 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %110 = tt.dot %76, %109, %arg11 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %111 = tt.extract %77, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %112 = tt.cast %111 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %113 = tt.dot %82, %112, %110 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %114 = tt.glue %113 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %115 = tt.dot %88, %109, %arg12 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %116 = tt.dot %91, %112, %115 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %117 = tt.glue %116 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %118 = tt.dot %95, %109, %arg13 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %119 = tt.dot %98, %112, %118 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %120 = tt.glue %119 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %121 = tt.dot %102, %109, %arg14 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %122 = tt.dot %105, %112, %121 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %123 = tt.glue %122 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %124 = tt.cast %73 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
      %125 = tt.extract %124, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %126 = tt.cast %125 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %127 = tt.dot %76, %126, %arg15 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %128 = tt.extract %124, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %129 = tt.cast %128 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %130 = tt.dot %82, %129, %127 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %131 = tt.glue %130 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %132 = tt.dot %88, %126, %arg16 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %133 = tt.dot %91, %129, %132 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %134 = tt.glue %133 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %135 = tt.dot %95, %126, %arg17 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %136 = tt.dot %98, %129, %135 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %137 = tt.glue %136 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %138 = tt.dot %102, %126, %arg18 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %139 = tt.dot %105, %129, %138 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %140 = tt.glue %139 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %141 = tt.extract %124, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %142 = tt.cast %141 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %143 = tt.dot %76, %142, %arg19 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %144 = tt.extract %124, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %145 = tt.cast %144 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %146 = tt.dot %82, %145, %143 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %147 = tt.glue %146 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %148 = tt.dot %88, %142, %arg20 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %149 = tt.dot %91, %145, %148 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %150 = tt.glue %149 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %151 = tt.dot %95, %142, %arg21 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %152 = tt.dot %98, %145, %151 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %153 = tt.glue %152 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %154 = tt.dot %102, %142, %arg22 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %155 = tt.dot %105, %145, %154 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %156 = tt.glue %155 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      tt.prefetch %arg26 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      tt.prefetch %arg27 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      %157 = tt.advance %arg26, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %158 = tt.advance %arg27, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %159 = tt.advance %arg23, [%c0_i32, %c32_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      tt.prefetch %arg28 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      tt.prefetch %arg29 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      %160 = tt.advance %arg28, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %161 = tt.advance %arg29, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %162 = tt.advance %arg24, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      %163 = tt.advance %arg25, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      scf.yield %86, %93, %100, %107, %114, %117, %120, %123, %131, %134, %137, %140, %147, %150, %153, %156, %159, %162, %163, %157, %158, %160, %161 : tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    } loc(#loc)
    %50 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %51 = arith.addi %25, %c8_i32 : i32 loc(#loc)
    %52 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %53 = arith.addi %25, %c16_i32 : i32 loc(#loc)
    %54 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %55 = arith.addi %25, %c24_i32 : i32 loc(#loc)
    %56 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %57 = arith.addi %45, %c16_i32 : i32 loc(#loc)
    %58 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %59 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %60 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %61 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %62 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %63 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %64 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %65 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %66 = arith.addi %45, %c48_i32 : i32 loc(#loc)
    %67 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %68 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %69 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %70 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    tt.store %50, %49#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %52, %49#1 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %54, %49#2 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %56, %49#3 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %58, %49#4 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %59, %49#5 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %60, %49#6 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %61, %49#7 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %62, %49#8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %63, %49#9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %64, %49#10 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %65, %49#11 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %67, %49#12 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %68, %49#13 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %69, %49#14 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %70, %49#15 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before SymbolDCE (symbol-dce) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %c7_i32 = arith.constant 7 : i32 loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %c48_i32 = arith.constant 48 : i32 loc(#loc)
    %c24_i32 = arith.constant 24 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<8x16xf32> loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %0 = gpu.subgroup_id : index loc(#loc)
    %1 = arith.index_cast %0 : index to i32 loc(#loc)
    %2 = tt.get_program_id x : i32 loc(#loc)
    %3 = arith.divsi %2, %c64_i32 : i32 loc(#loc)
    %4 = arith.muli %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.subi %c16_i32, %4 : i32 loc(#loc)
    %6 = arith.minsi %5, %c4_i32 : i32 loc(#loc)
    %7 = arith.remsi %2, %6 : i32 loc(#loc)
    %8 = arith.addi %4, %7 : i32 loc(#loc)
    %9 = arith.andi %2, %c63_i32 : i32 loc(#loc)
    %10 = arith.divsi %9, %6 : i32 loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = arith.muli %1, %c8_i32 : i32 loc(#loc)
    %13 = arith.addi %12, %11 : i32 loc(#loc)
    %14 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c0_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %15 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c16_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %14 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %15 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %16 = tt.advance %14, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %17 = tt.advance %15, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %16 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %17 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %18 = tt.advance %16, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %19 = tt.advance %17, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %18 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %19 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %20 = tt.advance %18, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %21 = tt.advance %19, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %22 = arith.divsi %1, %c4_i32 : i32 loc(#loc)
    %23 = arith.andi %22, %c7_i32 : i32 loc(#loc)
    %24 = arith.muli %23, %c32_i32 : i32 loc(#loc)
    %25 = arith.addi %24, %11 : i32 loc(#loc)
    %26 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %27 = arith.muli %10, %c256_i32 : i32 loc(#loc)
    %28 = arith.divsi %1, %c8_i32 : i32 loc(#loc)
    %29 = arith.andi %28, %c3_i32 : i32 loc(#loc)
    %30 = arith.muli %29, %c8_i32 : i32 loc(#loc)
    %31 = arith.andi %1, %c7_i32 : i32 loc(#loc)
    %32 = arith.muli %31, %c32_i32 : i32 loc(#loc)
    %33 = arith.addi %32, %27 : i32 loc(#loc)
    %34 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %33] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %35 = arith.addi %33, %c16_i32 : i32 loc(#loc)
    %36 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %35] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %34 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %36 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %37 = tt.advance %34, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %38 = tt.advance %36, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %37 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %38 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %39 = tt.advance %37, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %40 = tt.advance %38, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %39 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %40 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %41 = tt.advance %39, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %42 = tt.advance %40, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %43 = arith.andi %1, %c3_i32 : i32 loc(#loc)
    %44 = arith.muli %43, %c64_i32 : i32 loc(#loc)
    %45 = arith.addi %44, %27 : i32 loc(#loc)
    %46 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %45] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %47 = arith.addi %45, %c32_i32 : i32 loc(#loc)
    %48 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %47] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %49:23 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %cst, %arg9 = %cst, %arg10 = %cst, %arg11 = %cst, %arg12 = %cst, %arg13 = %cst, %arg14 = %cst, %arg15 = %cst, %arg16 = %cst, %arg17 = %cst, %arg18 = %cst, %arg19 = %cst, %arg20 = %cst, %arg21 = %cst, %arg22 = %cst, %arg23 = %26, %arg24 = %46, %arg25 = %48, %arg26 = %20, %arg27 = %21, %arg28 = %41, %arg29 = %42) -> (tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>)  : i32 {
      gpu.barrier loc(#loc)
      %71 = tt.load %arg23 {DotIdx = 0 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %72 = tt.load %arg24 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %73 = tt.load %arg25 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %74 = tt.cast %71 : tensor<32x32xf16> to tensor<32x32xi16> loc(#loc)
      %75 = tt.extract %74, 0 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %76 = tt.cast %75 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %77 = tt.cast %72 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
      %78 = tt.extract %77, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %79 = tt.cast %78 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %80 = tt.dot %76, %79, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %81 = tt.extract %74, 4 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %82 = tt.cast %81 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %83 = tt.extract %77, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %84 = tt.cast %83 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %85 = tt.dot %82, %84, %80 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %86 = tt.glue %85 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %87 = tt.extract %74, 1 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %88 = tt.cast %87 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %89 = tt.dot %88, %79, %arg8 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %90 = tt.extract %74, 5 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %91 = tt.cast %90 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %92 = tt.dot %91, %84, %89 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %93 = tt.glue %92 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %94 = tt.extract %74, 2 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %95 = tt.cast %94 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %96 = tt.dot %95, %79, %arg9 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %97 = tt.extract %74, 6 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %98 = tt.cast %97 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %99 = tt.dot %98, %84, %96 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %100 = tt.glue %99 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %101 = tt.extract %74, 3 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %102 = tt.cast %101 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %103 = tt.dot %102, %79, %arg10 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %104 = tt.extract %74, 7 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %105 = tt.cast %104 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %106 = tt.dot %105, %84, %103 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %107 = tt.glue %106 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %108 = tt.extract %77, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %109 = tt.cast %108 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %110 = tt.dot %76, %109, %arg11 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %111 = tt.extract %77, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %112 = tt.cast %111 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %113 = tt.dot %82, %112, %110 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %114 = tt.glue %113 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %115 = tt.dot %88, %109, %arg12 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %116 = tt.dot %91, %112, %115 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %117 = tt.glue %116 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %118 = tt.dot %95, %109, %arg13 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %119 = tt.dot %98, %112, %118 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %120 = tt.glue %119 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %121 = tt.dot %102, %109, %arg14 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %122 = tt.dot %105, %112, %121 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %123 = tt.glue %122 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %124 = tt.cast %73 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
      %125 = tt.extract %124, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %126 = tt.cast %125 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %127 = tt.dot %76, %126, %arg15 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %128 = tt.extract %124, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %129 = tt.cast %128 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %130 = tt.dot %82, %129, %127 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %131 = tt.glue %130 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %132 = tt.dot %88, %126, %arg16 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %133 = tt.dot %91, %129, %132 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %134 = tt.glue %133 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %135 = tt.dot %95, %126, %arg17 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %136 = tt.dot %98, %129, %135 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %137 = tt.glue %136 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %138 = tt.dot %102, %126, %arg18 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %139 = tt.dot %105, %129, %138 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %140 = tt.glue %139 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %141 = tt.extract %124, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %142 = tt.cast %141 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %143 = tt.dot %76, %142, %arg19 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %144 = tt.extract %124, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %145 = tt.cast %144 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %146 = tt.dot %82, %145, %143 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %147 = tt.glue %146 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %148 = tt.dot %88, %142, %arg20 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %149 = tt.dot %91, %145, %148 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %150 = tt.glue %149 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %151 = tt.dot %95, %142, %arg21 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %152 = tt.dot %98, %145, %151 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %153 = tt.glue %152 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %154 = tt.dot %102, %142, %arg22 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %155 = tt.dot %105, %145, %154 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %156 = tt.glue %155 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      tt.prefetch %arg26 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      tt.prefetch %arg27 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      %157 = tt.advance %arg26, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %158 = tt.advance %arg27, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %159 = tt.advance %arg23, [%c0_i32, %c32_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      tt.prefetch %arg28 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      tt.prefetch %arg29 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      %160 = tt.advance %arg28, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %161 = tt.advance %arg29, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %162 = tt.advance %arg24, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      %163 = tt.advance %arg25, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      scf.yield %86, %93, %100, %107, %114, %117, %120, %123, %131, %134, %137, %140, %147, %150, %153, %156, %159, %162, %163, %157, %158, %160, %161 : tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    } loc(#loc)
    %50 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %51 = arith.addi %25, %c8_i32 : i32 loc(#loc)
    %52 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %53 = arith.addi %25, %c16_i32 : i32 loc(#loc)
    %54 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %55 = arith.addi %25, %c24_i32 : i32 loc(#loc)
    %56 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %57 = arith.addi %45, %c16_i32 : i32 loc(#loc)
    %58 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %59 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %60 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %61 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %62 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %63 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %64 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %65 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %66 = arith.addi %45, %c48_i32 : i32 loc(#loc)
    %67 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %68 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %69 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %70 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    tt.store %50, %49#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %52, %49#1 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %54, %49#2 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %56, %49#3 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %58, %49#4 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %59, %49#5 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %60, %49#6 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %61, %49#7 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %62, %49#8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %63, %49#9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %64, %49#10 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %65, %49#11 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %67, %49#12 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %68, %49#13 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %69, %49#14 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %70, %49#15 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before DecomposeUnsupportedConversions (decompose-unsupported-conversions) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %c7_i32 = arith.constant 7 : i32 loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %c48_i32 = arith.constant 48 : i32 loc(#loc)
    %c24_i32 = arith.constant 24 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<8x16xf32> loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %0 = gpu.subgroup_id : index loc(#loc)
    %1 = arith.index_cast %0 : index to i32 loc(#loc)
    %2 = tt.get_program_id x : i32 loc(#loc)
    %3 = arith.divsi %2, %c64_i32 : i32 loc(#loc)
    %4 = arith.muli %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.subi %c16_i32, %4 : i32 loc(#loc)
    %6 = arith.minsi %5, %c4_i32 : i32 loc(#loc)
    %7 = arith.remsi %2, %6 : i32 loc(#loc)
    %8 = arith.addi %4, %7 : i32 loc(#loc)
    %9 = arith.andi %2, %c63_i32 : i32 loc(#loc)
    %10 = arith.divsi %9, %6 : i32 loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = arith.muli %1, %c8_i32 : i32 loc(#loc)
    %13 = arith.addi %12, %11 : i32 loc(#loc)
    %14 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c0_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %15 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c16_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %14 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %15 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %16 = tt.advance %14, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %17 = tt.advance %15, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %16 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %17 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %18 = tt.advance %16, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %19 = tt.advance %17, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %18 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %19 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %20 = tt.advance %18, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %21 = tt.advance %19, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %22 = arith.divsi %1, %c4_i32 : i32 loc(#loc)
    %23 = arith.andi %22, %c7_i32 : i32 loc(#loc)
    %24 = arith.muli %23, %c32_i32 : i32 loc(#loc)
    %25 = arith.addi %24, %11 : i32 loc(#loc)
    %26 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %27 = arith.muli %10, %c256_i32 : i32 loc(#loc)
    %28 = arith.divsi %1, %c8_i32 : i32 loc(#loc)
    %29 = arith.andi %28, %c3_i32 : i32 loc(#loc)
    %30 = arith.muli %29, %c8_i32 : i32 loc(#loc)
    %31 = arith.andi %1, %c7_i32 : i32 loc(#loc)
    %32 = arith.muli %31, %c32_i32 : i32 loc(#loc)
    %33 = arith.addi %32, %27 : i32 loc(#loc)
    %34 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %33] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %35 = arith.addi %33, %c16_i32 : i32 loc(#loc)
    %36 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %35] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %34 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %36 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %37 = tt.advance %34, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %38 = tt.advance %36, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %37 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %38 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %39 = tt.advance %37, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %40 = tt.advance %38, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %39 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %40 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %41 = tt.advance %39, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %42 = tt.advance %40, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %43 = arith.andi %1, %c3_i32 : i32 loc(#loc)
    %44 = arith.muli %43, %c64_i32 : i32 loc(#loc)
    %45 = arith.addi %44, %27 : i32 loc(#loc)
    %46 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %45] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %47 = arith.addi %45, %c32_i32 : i32 loc(#loc)
    %48 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %47] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %49:23 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %cst, %arg9 = %cst, %arg10 = %cst, %arg11 = %cst, %arg12 = %cst, %arg13 = %cst, %arg14 = %cst, %arg15 = %cst, %arg16 = %cst, %arg17 = %cst, %arg18 = %cst, %arg19 = %cst, %arg20 = %cst, %arg21 = %cst, %arg22 = %cst, %arg23 = %26, %arg24 = %46, %arg25 = %48, %arg26 = %20, %arg27 = %21, %arg28 = %41, %arg29 = %42) -> (tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>)  : i32 {
      gpu.barrier loc(#loc)
      %71 = tt.load %arg23 {DotIdx = 0 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %72 = tt.load %arg24 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %73 = tt.load %arg25 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %74 = tt.cast %71 : tensor<32x32xf16> to tensor<32x32xi16> loc(#loc)
      %75 = tt.extract %74, 0 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %76 = tt.cast %75 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %77 = tt.cast %72 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
      %78 = tt.extract %77, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %79 = tt.cast %78 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %80 = tt.dot %76, %79, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %81 = tt.extract %74, 4 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %82 = tt.cast %81 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %83 = tt.extract %77, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %84 = tt.cast %83 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %85 = tt.dot %82, %84, %80 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %86 = tt.glue %85 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %87 = tt.extract %74, 1 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %88 = tt.cast %87 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %89 = tt.dot %88, %79, %arg8 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %90 = tt.extract %74, 5 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %91 = tt.cast %90 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %92 = tt.dot %91, %84, %89 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %93 = tt.glue %92 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %94 = tt.extract %74, 2 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %95 = tt.cast %94 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %96 = tt.dot %95, %79, %arg9 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %97 = tt.extract %74, 6 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %98 = tt.cast %97 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %99 = tt.dot %98, %84, %96 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %100 = tt.glue %99 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %101 = tt.extract %74, 3 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %102 = tt.cast %101 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %103 = tt.dot %102, %79, %arg10 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %104 = tt.extract %74, 7 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %105 = tt.cast %104 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %106 = tt.dot %105, %84, %103 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %107 = tt.glue %106 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %108 = tt.extract %77, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %109 = tt.cast %108 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %110 = tt.dot %76, %109, %arg11 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %111 = tt.extract %77, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %112 = tt.cast %111 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %113 = tt.dot %82, %112, %110 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %114 = tt.glue %113 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %115 = tt.dot %88, %109, %arg12 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %116 = tt.dot %91, %112, %115 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %117 = tt.glue %116 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %118 = tt.dot %95, %109, %arg13 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %119 = tt.dot %98, %112, %118 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %120 = tt.glue %119 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %121 = tt.dot %102, %109, %arg14 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %122 = tt.dot %105, %112, %121 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %123 = tt.glue %122 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %124 = tt.cast %73 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
      %125 = tt.extract %124, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %126 = tt.cast %125 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %127 = tt.dot %76, %126, %arg15 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %128 = tt.extract %124, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %129 = tt.cast %128 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %130 = tt.dot %82, %129, %127 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %131 = tt.glue %130 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %132 = tt.dot %88, %126, %arg16 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %133 = tt.dot %91, %129, %132 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %134 = tt.glue %133 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %135 = tt.dot %95, %126, %arg17 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %136 = tt.dot %98, %129, %135 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %137 = tt.glue %136 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %138 = tt.dot %102, %126, %arg18 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %139 = tt.dot %105, %129, %138 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %140 = tt.glue %139 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %141 = tt.extract %124, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %142 = tt.cast %141 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %143 = tt.dot %76, %142, %arg19 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %144 = tt.extract %124, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %145 = tt.cast %144 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %146 = tt.dot %82, %145, %143 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %147 = tt.glue %146 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %148 = tt.dot %88, %142, %arg20 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %149 = tt.dot %91, %145, %148 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %150 = tt.glue %149 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %151 = tt.dot %95, %142, %arg21 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %152 = tt.dot %98, %145, %151 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %153 = tt.glue %152 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %154 = tt.dot %102, %142, %arg22 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %155 = tt.dot %105, %145, %154 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %156 = tt.glue %155 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      tt.prefetch %arg26 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      tt.prefetch %arg27 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      %157 = tt.advance %arg26, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %158 = tt.advance %arg27, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %159 = tt.advance %arg23, [%c0_i32, %c32_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      tt.prefetch %arg28 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      tt.prefetch %arg29 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      %160 = tt.advance %arg28, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %161 = tt.advance %arg29, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %162 = tt.advance %arg24, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      %163 = tt.advance %arg25, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      scf.yield %86, %93, %100, %107, %114, %117, %120, %123, %131, %134, %137, %140, %147, %150, %153, %156, %159, %162, %163, %157, %158, %160, %161 : tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    } loc(#loc)
    %50 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %51 = arith.addi %25, %c8_i32 : i32 loc(#loc)
    %52 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %53 = arith.addi %25, %c16_i32 : i32 loc(#loc)
    %54 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %55 = arith.addi %25, %c24_i32 : i32 loc(#loc)
    %56 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %57 = arith.addi %45, %c16_i32 : i32 loc(#loc)
    %58 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %59 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %60 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %61 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %62 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %63 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %64 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %65 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %66 = arith.addi %45, %c48_i32 : i32 loc(#loc)
    %67 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %68 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %69 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %70 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    tt.store %50, %49#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %52, %49#1 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %54, %49#2 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %56, %49#3 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %58, %49#4 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %59, %49#5 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %60, %49#6 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %61, %49#7 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %62, %49#8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %63, %49#9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %64, %49#10 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %65, %49#11 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %67, %49#12 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %68, %49#13 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %69, %49#14 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %70, %49#15 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before SCFToControlFlow (convert-scf-to-cf) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %c7_i32 = arith.constant 7 : i32 loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %c48_i32 = arith.constant 48 : i32 loc(#loc)
    %c24_i32 = arith.constant 24 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<8x16xf32> loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %0 = gpu.subgroup_id : index loc(#loc)
    %1 = arith.index_cast %0 : index to i32 loc(#loc)
    %2 = tt.get_program_id x : i32 loc(#loc)
    %3 = arith.divsi %2, %c64_i32 : i32 loc(#loc)
    %4 = arith.muli %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.subi %c16_i32, %4 : i32 loc(#loc)
    %6 = arith.minsi %5, %c4_i32 : i32 loc(#loc)
    %7 = arith.remsi %2, %6 : i32 loc(#loc)
    %8 = arith.addi %4, %7 : i32 loc(#loc)
    %9 = arith.andi %2, %c63_i32 : i32 loc(#loc)
    %10 = arith.divsi %9, %6 : i32 loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = arith.muli %1, %c8_i32 : i32 loc(#loc)
    %13 = arith.addi %12, %11 : i32 loc(#loc)
    %14 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c0_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %15 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c16_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %14 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %15 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %16 = tt.advance %14, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %17 = tt.advance %15, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %16 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %17 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %18 = tt.advance %16, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %19 = tt.advance %17, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %18 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %19 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %20 = tt.advance %18, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %21 = tt.advance %19, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %22 = arith.divsi %1, %c4_i32 : i32 loc(#loc)
    %23 = arith.andi %22, %c7_i32 : i32 loc(#loc)
    %24 = arith.muli %23, %c32_i32 : i32 loc(#loc)
    %25 = arith.addi %24, %11 : i32 loc(#loc)
    %26 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %27 = arith.muli %10, %c256_i32 : i32 loc(#loc)
    %28 = arith.divsi %1, %c8_i32 : i32 loc(#loc)
    %29 = arith.andi %28, %c3_i32 : i32 loc(#loc)
    %30 = arith.muli %29, %c8_i32 : i32 loc(#loc)
    %31 = arith.andi %1, %c7_i32 : i32 loc(#loc)
    %32 = arith.muli %31, %c32_i32 : i32 loc(#loc)
    %33 = arith.addi %32, %27 : i32 loc(#loc)
    %34 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %33] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %35 = arith.addi %33, %c16_i32 : i32 loc(#loc)
    %36 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %35] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %34 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %36 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %37 = tt.advance %34, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %38 = tt.advance %36, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %37 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %38 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %39 = tt.advance %37, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %40 = tt.advance %38, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %39 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %40 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %41 = tt.advance %39, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %42 = tt.advance %40, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %43 = arith.andi %1, %c3_i32 : i32 loc(#loc)
    %44 = arith.muli %43, %c64_i32 : i32 loc(#loc)
    %45 = arith.addi %44, %27 : i32 loc(#loc)
    %46 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %45] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %47 = arith.addi %45, %c32_i32 : i32 loc(#loc)
    %48 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %47] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %49:23 = scf.for %arg6 = %c0_i32 to %c4096_i32 step %c32_i32 iter_args(%arg7 = %cst, %arg8 = %cst, %arg9 = %cst, %arg10 = %cst, %arg11 = %cst, %arg12 = %cst, %arg13 = %cst, %arg14 = %cst, %arg15 = %cst, %arg16 = %cst, %arg17 = %cst, %arg18 = %cst, %arg19 = %cst, %arg20 = %cst, %arg21 = %cst, %arg22 = %cst, %arg23 = %26, %arg24 = %46, %arg25 = %48, %arg26 = %20, %arg27 = %21, %arg28 = %41, %arg29 = %42) -> (tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>)  : i32 {
      gpu.barrier loc(#loc)
      %71 = tt.load %arg23 {DotIdx = 0 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %72 = tt.load %arg24 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %73 = tt.load %arg25 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
      %74 = tt.cast %71 : tensor<32x32xf16> to tensor<32x32xi16> loc(#loc)
      %75 = tt.extract %74, 0 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %76 = tt.cast %75 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %77 = tt.cast %72 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
      %78 = tt.extract %77, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %79 = tt.cast %78 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %80 = tt.dot %76, %79, %arg7 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %81 = tt.extract %74, 4 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %82 = tt.cast %81 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %83 = tt.extract %77, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %84 = tt.cast %83 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %85 = tt.dot %82, %84, %80 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %86 = tt.glue %85 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %87 = tt.extract %74, 1 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %88 = tt.cast %87 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %89 = tt.dot %88, %79, %arg8 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %90 = tt.extract %74, 5 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %91 = tt.cast %90 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %92 = tt.dot %91, %84, %89 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %93 = tt.glue %92 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %94 = tt.extract %74, 2 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %95 = tt.cast %94 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %96 = tt.dot %95, %79, %arg9 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %97 = tt.extract %74, 6 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %98 = tt.cast %97 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %99 = tt.dot %98, %84, %96 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %100 = tt.glue %99 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %101 = tt.extract %74, 3 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %102 = tt.cast %101 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %103 = tt.dot %102, %79, %arg10 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %104 = tt.extract %74, 7 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
      %105 = tt.cast %104 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
      %106 = tt.dot %105, %84, %103 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %107 = tt.glue %106 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %108 = tt.extract %77, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %109 = tt.cast %108 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %110 = tt.dot %76, %109, %arg11 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %111 = tt.extract %77, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %112 = tt.cast %111 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %113 = tt.dot %82, %112, %110 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %114 = tt.glue %113 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %115 = tt.dot %88, %109, %arg12 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %116 = tt.dot %91, %112, %115 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %117 = tt.glue %116 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %118 = tt.dot %95, %109, %arg13 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %119 = tt.dot %98, %112, %118 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %120 = tt.glue %119 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %121 = tt.dot %102, %109, %arg14 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %122 = tt.dot %105, %112, %121 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %123 = tt.glue %122 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %124 = tt.cast %73 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
      %125 = tt.extract %124, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %126 = tt.cast %125 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %127 = tt.dot %76, %126, %arg15 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %128 = tt.extract %124, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %129 = tt.cast %128 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %130 = tt.dot %82, %129, %127 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %131 = tt.glue %130 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %132 = tt.dot %88, %126, %arg16 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %133 = tt.dot %91, %129, %132 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %134 = tt.glue %133 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %135 = tt.dot %95, %126, %arg17 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %136 = tt.dot %98, %129, %135 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %137 = tt.glue %136 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %138 = tt.dot %102, %126, %arg18 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %139 = tt.dot %105, %129, %138 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %140 = tt.glue %139 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %141 = tt.extract %124, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %142 = tt.cast %141 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %143 = tt.dot %76, %142, %arg19 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %144 = tt.extract %124, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
      %145 = tt.cast %144 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
      %146 = tt.dot %82, %145, %143 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %147 = tt.glue %146 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %148 = tt.dot %88, %142, %arg20 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %149 = tt.dot %91, %145, %148 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %150 = tt.glue %149 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %151 = tt.dot %95, %142, %arg21 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %152 = tt.dot %98, %145, %151 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %153 = tt.glue %152 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      %154 = tt.dot %102, %142, %arg22 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %155 = tt.dot %105, %145, %154 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
      %156 = tt.glue %155 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
      tt.prefetch %arg26 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      tt.prefetch %arg27 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      %157 = tt.advance %arg26, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %158 = tt.advance %arg27, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %159 = tt.advance %arg23, [%c0_i32, %c32_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      tt.prefetch %arg28 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      tt.prefetch %arg29 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
      %160 = tt.advance %arg28, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %161 = tt.advance %arg29, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
      %162 = tt.advance %arg24, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      %163 = tt.advance %arg25, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
      scf.yield %86, %93, %100, %107, %114, %117, %120, %123, %131, %134, %137, %140, %147, %150, %153, %156, %159, %162, %163, %157, %158, %160, %161 : tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    } loc(#loc)
    %50 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %51 = arith.addi %25, %c8_i32 : i32 loc(#loc)
    %52 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %53 = arith.addi %25, %c16_i32 : i32 loc(#loc)
    %54 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %55 = arith.addi %25, %c24_i32 : i32 loc(#loc)
    %56 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %57 = arith.addi %45, %c16_i32 : i32 loc(#loc)
    %58 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %59 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %60 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %61 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %57] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %62 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %63 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %64 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %65 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %66 = arith.addi %45, %c48_i32 : i32 loc(#loc)
    %67 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %68 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%51, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %69 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%53, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %70 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%55, %66] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    tt.store %50, %49#0 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %52, %49#1 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %54, %49#2 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %56, %49#3 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %58, %49#4 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %59, %49#5 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %60, %49#6 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %61, %49#7 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %62, %49#8 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %63, %49#9 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %64, %49#10 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %65, %49#11 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %67, %49#12 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %68, %49#13 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %69, %49#14 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %70, %49#15 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before ConvertIndexToLLVMPass (convert-index-to-llvm) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %c7_i32 = arith.constant 7 : i32 loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %c48_i32 = arith.constant 48 : i32 loc(#loc)
    %c24_i32 = arith.constant 24 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<8x16xf32> loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %0 = gpu.subgroup_id : index loc(#loc)
    %1 = arith.index_cast %0 : index to i32 loc(#loc)
    %2 = tt.get_program_id x : i32 loc(#loc)
    %3 = arith.divsi %2, %c64_i32 : i32 loc(#loc)
    %4 = arith.muli %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.subi %c16_i32, %4 : i32 loc(#loc)
    %6 = arith.minsi %5, %c4_i32 : i32 loc(#loc)
    %7 = arith.remsi %2, %6 : i32 loc(#loc)
    %8 = arith.addi %4, %7 : i32 loc(#loc)
    %9 = arith.andi %2, %c63_i32 : i32 loc(#loc)
    %10 = arith.divsi %9, %6 : i32 loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = arith.muli %1, %c8_i32 : i32 loc(#loc)
    %13 = arith.addi %12, %11 : i32 loc(#loc)
    %14 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c0_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %15 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c16_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %14 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %15 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %16 = tt.advance %14, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %17 = tt.advance %15, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %16 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %17 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %18 = tt.advance %16, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %19 = tt.advance %17, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %18 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %19 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %20 = tt.advance %18, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %21 = tt.advance %19, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %22 = arith.divsi %1, %c4_i32 : i32 loc(#loc)
    %23 = arith.andi %22, %c7_i32 : i32 loc(#loc)
    %24 = arith.muli %23, %c32_i32 : i32 loc(#loc)
    %25 = arith.addi %24, %11 : i32 loc(#loc)
    %26 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %27 = arith.muli %10, %c256_i32 : i32 loc(#loc)
    %28 = arith.divsi %1, %c8_i32 : i32 loc(#loc)
    %29 = arith.andi %28, %c3_i32 : i32 loc(#loc)
    %30 = arith.muli %29, %c8_i32 : i32 loc(#loc)
    %31 = arith.andi %1, %c7_i32 : i32 loc(#loc)
    %32 = arith.muli %31, %c32_i32 : i32 loc(#loc)
    %33 = arith.addi %32, %27 : i32 loc(#loc)
    %34 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %33] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %35 = arith.addi %33, %c16_i32 : i32 loc(#loc)
    %36 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %35] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %34 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %36 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %37 = tt.advance %34, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %38 = tt.advance %36, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %37 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %38 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %39 = tt.advance %37, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %40 = tt.advance %38, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %39 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %40 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %41 = tt.advance %39, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %42 = tt.advance %40, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %43 = arith.andi %1, %c3_i32 : i32 loc(#loc)
    %44 = arith.muli %43, %c64_i32 : i32 loc(#loc)
    %45 = arith.addi %44, %27 : i32 loc(#loc)
    %46 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %45] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %47 = arith.addi %45, %c32_i32 : i32 loc(#loc)
    %48 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %47] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    cf.br ^bb1(%c0_i32, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %26, %46, %48, %20, %21, %41, %42 : i32, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>) loc(#loc)
  ^bb1(%49: i32 loc(unknown), %50: tensor<8x16xf32> loc(unknown), %51: tensor<8x16xf32> loc(unknown), %52: tensor<8x16xf32> loc(unknown), %53: tensor<8x16xf32> loc(unknown), %54: tensor<8x16xf32> loc(unknown), %55: tensor<8x16xf32> loc(unknown), %56: tensor<8x16xf32> loc(unknown), %57: tensor<8x16xf32> loc(unknown), %58: tensor<8x16xf32> loc(unknown), %59: tensor<8x16xf32> loc(unknown), %60: tensor<8x16xf32> loc(unknown), %61: tensor<8x16xf32> loc(unknown), %62: tensor<8x16xf32> loc(unknown), %63: tensor<8x16xf32> loc(unknown), %64: tensor<8x16xf32> loc(unknown), %65: tensor<8x16xf32> loc(unknown), %66: !tt.ptr<tensor<32x32xf16>, 1> loc(unknown), %67: !tt.ptr<tensor<32x32xf16>, 1> loc(unknown), %68: !tt.ptr<tensor<32x32xf16>, 1> loc(unknown), %69: !tt.ptr<tensor<8x16xf16>, 1> loc(unknown), %70: !tt.ptr<tensor<8x16xf16>, 1> loc(unknown), %71: !tt.ptr<tensor<8x16xf16>, 1> loc(unknown), %72: !tt.ptr<tensor<8x16xf16>, 1> loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %73 = arith.cmpi slt, %49, %c4096_i32 : i32 loc(#loc)
    cf.cond_br %73, ^bb2, ^bb3 loc(#loc)
  ^bb2:  // pred: ^bb1
    gpu.barrier loc(#loc)
    %74 = tt.load %66 {DotIdx = 0 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
    %75 = tt.load %67 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
    %76 = tt.load %68 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
    %77 = tt.cast %74 : tensor<32x32xf16> to tensor<32x32xi16> loc(#loc)
    %78 = tt.extract %77, 0 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %79 = tt.cast %78 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %80 = tt.cast %75 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
    %81 = tt.extract %80, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %82 = tt.cast %81 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %83 = tt.dot %79, %82, %50 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %84 = tt.extract %77, 4 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %85 = tt.cast %84 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %86 = tt.extract %80, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %87 = tt.cast %86 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %88 = tt.dot %85, %87, %83 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %89 = tt.glue %88 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %90 = tt.extract %77, 1 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %91 = tt.cast %90 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %92 = tt.dot %91, %82, %51 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %93 = tt.extract %77, 5 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %94 = tt.cast %93 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %95 = tt.dot %94, %87, %92 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %96 = tt.glue %95 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %97 = tt.extract %77, 2 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %98 = tt.cast %97 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %99 = tt.dot %98, %82, %52 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %100 = tt.extract %77, 6 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %101 = tt.cast %100 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %102 = tt.dot %101, %87, %99 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %103 = tt.glue %102 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %104 = tt.extract %77, 3 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %105 = tt.cast %104 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %106 = tt.dot %105, %82, %53 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %107 = tt.extract %77, 7 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %108 = tt.cast %107 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %109 = tt.dot %108, %87, %106 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %110 = tt.glue %109 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %111 = tt.extract %80, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %112 = tt.cast %111 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %113 = tt.dot %79, %112, %54 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %114 = tt.extract %80, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %115 = tt.cast %114 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %116 = tt.dot %85, %115, %113 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %117 = tt.glue %116 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %118 = tt.dot %91, %112, %55 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %119 = tt.dot %94, %115, %118 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %120 = tt.glue %119 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %121 = tt.dot %98, %112, %56 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %122 = tt.dot %101, %115, %121 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %123 = tt.glue %122 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %124 = tt.dot %105, %112, %57 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %125 = tt.dot %108, %115, %124 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %126 = tt.glue %125 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %127 = tt.cast %76 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
    %128 = tt.extract %127, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %129 = tt.cast %128 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %130 = tt.dot %79, %129, %58 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %131 = tt.extract %127, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %132 = tt.cast %131 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %133 = tt.dot %85, %132, %130 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %134 = tt.glue %133 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %135 = tt.dot %91, %129, %59 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %136 = tt.dot %94, %132, %135 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %137 = tt.glue %136 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %138 = tt.dot %98, %129, %60 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %139 = tt.dot %101, %132, %138 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %140 = tt.glue %139 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %141 = tt.dot %105, %129, %61 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %142 = tt.dot %108, %132, %141 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %143 = tt.glue %142 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %144 = tt.extract %127, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %145 = tt.cast %144 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %146 = tt.dot %79, %145, %62 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %147 = tt.extract %127, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %148 = tt.cast %147 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %149 = tt.dot %85, %148, %146 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %150 = tt.glue %149 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %151 = tt.dot %91, %145, %63 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %152 = tt.dot %94, %148, %151 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %153 = tt.glue %152 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %154 = tt.dot %98, %145, %64 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %155 = tt.dot %101, %148, %154 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %156 = tt.glue %155 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %157 = tt.dot %105, %145, %65 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %158 = tt.dot %108, %148, %157 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %159 = tt.glue %158 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    tt.prefetch %69 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %70 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %160 = tt.advance %69, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %161 = tt.advance %70, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %162 = tt.advance %66, [%c0_i32, %c32_i32] : <tensor<32x32xf16>, 1> loc(#loc)
    tt.prefetch %71 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %72 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %163 = tt.advance %71, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %164 = tt.advance %72, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %165 = tt.advance %67, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
    %166 = tt.advance %68, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
    %167 = arith.addi %49, %c32_i32 : i32 loc(#loc)
    cf.br ^bb1(%167, %89, %96, %103, %110, %117, %120, %123, %126, %134, %137, %140, %143, %150, %153, %156, %159, %162, %165, %166, %160, %161, %163, %164 : i32, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>) loc(#loc)
  ^bb3:  // pred: ^bb1
    %168 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %169 = arith.addi %25, %c8_i32 : i32 loc(#loc)
    %170 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%169, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %171 = arith.addi %25, %c16_i32 : i32 loc(#loc)
    %172 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%171, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %173 = arith.addi %25, %c24_i32 : i32 loc(#loc)
    %174 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%173, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %175 = arith.addi %45, %c16_i32 : i32 loc(#loc)
    %176 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %175] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %177 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%169, %175] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %178 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%171, %175] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %179 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%173, %175] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %180 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %181 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%169, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %182 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%171, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %183 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%173, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %184 = arith.addi %45, %c48_i32 : i32 loc(#loc)
    %185 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %184] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %186 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%169, %184] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %187 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%171, %184] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %188 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%173, %184] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    tt.store %168, %50 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %170, %51 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %172, %52 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %174, %53 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %176, %54 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %177, %55 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %178, %56 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %179, %57 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %180, %58 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %181, %59 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %182, %60 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %183, %61 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %185, %62 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %186, %63 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %187, %64 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %188, %65 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before AllocateSharedMemory (allocate-shared-memory) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %c7_i32 = arith.constant 7 : i32 loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %c48_i32 = arith.constant 48 : i32 loc(#loc)
    %c24_i32 = arith.constant 24 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<8x16xf32> loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %0 = gpu.subgroup_id : index loc(#loc)
    %1 = arith.index_cast %0 : index to i32 loc(#loc)
    %2 = tt.get_program_id x : i32 loc(#loc)
    %3 = arith.divsi %2, %c64_i32 : i32 loc(#loc)
    %4 = arith.muli %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.subi %c16_i32, %4 : i32 loc(#loc)
    %6 = arith.minsi %5, %c4_i32 : i32 loc(#loc)
    %7 = arith.remsi %2, %6 : i32 loc(#loc)
    %8 = arith.addi %4, %7 : i32 loc(#loc)
    %9 = arith.andi %2, %c63_i32 : i32 loc(#loc)
    %10 = arith.divsi %9, %6 : i32 loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = arith.muli %1, %c8_i32 : i32 loc(#loc)
    %13 = arith.addi %12, %11 : i32 loc(#loc)
    %14 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c0_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %15 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c16_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %14 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %15 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %16 = tt.advance %14, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %17 = tt.advance %15, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %16 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %17 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %18 = tt.advance %16, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %19 = tt.advance %17, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %18 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %19 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %20 = tt.advance %18, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %21 = tt.advance %19, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %22 = arith.divsi %1, %c4_i32 : i32 loc(#loc)
    %23 = arith.andi %22, %c7_i32 : i32 loc(#loc)
    %24 = arith.muli %23, %c32_i32 : i32 loc(#loc)
    %25 = arith.addi %24, %11 : i32 loc(#loc)
    %26 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %27 = arith.muli %10, %c256_i32 : i32 loc(#loc)
    %28 = arith.divsi %1, %c8_i32 : i32 loc(#loc)
    %29 = arith.andi %28, %c3_i32 : i32 loc(#loc)
    %30 = arith.muli %29, %c8_i32 : i32 loc(#loc)
    %31 = arith.andi %1, %c7_i32 : i32 loc(#loc)
    %32 = arith.muli %31, %c32_i32 : i32 loc(#loc)
    %33 = arith.addi %32, %27 : i32 loc(#loc)
    %34 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %33] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %35 = arith.addi %33, %c16_i32 : i32 loc(#loc)
    %36 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %35] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %34 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %36 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %37 = tt.advance %34, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %38 = tt.advance %36, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %37 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %38 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %39 = tt.advance %37, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %40 = tt.advance %38, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %39 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %40 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %41 = tt.advance %39, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %42 = tt.advance %40, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %43 = arith.andi %1, %c3_i32 : i32 loc(#loc)
    %44 = arith.muli %43, %c64_i32 : i32 loc(#loc)
    %45 = arith.addi %44, %27 : i32 loc(#loc)
    %46 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %45] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %47 = arith.addi %45, %c32_i32 : i32 loc(#loc)
    %48 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %47] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    cf.br ^bb1(%c0_i32, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %26, %46, %48, %20, %21, %41, %42 : i32, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>) loc(#loc)
  ^bb1(%49: i32 loc(unknown), %50: tensor<8x16xf32> loc(unknown), %51: tensor<8x16xf32> loc(unknown), %52: tensor<8x16xf32> loc(unknown), %53: tensor<8x16xf32> loc(unknown), %54: tensor<8x16xf32> loc(unknown), %55: tensor<8x16xf32> loc(unknown), %56: tensor<8x16xf32> loc(unknown), %57: tensor<8x16xf32> loc(unknown), %58: tensor<8x16xf32> loc(unknown), %59: tensor<8x16xf32> loc(unknown), %60: tensor<8x16xf32> loc(unknown), %61: tensor<8x16xf32> loc(unknown), %62: tensor<8x16xf32> loc(unknown), %63: tensor<8x16xf32> loc(unknown), %64: tensor<8x16xf32> loc(unknown), %65: tensor<8x16xf32> loc(unknown), %66: !tt.ptr<tensor<32x32xf16>, 1> loc(unknown), %67: !tt.ptr<tensor<32x32xf16>, 1> loc(unknown), %68: !tt.ptr<tensor<32x32xf16>, 1> loc(unknown), %69: !tt.ptr<tensor<8x16xf16>, 1> loc(unknown), %70: !tt.ptr<tensor<8x16xf16>, 1> loc(unknown), %71: !tt.ptr<tensor<8x16xf16>, 1> loc(unknown), %72: !tt.ptr<tensor<8x16xf16>, 1> loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %73 = arith.cmpi slt, %49, %c4096_i32 : i32 loc(#loc)
    cf.cond_br %73, ^bb2, ^bb3 loc(#loc)
  ^bb2:  // pred: ^bb1
    gpu.barrier loc(#loc)
    %74 = tt.load %66 {DotIdx = 0 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
    %75 = tt.load %67 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
    %76 = tt.load %68 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
    %77 = tt.cast %74 : tensor<32x32xf16> to tensor<32x32xi16> loc(#loc)
    %78 = tt.extract %77, 0 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %79 = tt.cast %78 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %80 = tt.cast %75 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
    %81 = tt.extract %80, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %82 = tt.cast %81 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %83 = tt.dot %79, %82, %50 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %84 = tt.extract %77, 4 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %85 = tt.cast %84 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %86 = tt.extract %80, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %87 = tt.cast %86 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %88 = tt.dot %85, %87, %83 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %89 = tt.glue %88 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %90 = tt.extract %77, 1 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %91 = tt.cast %90 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %92 = tt.dot %91, %82, %51 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %93 = tt.extract %77, 5 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %94 = tt.cast %93 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %95 = tt.dot %94, %87, %92 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %96 = tt.glue %95 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %97 = tt.extract %77, 2 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %98 = tt.cast %97 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %99 = tt.dot %98, %82, %52 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %100 = tt.extract %77, 6 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %101 = tt.cast %100 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %102 = tt.dot %101, %87, %99 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %103 = tt.glue %102 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %104 = tt.extract %77, 3 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %105 = tt.cast %104 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %106 = tt.dot %105, %82, %53 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %107 = tt.extract %77, 7 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %108 = tt.cast %107 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %109 = tt.dot %108, %87, %106 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %110 = tt.glue %109 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %111 = tt.extract %80, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %112 = tt.cast %111 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %113 = tt.dot %79, %112, %54 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %114 = tt.extract %80, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %115 = tt.cast %114 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %116 = tt.dot %85, %115, %113 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %117 = tt.glue %116 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %118 = tt.dot %91, %112, %55 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %119 = tt.dot %94, %115, %118 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %120 = tt.glue %119 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %121 = tt.dot %98, %112, %56 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %122 = tt.dot %101, %115, %121 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %123 = tt.glue %122 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %124 = tt.dot %105, %112, %57 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %125 = tt.dot %108, %115, %124 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %126 = tt.glue %125 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %127 = tt.cast %76 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
    %128 = tt.extract %127, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %129 = tt.cast %128 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %130 = tt.dot %79, %129, %58 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %131 = tt.extract %127, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %132 = tt.cast %131 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %133 = tt.dot %85, %132, %130 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %134 = tt.glue %133 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %135 = tt.dot %91, %129, %59 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %136 = tt.dot %94, %132, %135 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %137 = tt.glue %136 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %138 = tt.dot %98, %129, %60 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %139 = tt.dot %101, %132, %138 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %140 = tt.glue %139 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %141 = tt.dot %105, %129, %61 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %142 = tt.dot %108, %132, %141 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %143 = tt.glue %142 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %144 = tt.extract %127, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %145 = tt.cast %144 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %146 = tt.dot %79, %145, %62 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %147 = tt.extract %127, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %148 = tt.cast %147 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %149 = tt.dot %85, %148, %146 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %150 = tt.glue %149 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %151 = tt.dot %91, %145, %63 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %152 = tt.dot %94, %148, %151 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %153 = tt.glue %152 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %154 = tt.dot %98, %145, %64 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %155 = tt.dot %101, %148, %154 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %156 = tt.glue %155 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %157 = tt.dot %105, %145, %65 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %158 = tt.dot %108, %148, %157 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %159 = tt.glue %158 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    tt.prefetch %69 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %70 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %160 = tt.advance %69, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %161 = tt.advance %70, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %162 = tt.advance %66, [%c0_i32, %c32_i32] : <tensor<32x32xf16>, 1> loc(#loc)
    tt.prefetch %71 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %72 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %163 = tt.advance %71, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %164 = tt.advance %72, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %165 = tt.advance %67, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
    %166 = tt.advance %68, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
    %167 = arith.addi %49, %c32_i32 : i32 loc(#loc)
    cf.br ^bb1(%167, %89, %96, %103, %110, %117, %120, %123, %126, %134, %137, %140, %143, %150, %153, %156, %159, %162, %165, %166, %160, %161, %163, %164 : i32, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>) loc(#loc)
  ^bb3:  // pred: ^bb1
    %168 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %169 = arith.addi %25, %c8_i32 : i32 loc(#loc)
    %170 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%169, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %171 = arith.addi %25, %c16_i32 : i32 loc(#loc)
    %172 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%171, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %173 = arith.addi %25, %c24_i32 : i32 loc(#loc)
    %174 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%173, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %175 = arith.addi %45, %c16_i32 : i32 loc(#loc)
    %176 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %175] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %177 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%169, %175] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %178 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%171, %175] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %179 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%173, %175] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %180 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %181 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%169, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %182 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%171, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %183 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%173, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %184 = arith.addi %45, %c48_i32 : i32 loc(#loc)
    %185 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %184] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %186 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%169, %184] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %187 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%171, %184] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %188 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%173, %184] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    tt.store %168, %50 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %170, %51 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %172, %52 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %174, %53 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %176, %54 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %177, %55 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %178, %56 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %179, %57 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %180, %58 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %181, %59 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %182, %60 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %183, %61 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %185, %62 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %186, %63 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %187, %64 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %188, %65 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before ConvertTritonGPUToLLVM (convert-triton-gpu-to-llvm) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, triton_gpu.shared = 0 : i32, "triton_gpu.threads-per-warp" = 1 : i32} {
  tt.func public @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !tt.ptr<f16, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !tt.ptr<f32, 1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {noinline = false} {
    %c3_i32 = arith.constant 3 : i32 loc(#loc)
    %c7_i32 = arith.constant 7 : i32 loc(#loc)
    %c63_i32 = arith.constant 63 : i32 loc(#loc)
    %c48_i32 = arith.constant 48 : i32 loc(#loc)
    %c24_i32 = arith.constant 24 : i32 loc(#loc)
    %c8_i32 = arith.constant 8 : i32 loc(#loc)
    %c4_i32 = arith.constant 4 : i32 loc(#loc)
    %c256_i32 = arith.constant 256 : i32 loc(#loc)
    %c4096_i64 = arith.constant 4096 : i64 loc(#loc)
    %c1_i64 = arith.constant 1 : i64 loc(#loc)
    %c0_i32 = arith.constant 0 : i32 loc(#loc)
    %c32_i32 = arith.constant 32 : i32 loc(#loc)
    %cst = arith.constant dense<0.000000e+00> : tensor<8x16xf32> loc(#loc)
    %c4096_i32 = arith.constant 4096 : i32 loc(#loc)
    %c16_i32 = arith.constant 16 : i32 loc(#loc)
    %c64_i32 = arith.constant 64 : i32 loc(#loc)
    %0 = gpu.subgroup_id : index loc(#loc)
    %1 = arith.index_cast %0 : index to i32 loc(#loc)
    %2 = tt.get_program_id x : i32 loc(#loc)
    %3 = arith.divsi %2, %c64_i32 : i32 loc(#loc)
    %4 = arith.muli %3, %c4_i32 : i32 loc(#loc)
    %5 = arith.subi %c16_i32, %4 : i32 loc(#loc)
    %6 = arith.minsi %5, %c4_i32 : i32 loc(#loc)
    %7 = arith.remsi %2, %6 : i32 loc(#loc)
    %8 = arith.addi %4, %7 : i32 loc(#loc)
    %9 = arith.andi %2, %c63_i32 : i32 loc(#loc)
    %10 = arith.divsi %9, %6 : i32 loc(#loc)
    %11 = arith.muli %8, %c256_i32 : i32 loc(#loc)
    %12 = arith.muli %1, %c8_i32 : i32 loc(#loc)
    %13 = arith.addi %12, %11 : i32 loc(#loc)
    %14 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c0_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %15 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%13, %c16_i32] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %14 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %15 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %16 = tt.advance %14, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %17 = tt.advance %15, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %16 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %17 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %18 = tt.advance %16, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %19 = tt.advance %17, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %18 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %19 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %20 = tt.advance %18, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %21 = tt.advance %19, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %22 = arith.divsi %1, %c4_i32 : i32 loc(#loc)
    %23 = arith.andi %22, %c7_i32 : i32 loc(#loc)
    %24 = arith.muli %23, %c32_i32 : i32 loc(#loc)
    %25 = arith.addi %24, %11 : i32 loc(#loc)
    %26 = tt.make_tensor_ptr %arg0, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %27 = arith.muli %10, %c256_i32 : i32 loc(#loc)
    %28 = arith.divsi %1, %c8_i32 : i32 loc(#loc)
    %29 = arith.andi %28, %c3_i32 : i32 loc(#loc)
    %30 = arith.muli %29, %c8_i32 : i32 loc(#loc)
    %31 = arith.andi %1, %c7_i32 : i32 loc(#loc)
    %32 = arith.muli %31, %c32_i32 : i32 loc(#loc)
    %33 = arith.addi %32, %27 : i32 loc(#loc)
    %34 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %33] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    %35 = arith.addi %33, %c16_i32 : i32 loc(#loc)
    %36 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%30, %35] {order = array<i32: 1, 0>} : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %34 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %36 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %37 = tt.advance %34, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %38 = tt.advance %36, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %37 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %38 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %39 = tt.advance %37, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %40 = tt.advance %38, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %39 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %40 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %41 = tt.advance %39, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %42 = tt.advance %40, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %43 = arith.andi %1, %c3_i32 : i32 loc(#loc)
    %44 = arith.muli %43, %c64_i32 : i32 loc(#loc)
    %45 = arith.addi %44, %27 : i32 loc(#loc)
    %46 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %45] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    %47 = arith.addi %45, %c32_i32 : i32 loc(#loc)
    %48 = tt.make_tensor_ptr %arg1, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%c0_i32, %47] {order = array<i32: 1, 0>} : <tensor<32x32xf16>, 1> loc(#loc)
    cf.br ^bb1(%c0_i32, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %cst, %26, %46, %48, %20, %21, %41, %42 : i32, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>) loc(#loc)
  ^bb1(%49: i32 loc(unknown), %50: tensor<8x16xf32> loc(unknown), %51: tensor<8x16xf32> loc(unknown), %52: tensor<8x16xf32> loc(unknown), %53: tensor<8x16xf32> loc(unknown), %54: tensor<8x16xf32> loc(unknown), %55: tensor<8x16xf32> loc(unknown), %56: tensor<8x16xf32> loc(unknown), %57: tensor<8x16xf32> loc(unknown), %58: tensor<8x16xf32> loc(unknown), %59: tensor<8x16xf32> loc(unknown), %60: tensor<8x16xf32> loc(unknown), %61: tensor<8x16xf32> loc(unknown), %62: tensor<8x16xf32> loc(unknown), %63: tensor<8x16xf32> loc(unknown), %64: tensor<8x16xf32> loc(unknown), %65: tensor<8x16xf32> loc(unknown), %66: !tt.ptr<tensor<32x32xf16>, 1> loc(unknown), %67: !tt.ptr<tensor<32x32xf16>, 1> loc(unknown), %68: !tt.ptr<tensor<32x32xf16>, 1> loc(unknown), %69: !tt.ptr<tensor<8x16xf16>, 1> loc(unknown), %70: !tt.ptr<tensor<8x16xf16>, 1> loc(unknown), %71: !tt.ptr<tensor<8x16xf16>, 1> loc(unknown), %72: !tt.ptr<tensor<8x16xf16>, 1> loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %73 = arith.cmpi slt, %49, %c4096_i32 : i32 loc(#loc)
    cf.cond_br %73, ^bb2, ^bb3 loc(#loc)
  ^bb2:  // pred: ^bb1
    gpu.barrier loc(#loc)
    %74 = tt.load %66 {DotIdx = 0 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
    %75 = tt.load %67 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
    %76 = tt.load %68 {DotIdx = 1 : i32, boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<32x32xf16>, 1> -> tensor<32x32xf16> loc(#loc)
    %77 = tt.cast %74 : tensor<32x32xf16> to tensor<32x32xi16> loc(#loc)
    %78 = tt.extract %77, 0 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %79 = tt.cast %78 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %80 = tt.cast %75 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
    %81 = tt.extract %80, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %82 = tt.cast %81 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %83 = tt.dot %79, %82, %50 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %84 = tt.extract %77, 4 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %85 = tt.cast %84 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %86 = tt.extract %80, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %87 = tt.cast %86 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %88 = tt.dot %85, %87, %83 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %89 = tt.glue %88 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %90 = tt.extract %77, 1 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %91 = tt.cast %90 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %92 = tt.dot %91, %82, %51 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %93 = tt.extract %77, 5 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %94 = tt.cast %93 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %95 = tt.dot %94, %87, %92 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %96 = tt.glue %95 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %97 = tt.extract %77, 2 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %98 = tt.cast %97 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %99 = tt.dot %98, %82, %52 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %100 = tt.extract %77, 6 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %101 = tt.cast %100 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %102 = tt.dot %101, %87, %99 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %103 = tt.glue %102 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %104 = tt.extract %77, 3 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %105 = tt.cast %104 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %106 = tt.dot %105, %82, %53 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %107 = tt.extract %77, 7 : tensor<32x32xi16> -> tensor<8x16xi16> loc(#loc)
    %108 = tt.cast %107 : tensor<8x16xi16> to tensor<8x16xf16> loc(#loc)
    %109 = tt.dot %108, %87, %106 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %110 = tt.glue %109 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %111 = tt.extract %80, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %112 = tt.cast %111 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %113 = tt.dot %79, %112, %54 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %114 = tt.extract %80, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %115 = tt.cast %114 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %116 = tt.dot %85, %115, %113 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %117 = tt.glue %116 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %118 = tt.dot %91, %112, %55 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %119 = tt.dot %94, %115, %118 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %120 = tt.glue %119 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %121 = tt.dot %98, %112, %56 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %122 = tt.dot %101, %115, %121 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %123 = tt.glue %122 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %124 = tt.dot %105, %112, %57 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %125 = tt.dot %108, %115, %124 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %126 = tt.glue %125 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %127 = tt.cast %76 : tensor<32x32xf16> to tensor<16x32xi32> loc(#loc)
    %128 = tt.extract %127, 0 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %129 = tt.cast %128 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %130 = tt.dot %79, %129, %58 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %131 = tt.extract %127, 1 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %132 = tt.cast %131 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %133 = tt.dot %85, %132, %130 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %134 = tt.glue %133 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %135 = tt.dot %91, %129, %59 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %136 = tt.dot %94, %132, %135 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %137 = tt.glue %136 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %138 = tt.dot %98, %129, %60 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %139 = tt.dot %101, %132, %138 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %140 = tt.glue %139 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %141 = tt.dot %105, %129, %61 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %142 = tt.dot %108, %132, %141 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %143 = tt.glue %142 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %144 = tt.extract %127, 2 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %145 = tt.cast %144 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %146 = tt.dot %79, %145, %62 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %147 = tt.extract %127, 3 : tensor<16x32xi32> -> tensor<8x16xi32> loc(#loc)
    %148 = tt.cast %147 : tensor<8x16xi32> to tensor<16x16xf16> loc(#loc)
    %149 = tt.dot %85, %148, %146 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %150 = tt.glue %149 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %151 = tt.dot %91, %145, %63 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %152 = tt.dot %94, %148, %151 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %153 = tt.glue %152 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %154 = tt.dot %98, %145, %64 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %155 = tt.dot %101, %148, %154 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %156 = tt.glue %155 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    %157 = tt.dot %105, %145, %65 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %158 = tt.dot %108, %148, %157 {allowTF32 = true, maxNumImpreciseAcc = 0 : i32} : tensor<8x16xf16> * tensor<16x16xf16> -> tensor<8x16xf32> loc(#loc)
    %159 = tt.glue %158 : tensor<8x16xf32> -> tensor<8x16xf32> loc(#loc)
    tt.prefetch %69 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %70 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %160 = tt.advance %69, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %161 = tt.advance %70, [%c0_i32, %c32_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %162 = tt.advance %66, [%c0_i32, %c32_i32] : <tensor<32x32xf16>, 1> loc(#loc)
    tt.prefetch %71 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    tt.prefetch %72 {cache = 1 : i32, evict = 1 : i32, isVolatile = false} : !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %163 = tt.advance %71, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %164 = tt.advance %72, [%c32_i32, %c0_i32] : <tensor<8x16xf16>, 1> loc(#loc)
    %165 = tt.advance %67, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
    %166 = tt.advance %68, [%c32_i32, %c0_i32] : <tensor<32x32xf16>, 1> loc(#loc)
    %167 = arith.addi %49, %c32_i32 : i32 loc(#loc)
    cf.br ^bb1(%167, %89, %96, %103, %110, %117, %120, %123, %126, %134, %137, %140, %143, %150, %153, %156, %159, %162, %165, %166, %160, %161, %163, %164 : i32, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>) loc(#loc)
  ^bb3:  // pred: ^bb1
    %168 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %169 = arith.addi %25, %c8_i32 : i32 loc(#loc)
    %170 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%169, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %171 = arith.addi %25, %c16_i32 : i32 loc(#loc)
    %172 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%171, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %173 = arith.addi %25, %c24_i32 : i32 loc(#loc)
    %174 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%173, %45] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %175 = arith.addi %45, %c16_i32 : i32 loc(#loc)
    %176 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %175] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %177 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%169, %175] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %178 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%171, %175] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %179 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%173, %175] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %180 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %181 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%169, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %182 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%171, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %183 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%173, %47] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %184 = arith.addi %45, %c48_i32 : i32 loc(#loc)
    %185 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%25, %184] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %186 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%169, %184] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %187 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%171, %184] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    %188 = tt.make_tensor_ptr %arg2, [%c4096_i64, %c4096_i64], [%c4096_i64, %c1_i64], [%173, %184] {order = array<i32: 1, 0>} : <tensor<8x16xf32>, 1> loc(#loc)
    tt.store %168, %50 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %170, %51 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %172, %52 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %174, %53 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %176, %54 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %177, %55 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %178, %56 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %179, %57 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %180, %58 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %181, %59 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %182, %60 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %183, %61 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %185, %62 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %186, %63 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %187, %64 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.store %188, %65 {boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32} : !tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32> loc(#loc)
    tt.return loc(#loc)
  } loc(#loc)
} loc(#loc)


"builtin.module"() ({
  "llvm.func"() <{CConv = #llvm.cconv<ccc>, arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}], function_type = !llvm.func<void (ptr<1>, ptr<1>, ptr<1>, i32, i32, i32)>, linkage = #llvm.linkage<external>, sym_name = "matmul_kernel_with_block_pointers_0d1d2d3d4d5d", visibility_ = 0 : i64}> ({
  ^bb0(%arg0: !llvm.ptr<1>, %arg1: !llvm.ptr<1>, %arg2: !llvm.ptr<1>, %arg3: i32, %arg4: i32, %arg5: i32):
    %0 = "builtin.unrealized_conversion_cast"(%arg2) : (!llvm.ptr<1>) -> !tt.ptr<f32, 1>
    %1 = "builtin.unrealized_conversion_cast"(%arg1) : (!llvm.ptr<1>) -> !tt.ptr<f16, 1>
    %2 = "builtin.unrealized_conversion_cast"(%arg0) : (!llvm.ptr<1>) -> !tt.ptr<f16, 1>
    %3 = "arith.constant"() <{value = 3 : i32}> : () -> i32
    %4 = "arith.constant"() <{value = 7 : i32}> : () -> i32
    %5 = "arith.constant"() <{value = 63 : i32}> : () -> i32
    %6 = "arith.constant"() <{value = 48 : i32}> : () -> i32
    %7 = "arith.constant"() <{value = 24 : i32}> : () -> i32
    %8 = "arith.constant"() <{value = 8 : i32}> : () -> i32
    %9 = "arith.constant"() <{value = 4 : i32}> : () -> i32
    %10 = "arith.constant"() <{value = 256 : i32}> : () -> i32
    %11 = "arith.constant"() <{value = 4096 : i64}> : () -> i64
    %12 = "arith.constant"() <{value = 1 : i64}> : () -> i64
    %13 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %14 = "arith.constant"() <{value = 32 : i32}> : () -> i32
    %15 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<8x16xf32>}> : () -> tensor<8x16xf32>
    %16 = "arith.constant"() <{value = 4096 : i32}> : () -> i32
    %17 = "arith.constant"() <{value = 16 : i32}> : () -> i32
    %18 = "arith.constant"() <{value = 64 : i32}> : () -> i32
    %19 = "gpu.subgroup_id"() : () -> index
    %20 = "arith.index_cast"(%19) : (index) -> i32
    %21 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
    %22 = "arith.divsi"(%21, %18) : (i32, i32) -> i32
    %23 = "arith.muli"(%22, %9) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %24 = "arith.subi"(%17, %23) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %25 = "arith.minsi"(%24, %9) : (i32, i32) -> i32
    %26 = "arith.remsi"(%21, %25) : (i32, i32) -> i32
    %27 = "arith.addi"(%23, %26) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %28 = "arith.andi"(%21, %5) : (i32, i32) -> i32
    %29 = "arith.divsi"(%28, %25) : (i32, i32) -> i32
    %30 = "arith.muli"(%27, %10) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %31 = "arith.muli"(%20, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %32 = "arith.addi"(%31, %30) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %33 = "tt.make_tensor_ptr"(%2, %11, %11, %11, %12, %32, %13) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %34 = "tt.make_tensor_ptr"(%2, %11, %11, %11, %12, %32, %17) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    "tt.prefetch"(%33) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    "tt.prefetch"(%34) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    %35 = "tt.advance"(%33, %13, %14) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %36 = "tt.advance"(%34, %13, %14) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    "tt.prefetch"(%35) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    "tt.prefetch"(%36) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    %37 = "tt.advance"(%35, %13, %14) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %38 = "tt.advance"(%36, %13, %14) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    "tt.prefetch"(%37) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    "tt.prefetch"(%38) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    %39 = "tt.advance"(%37, %13, %14) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %40 = "tt.advance"(%38, %13, %14) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %41 = "arith.divsi"(%20, %9) : (i32, i32) -> i32
    %42 = "arith.andi"(%41, %4) : (i32, i32) -> i32
    %43 = "arith.muli"(%42, %14) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %44 = "arith.addi"(%43, %30) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %45 = "tt.make_tensor_ptr"(%2, %11, %11, %11, %12, %44, %13) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<32x32xf16>, 1>
    %46 = "arith.muli"(%29, %10) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %47 = "arith.divsi"(%20, %8) : (i32, i32) -> i32
    %48 = "arith.andi"(%47, %3) : (i32, i32) -> i32
    %49 = "arith.muli"(%48, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %50 = "arith.andi"(%20, %4) : (i32, i32) -> i32
    %51 = "arith.muli"(%50, %14) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %52 = "arith.addi"(%51, %46) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %53 = "tt.make_tensor_ptr"(%1, %11, %11, %11, %12, %49, %52) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %54 = "arith.addi"(%52, %17) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %55 = "tt.make_tensor_ptr"(%1, %11, %11, %11, %12, %49, %54) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    "tt.prefetch"(%53) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    "tt.prefetch"(%55) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    %56 = "tt.advance"(%53, %14, %13) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %57 = "tt.advance"(%55, %14, %13) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    "tt.prefetch"(%56) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    "tt.prefetch"(%57) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    %58 = "tt.advance"(%56, %14, %13) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %59 = "tt.advance"(%57, %14, %13) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    "tt.prefetch"(%58) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    "tt.prefetch"(%59) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    %60 = "tt.advance"(%58, %14, %13) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %61 = "tt.advance"(%59, %14, %13) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %62 = "arith.andi"(%20, %3) : (i32, i32) -> i32
    %63 = "arith.muli"(%62, %18) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %64 = "arith.addi"(%63, %46) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %65 = "tt.make_tensor_ptr"(%1, %11, %11, %11, %12, %13, %64) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<32x32xf16>, 1>
    %66 = "arith.addi"(%64, %14) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %67 = "tt.make_tensor_ptr"(%1, %11, %11, %11, %12, %13, %66) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<32x32xf16>, 1>
    "cf.br"(%13, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %45, %65, %67, %39, %40, %60, %61)[^bb1] : (i32, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>) -> ()
  ^bb1(%68: i32, %69: vector<8xf32>, %70: vector<8xf32>, %71: vector<8xf32>, %72: vector<8xf32>, %73: vector<8xf32>, %74: vector<8xf32>, %75: vector<8xf32>, %76: vector<8xf32>, %77: vector<8xf32>, %78: vector<8xf32>, %79: vector<8xf32>, %80: vector<8xf32>, %81: vector<8xf32>, %82: vector<8xf32>, %83: vector<8xf32>, %84: vector<8xf32>, %85: vector<2xi32>, %86: vector<2xi32>, %87: vector<2xi32>, %88: vector<2xi32>, %89: vector<2xi32>, %90: vector<2xi32>, %91: vector<2xi32>):  // 2 preds: ^bb0, ^bb2
    %92 = "builtin.unrealized_conversion_cast"(%91) : (vector<2xi32>) -> !tt.ptr<tensor<8x16xf16>, 1>
    %93 = "builtin.unrealized_conversion_cast"(%90) : (vector<2xi32>) -> !tt.ptr<tensor<8x16xf16>, 1>
    %94 = "builtin.unrealized_conversion_cast"(%89) : (vector<2xi32>) -> !tt.ptr<tensor<8x16xf16>, 1>
    %95 = "builtin.unrealized_conversion_cast"(%88) : (vector<2xi32>) -> !tt.ptr<tensor<8x16xf16>, 1>
    %96 = "builtin.unrealized_conversion_cast"(%87) : (vector<2xi32>) -> !tt.ptr<tensor<32x32xf16>, 1>
    %97 = "builtin.unrealized_conversion_cast"(%86) : (vector<2xi32>) -> !tt.ptr<tensor<32x32xf16>, 1>
    %98 = "builtin.unrealized_conversion_cast"(%85) : (vector<2xi32>) -> !tt.ptr<tensor<32x32xf16>, 1>
    %99 = "builtin.unrealized_conversion_cast"(%84) : (vector<8xf32>) -> tensor<8x16xf32>
    %100 = "builtin.unrealized_conversion_cast"(%83) : (vector<8xf32>) -> tensor<8x16xf32>
    %101 = "builtin.unrealized_conversion_cast"(%82) : (vector<8xf32>) -> tensor<8x16xf32>
    %102 = "builtin.unrealized_conversion_cast"(%81) : (vector<8xf32>) -> tensor<8x16xf32>
    %103 = "builtin.unrealized_conversion_cast"(%80) : (vector<8xf32>) -> tensor<8x16xf32>
    %104 = "builtin.unrealized_conversion_cast"(%79) : (vector<8xf32>) -> tensor<8x16xf32>
    %105 = "builtin.unrealized_conversion_cast"(%78) : (vector<8xf32>) -> tensor<8x16xf32>
    %106 = "builtin.unrealized_conversion_cast"(%77) : (vector<8xf32>) -> tensor<8x16xf32>
    %107 = "builtin.unrealized_conversion_cast"(%76) : (vector<8xf32>) -> tensor<8x16xf32>
    %108 = "builtin.unrealized_conversion_cast"(%75) : (vector<8xf32>) -> tensor<8x16xf32>
    %109 = "builtin.unrealized_conversion_cast"(%74) : (vector<8xf32>) -> tensor<8x16xf32>
    %110 = "builtin.unrealized_conversion_cast"(%73) : (vector<8xf32>) -> tensor<8x16xf32>
    %111 = "builtin.unrealized_conversion_cast"(%72) : (vector<8xf32>) -> tensor<8x16xf32>
    %112 = "builtin.unrealized_conversion_cast"(%71) : (vector<8xf32>) -> tensor<8x16xf32>
    %113 = "builtin.unrealized_conversion_cast"(%70) : (vector<8xf32>) -> tensor<8x16xf32>
    %114 = "builtin.unrealized_conversion_cast"(%69) : (vector<8xf32>) -> tensor<8x16xf32>
    %115 = "arith.cmpi"(%68, %16) <{predicate = 2 : i64}> : (i32, i32) -> i1
    "cf.cond_br"(%115)[^bb2, ^bb3] <{operandSegmentSizes = array<i32: 1, 0, 0>}> : (i1) -> ()
  ^bb2:  // pred: ^bb1
    "gpu.barrier"() : () -> ()
    %116 = "tt.load"(%98) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> {DotIdx = 0 : i32} : (!tt.ptr<tensor<32x32xf16>, 1>) -> tensor<32x32xf16>
    %117 = "tt.load"(%97) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> {DotIdx = 1 : i32} : (!tt.ptr<tensor<32x32xf16>, 1>) -> tensor<32x32xf16>
    %118 = "tt.load"(%96) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> {DotIdx = 1 : i32} : (!tt.ptr<tensor<32x32xf16>, 1>) -> tensor<32x32xf16>
    %119 = "tt.cast"(%116) : (tensor<32x32xf16>) -> tensor<32x32xi16>
    %120 = "tt.extract"(%119) <{idx = 0 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
    %121 = "tt.cast"(%120) : (tensor<8x16xi16>) -> tensor<8x16xf16>
    %122 = "tt.cast"(%117) : (tensor<32x32xf16>) -> tensor<16x32xi32>
    %123 = "tt.extract"(%122) <{idx = 0 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
    %124 = "tt.cast"(%123) : (tensor<8x16xi32>) -> tensor<16x16xf16>
    %125 = "tt.dot"(%121, %124, %114) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %126 = "tt.extract"(%119) <{idx = 4 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
    %127 = "tt.cast"(%126) : (tensor<8x16xi16>) -> tensor<8x16xf16>
    %128 = "tt.extract"(%122) <{idx = 1 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
    %129 = "tt.cast"(%128) : (tensor<8x16xi32>) -> tensor<16x16xf16>
    %130 = "tt.dot"(%127, %129, %125) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %131 = "tt.glue"(%130) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %132 = "tt.extract"(%119) <{idx = 1 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
    %133 = "tt.cast"(%132) : (tensor<8x16xi16>) -> tensor<8x16xf16>
    %134 = "tt.dot"(%133, %124, %113) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %135 = "tt.extract"(%119) <{idx = 5 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
    %136 = "tt.cast"(%135) : (tensor<8x16xi16>) -> tensor<8x16xf16>
    %137 = "tt.dot"(%136, %129, %134) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %138 = "tt.glue"(%137) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %139 = "tt.extract"(%119) <{idx = 2 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
    %140 = "tt.cast"(%139) : (tensor<8x16xi16>) -> tensor<8x16xf16>
    %141 = "tt.dot"(%140, %124, %112) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %142 = "tt.extract"(%119) <{idx = 6 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
    %143 = "tt.cast"(%142) : (tensor<8x16xi16>) -> tensor<8x16xf16>
    %144 = "tt.dot"(%143, %129, %141) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %145 = "tt.glue"(%144) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %146 = "tt.extract"(%119) <{idx = 3 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
    %147 = "tt.cast"(%146) : (tensor<8x16xi16>) -> tensor<8x16xf16>
    %148 = "tt.dot"(%147, %124, %111) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %149 = "tt.extract"(%119) <{idx = 7 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
    %150 = "tt.cast"(%149) : (tensor<8x16xi16>) -> tensor<8x16xf16>
    %151 = "tt.dot"(%150, %129, %148) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %152 = "tt.glue"(%151) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %153 = "tt.extract"(%122) <{idx = 2 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
    %154 = "tt.cast"(%153) : (tensor<8x16xi32>) -> tensor<16x16xf16>
    %155 = "tt.dot"(%121, %154, %110) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %156 = "tt.extract"(%122) <{idx = 3 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
    %157 = "tt.cast"(%156) : (tensor<8x16xi32>) -> tensor<16x16xf16>
    %158 = "tt.dot"(%127, %157, %155) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %159 = "tt.glue"(%158) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %160 = "tt.dot"(%133, %154, %109) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %161 = "tt.dot"(%136, %157, %160) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %162 = "tt.glue"(%161) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %163 = "tt.dot"(%140, %154, %108) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %164 = "tt.dot"(%143, %157, %163) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %165 = "tt.glue"(%164) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %166 = "tt.dot"(%147, %154, %107) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %167 = "tt.dot"(%150, %157, %166) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %168 = "tt.glue"(%167) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %169 = "tt.cast"(%118) : (tensor<32x32xf16>) -> tensor<16x32xi32>
    %170 = "tt.extract"(%169) <{idx = 0 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
    %171 = "tt.cast"(%170) : (tensor<8x16xi32>) -> tensor<16x16xf16>
    %172 = "tt.dot"(%121, %171, %106) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %173 = "tt.extract"(%169) <{idx = 1 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
    %174 = "tt.cast"(%173) : (tensor<8x16xi32>) -> tensor<16x16xf16>
    %175 = "tt.dot"(%127, %174, %172) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %176 = "tt.glue"(%175) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %177 = "tt.dot"(%133, %171, %105) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %178 = "tt.dot"(%136, %174, %177) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %179 = "tt.glue"(%178) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %180 = "tt.dot"(%140, %171, %104) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %181 = "tt.dot"(%143, %174, %180) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %182 = "tt.glue"(%181) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %183 = "tt.dot"(%147, %171, %103) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %184 = "tt.dot"(%150, %174, %183) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %185 = "tt.glue"(%184) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %186 = "tt.extract"(%169) <{idx = 2 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
    %187 = "tt.cast"(%186) : (tensor<8x16xi32>) -> tensor<16x16xf16>
    %188 = "tt.dot"(%121, %187, %102) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %189 = "tt.extract"(%169) <{idx = 3 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
    %190 = "tt.cast"(%189) : (tensor<8x16xi32>) -> tensor<16x16xf16>
    %191 = "tt.dot"(%127, %190, %188) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %192 = "tt.glue"(%191) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %193 = "tt.dot"(%133, %187, %101) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %194 = "tt.dot"(%136, %190, %193) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %195 = "tt.glue"(%194) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %196 = "tt.dot"(%140, %187, %100) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %197 = "tt.dot"(%143, %190, %196) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %198 = "tt.glue"(%197) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    %199 = "tt.dot"(%147, %187, %99) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %200 = "tt.dot"(%150, %190, %199) <{allowTF32 = true, maxNumImpreciseAcc = 0 : i32}> : (tensor<8x16xf16>, tensor<16x16xf16>, tensor<8x16xf32>) -> tensor<8x16xf32>
    %201 = "tt.glue"(%200) : (tensor<8x16xf32>) -> tensor<8x16xf32>
    "tt.prefetch"(%95) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    "tt.prefetch"(%94) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    %202 = "tt.advance"(%95, %13, %14) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %203 = "tt.advance"(%94, %13, %14) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %204 = "tt.advance"(%98, %13, %14) : (!tt.ptr<tensor<32x32xf16>, 1>, i32, i32) -> !tt.ptr<tensor<32x32xf16>, 1>
    "tt.prefetch"(%93) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    "tt.prefetch"(%92) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
    %205 = "tt.advance"(%93, %14, %13) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %206 = "tt.advance"(%92, %14, %13) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
    %207 = "tt.advance"(%97, %14, %13) : (!tt.ptr<tensor<32x32xf16>, 1>, i32, i32) -> !tt.ptr<tensor<32x32xf16>, 1>
    %208 = "tt.advance"(%96, %14, %13) : (!tt.ptr<tensor<32x32xf16>, 1>, i32, i32) -> !tt.ptr<tensor<32x32xf16>, 1>
    %209 = "arith.addi"(%68, %14) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    "cf.br"(%209, %131, %138, %145, %152, %159, %162, %165, %168, %176, %179, %182, %185, %192, %195, %198, %201, %204, %207, %208, %202, %203, %205, %206)[^bb1] : (i32, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, tensor<8x16xf32>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<32x32xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>, !tt.ptr<tensor<8x16xf16>, 1>) -> ()
  ^bb3:  // pred: ^bb1
    %210 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %44, %64) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %211 = "arith.addi"(%44, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %212 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %211, %64) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %213 = "arith.addi"(%44, %17) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %214 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %213, %64) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %215 = "arith.addi"(%44, %7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %216 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %215, %64) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %217 = "arith.addi"(%64, %17) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %218 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %44, %217) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %219 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %211, %217) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %220 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %213, %217) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %221 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %215, %217) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %222 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %44, %66) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %223 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %211, %66) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %224 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %213, %66) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %225 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %215, %66) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %226 = "arith.addi"(%64, %6) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %227 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %44, %226) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %228 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %211, %226) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %229 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %213, %226) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    %230 = "tt.make_tensor_ptr"(%0, %11, %11, %11, %12, %215, %226) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
    "tt.store"(%210, %114) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%212, %113) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%214, %112) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%216, %111) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%218, %110) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%219, %109) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%220, %108) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%221, %107) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%222, %106) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%223, %105) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%224, %104) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%225, %103) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%227, %102) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%228, %101) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%229, %100) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.store"(%230, %99) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
    "tt.return"() : () -> ()
  }) {genx.intel_reqd_sub_group_size = [16 : i32], genx.kernel = 1 : i32, genx.max_work_group_size = [512 : i32, 1 : i32, 1 : i32], noinline = false} : () -> ()
}) {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, triton_gpu.shared = 0 : i32, "triton_gpu.threads-per-warp" = 16 : i32} : () -> ()
%86 = "tt.make_tensor_ptr"(%2, %21, %21, %21, %23, %85, %25) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%92 = "tt.make_tensor_ptr"(%2, %21, %21, %21, %23, %85, %33) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
"tt.prefetch"(%91) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
"tt.prefetch"(%118) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
%148 = "tt.advance"(%91, %25, %27) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%152 = "llvm.insertelement"(%90, %151, %148) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%154 = "tt.advance"(%118, %25, %27) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%158 = "llvm.insertelement"(%117, %157, %154) : (vector<2xi32>, i32, i32) -> vector<2xi32>
"tt.prefetch"(%153) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
"tt.prefetch"(%180) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
%210 = "tt.advance"(%195, %25, %27) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%214 = "llvm.insertelement"(%194, %213, %210) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%216 = "tt.advance"(%201, %25, %27) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%220 = "llvm.insertelement"(%200, %219, %216) : (vector<2xi32>, i32, i32) -> vector<2xi32>
"tt.prefetch"(%215) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
"tt.prefetch"(%242) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
%272 = "tt.advance"(%257, %25, %27) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%276 = "llvm.insertelement"(%256, %275, %272) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%278 = "tt.advance"(%263, %25, %27) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%282 = "llvm.insertelement"(%262, %281, %278) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%292 = "tt.make_tensor_ptr"(%2, %21, %21, %21, %23, %291, %25) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<32x32xf16>, 1>
%313 = "tt.make_tensor_ptr"(%1, %22, %22, %22, %24, %306, %312) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%321 = "tt.make_tensor_ptr"(%1, %22, %22, %22, %24, %306, %320) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
"tt.prefetch"(%318) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
"tt.prefetch"(%347) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
%377 = "tt.advance"(%318, %28, %26) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%381 = "llvm.insertelement"(%317, %380, %378) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%383 = "tt.advance"(%347, %28, %26) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%387 = "llvm.insertelement"(%346, %386, %384) : (vector<2xi32>, i32, i32) -> vector<2xi32>
"tt.prefetch"(%382) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
"tt.prefetch"(%409) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
%439 = "tt.advance"(%424, %28, %26) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%443 = "llvm.insertelement"(%423, %442, %440) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%445 = "tt.advance"(%430, %28, %26) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%449 = "llvm.insertelement"(%429, %448, %446) : (vector<2xi32>, i32, i32) -> vector<2xi32>
"tt.prefetch"(%444) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
"tt.prefetch"(%471) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
%501 = "tt.advance"(%486, %28, %26) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%505 = "llvm.insertelement"(%485, %504, %502) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%507 = "tt.advance"(%492, %28, %26) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%511 = "llvm.insertelement"(%491, %510, %508) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%519 = "tt.make_tensor_ptr"(%1, %22, %22, %22, %24, %26, %518) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<32x32xf16>, 1>
%527 = "tt.make_tensor_ptr"(%1, %22, %22, %22, %24, %26, %526) <{order = array<i32: 1, 0>}> : (!tt.ptr<f16, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<32x32xf16>, 1>
%583 = "tt.load"(%563) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> {DotIdx = 0 : i32} : (!tt.ptr<tensor<32x32xf16>, 1>) -> tensor<32x32xf16>
%612 = "tt.load"(%583) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> {DotIdx = 1 : i32} : (!tt.ptr<tensor<32x32xf16>, 1>) -> tensor<32x32xf16>
%641 = "tt.load"(%603) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> {DotIdx = 1 : i32} : (!tt.ptr<tensor<32x32xf16>, 1>) -> tensor<32x32xf16>
%669 = "tt.cast"(%654) : (tensor<32x32xf16>) -> tensor<32x32xi16>
%671 = "tt.extract"(%670) <{idx = 0 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
%673 = "tt.cast"(%672) : (tensor<8x16xi16>) -> tensor<8x16xf16>
%675 = "tt.cast"(%661) : (tensor<32x32xf16>) -> tensor<16x32xi32>
%677 = "tt.extract"(%676) <{idx = 0 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
%679 = "tt.cast"(%678) : (tensor<8x16xi32>) -> tensor<16x16xf16>
%686 = "tt.extract"(%671) <{idx = 4 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
%688 = "tt.cast"(%687) : (tensor<8x16xi16>) -> tensor<8x16xf16>
%690 = "tt.extract"(%677) <{idx = 1 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
%692 = "tt.cast"(%691) : (tensor<8x16xi32>) -> tensor<16x16xf16>
%698 = "tt.glue"(%697) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%699 = "tt.extract"(%671) <{idx = 1 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
%701 = "tt.cast"(%700) : (tensor<8x16xi16>) -> tensor<8x16xf16>
%708 = "tt.extract"(%672) <{idx = 5 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
%710 = "tt.cast"(%709) : (tensor<8x16xi16>) -> tensor<8x16xf16>
%716 = "tt.glue"(%715) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%717 = "tt.extract"(%672) <{idx = 2 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
%719 = "tt.cast"(%718) : (tensor<8x16xi16>) -> tensor<8x16xf16>
%726 = "tt.extract"(%673) <{idx = 6 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
%728 = "tt.cast"(%727) : (tensor<8x16xi16>) -> tensor<8x16xf16>
%734 = "tt.glue"(%733) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%735 = "tt.extract"(%673) <{idx = 3 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
%737 = "tt.cast"(%736) : (tensor<8x16xi16>) -> tensor<8x16xf16>
%744 = "tt.extract"(%674) <{idx = 7 : i32}> : (tensor<32x32xi16>) -> tensor<8x16xi16>
%746 = "tt.cast"(%745) : (tensor<8x16xi16>) -> tensor<8x16xf16>
%752 = "tt.glue"(%751) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%753 = "tt.extract"(%680) <{idx = 2 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
%755 = "tt.cast"(%754) : (tensor<8x16xi32>) -> tensor<16x16xf16>
%762 = "tt.extract"(%681) <{idx = 3 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
%764 = "tt.cast"(%763) : (tensor<8x16xi32>) -> tensor<16x16xf16>
%770 = "tt.glue"(%769) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%780 = "tt.glue"(%779) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%790 = "tt.glue"(%789) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%800 = "tt.glue"(%799) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%801 = "tt.cast"(%676) : (tensor<32x32xf16>) -> tensor<16x32xi32>
%803 = "tt.extract"(%802) <{idx = 0 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
%805 = "tt.cast"(%804) : (tensor<8x16xi32>) -> tensor<16x16xf16>
%812 = "tt.extract"(%803) <{idx = 1 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
%814 = "tt.cast"(%813) : (tensor<8x16xi32>) -> tensor<16x16xf16>
%820 = "tt.glue"(%819) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%830 = "tt.glue"(%829) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%840 = "tt.glue"(%839) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%850 = "tt.glue"(%849) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%851 = "tt.extract"(%806) <{idx = 2 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
%853 = "tt.cast"(%852) : (tensor<8x16xi32>) -> tensor<16x16xf16>
%860 = "tt.extract"(%807) <{idx = 3 : i32}> : (tensor<16x32xi32>) -> tensor<8x16xi32>
%862 = "tt.cast"(%861) : (tensor<8x16xi32>) -> tensor<16x16xf16>
%868 = "tt.glue"(%867) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%878 = "tt.glue"(%877) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%888 = "tt.glue"(%887) : (tensor<8x16xf32>) -> tensor<8x16xf32>
%898 = "tt.glue"(%897) : (tensor<8x16xf32>) -> tensor<8x16xf32>
"tt.prefetch"(%623) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
"tt.prefetch"(%643) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
%951 = "tt.advance"(%666, %26, %28) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%955 = "llvm.insertelement"(%667, %954, %951) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%957 = "tt.advance"(%664, %26, %28) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%961 = "llvm.insertelement"(%665, %960, %957) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%963 = "tt.advance"(%672, %26, %28) : (!tt.ptr<tensor<32x32xf16>, 1>, i32, i32) -> !tt.ptr<tensor<32x32xf16>, 1>
%967 = "llvm.insertelement"(%673, %966, %963) : (vector<2xi32>, i32, i32) -> vector<2xi32>
"tt.prefetch"(%663) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
"tt.prefetch"(%683) <{cache = 1 : i32, evict = 1 : i32, isVolatile = false}> : (!tt.ptr<tensor<8x16xf16>, 1>) -> ()
%1021 = "tt.advance"(%706, %28, %26) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%1025 = "llvm.insertelement"(%707, %1024, %1022) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%1027 = "tt.advance"(%704, %28, %26) : (!tt.ptr<tensor<8x16xf16>, 1>, i32, i32) -> !tt.ptr<tensor<8x16xf16>, 1>
%1031 = "llvm.insertelement"(%705, %1030, %1028) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%1033 = "tt.advance"(%714, %28, %26) : (!tt.ptr<tensor<32x32xf16>, 1>, i32, i32) -> !tt.ptr<tensor<32x32xf16>, 1>
%1037 = "llvm.insertelement"(%715, %1036, %1034) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%1039 = "tt.advance"(%712, %28, %26) : (!tt.ptr<tensor<32x32xf16>, 1>, i32, i32) -> !tt.ptr<tensor<32x32xf16>, 1>
%1043 = "llvm.insertelement"(%713, %1042, %1040) : (vector<2xi32>, i32, i32) -> vector<2xi32>
%1048 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %335, %624) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1056 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %1055, %624) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1064 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %1063, %624) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1072 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %1071, %624) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1080 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %335, %1079) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1086 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %1055, %1079) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1092 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %1063, %1079) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1098 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %1071, %1079) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1104 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %335, %653) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1110 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %1055, %653) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1116 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %1063, %653) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1122 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %1071, %653) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1130 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %335, %1129) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1136 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %1055, %1129) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1142 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %1063, %1129) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
%1148 = "tt.make_tensor_ptr"(%0, %23, %23, %23, %25, %1071, %1129) <{order = array<i32: 1, 0>}> : (!tt.ptr<f32, 1>, i64, i64, i64, i64, i32, i32) -> !tt.ptr<tensor<8x16xf32>, 1>
"tt.store"(%1053, %749) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1082, %747) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1111, %745) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1140, %743) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1169, %741) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1196, %739) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1223, %737) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1250, %735) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1277, %733) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1304, %731) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1331, %729) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1358, %727) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1387, %725) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1414, %723) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1441, %721) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
"tt.store"(%1468, %719) <{boundaryCheck = array<i32: 0, 1>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<tensor<8x16xf32>, 1>, tensor<8x16xf32>) -> ()
// -----// IR Dump Before ConvertNVGPUToLLVM (convert-nv-gpu-to-llvm) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, triton_gpu.shared = 0 : i32, "triton_gpu.threads-per-warp" = 16 : i32} {
  llvm.func @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {genx.intel_reqd_sub_group_size = [16 : i32], genx.kernel = 1 : i32, genx.max_work_group_size = [512 : i32, 1 : i32, 1 : i32], noinline = false} {
    %0 = builtin.unrealized_conversion_cast %arg2 : !llvm.ptr<1> to !tt.ptr<f32, 1> loc(#loc)
    %1 = builtin.unrealized_conversion_cast %arg1 : !llvm.ptr<1> to !tt.ptr<f16, 1> loc(#loc)
    %2 = builtin.unrealized_conversion_cast %arg0 : !llvm.ptr<1> to !tt.ptr<f16, 1> loc(#loc)
    %3 = llvm.mlir.constant(3 : i32) : i32 loc(#loc)
    %4 = llvm.mlir.constant(7 : i32) : i32 loc(#loc)
    %5 = llvm.mlir.constant(63 : i32) : i32 loc(#loc)
    %6 = llvm.mlir.constant(48 : i32) : i32 loc(#loc)
    %7 = llvm.mlir.constant(24 : i32) : i32 loc(#loc)
    %8 = llvm.mlir.constant(8 : i32) : i32 loc(#loc)
    %9 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %10 = llvm.mlir.constant(256 : i32) : i32 loc(#loc)
    %11 = llvm.mlir.constant(4096 : i64) : i64 loc(#loc)
    %12 = llvm.mlir.constant(1 : i64) : i64 loc(#loc)
    %13 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %14 = llvm.mlir.constant(32 : i32) : i32 loc(#loc)
    %15 = llvm.mlir.constant(dense<0.000000e+00> : vector<8xf32>) : vector<8xf32> loc(#loc)
    %16 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %17 = llvm.mlir.constant(16 : i32) : i32 loc(#loc)
    %18 = llvm.mlir.constant(64 : i32) : i32 loc(#loc)
    %19 = genx.workitem.id.x : i32 loc(#loc)
    %20 = genx.workitem.id.y : i32 loc(#loc)
    %21 = genx.workitem.id.z : i32 loc(#loc)
    %22 = genx.workgroup.dim.x : i32 loc(#loc)
    %23 = genx.workgroup.dim.y : i32 loc(#loc)
    %24 = llvm.mul %21, %23  : i32 loc(#loc)
    %25 = llvm.add %24, %20  : i32 loc(#loc)
    %26 = llvm.mul %25, %22  : i32 loc(#loc)
    %27 = llvm.add %26, %19  : i32 loc(#loc)
    %28 = llvm.mlir.constant(16 : i32) : i32 loc(#loc)
    %29 = llvm.udiv %27, %28  : i32 loc(#loc)
    %30 = genx.workgroup.id.x : i32 loc(#loc)
    %31 = llvm.sdiv %30, %18  : i32 loc(#loc)
    %32 = llvm.mul %31, %9  : i32 loc(#loc)
    %33 = llvm.sub %17, %32  : i32 loc(#loc)
    %34 = llvm.intr.smin(%33, %9)  : (i32, i32) -> i32 loc(#loc)
    %35 = llvm.srem %30, %34  : i32 loc(#loc)
    %36 = llvm.add %32, %35  : i32 loc(#loc)
    %37 = llvm.and %30, %5  : i32 loc(#loc)
    %38 = llvm.sdiv %37, %34  : i32 loc(#loc)
    %39 = llvm.mul %36, %10  : i32 loc(#loc)
    %40 = llvm.mul %29, %8  : i32 loc(#loc)
    %41 = llvm.add %40, %39  : i32 loc(#loc)
    %42 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %43 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %44 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %45 = llvm.insertelement %13, %42[%43 : i32] : vector<2xi32> loc(#loc)
    %46 = llvm.insertelement %41, %45[%44 : i32] : vector<2xi32> loc(#loc)
    %47 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %48 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %49 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %50 = llvm.mul %49, %47  : i32 loc(#loc)
    %51 = llvm.sub %50, %48  : i32 loc(#loc)
    %52 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %53 = llvm.sub %52, %48  : i32 loc(#loc)
    %54 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %55 = llvm.mul %54, %47  : i32 loc(#loc)
    %56 = llvm.sub %55, %48  : i32 loc(#loc)
    %57 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %58 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %59 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %60 = llvm.mul %59, %57  : i32 loc(#loc)
    %61 = llvm.sub %60, %58  : i32 loc(#loc)
    %62 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %63 = llvm.sub %62, %58  : i32 loc(#loc)
    %64 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %65 = llvm.mul %64, %57  : i32 loc(#loc)
    %66 = llvm.sub %65, %58  : i32 loc(#loc)
    %67 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %68 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %69 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %70 = llvm.mul %69, %67  : i32 loc(#loc)
    %71 = llvm.sub %70, %68  : i32 loc(#loc)
    %72 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %73 = llvm.sub %72, %68  : i32 loc(#loc)
    %74 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %75 = llvm.mul %74, %67  : i32 loc(#loc)
    %76 = llvm.sub %75, %68  : i32 loc(#loc)
    %77 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %78 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %79 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %80 = llvm.mul %79, %77  : i32 loc(#loc)
    %81 = llvm.sub %80, %78  : i32 loc(#loc)
    %82 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %83 = llvm.sub %82, %78  : i32 loc(#loc)
    %84 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %85 = llvm.mul %84, %77  : i32 loc(#loc)
    %86 = llvm.sub %85, %78  : i32 loc(#loc)
    %87 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %88 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %89 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %90 = llvm.insertelement %17, %87[%88 : i32] : vector<2xi32> loc(#loc)
    %91 = llvm.insertelement %41, %90[%89 : i32] : vector<2xi32> loc(#loc)
    %92 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %93 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %94 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %95 = llvm.mul %94, %92  : i32 loc(#loc)
    %96 = llvm.sub %95, %93  : i32 loc(#loc)
    %97 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %98 = llvm.sub %97, %93  : i32 loc(#loc)
    %99 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %100 = llvm.mul %99, %92  : i32 loc(#loc)
    %101 = llvm.sub %100, %93  : i32 loc(#loc)
    %102 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %103 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %104 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %105 = llvm.mul %104, %102  : i32 loc(#loc)
    %106 = llvm.sub %105, %103  : i32 loc(#loc)
    %107 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %108 = llvm.sub %107, %103  : i32 loc(#loc)
    %109 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %110 = llvm.mul %109, %102  : i32 loc(#loc)
    %111 = llvm.sub %110, %103  : i32 loc(#loc)
    %112 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %113 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %114 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %115 = llvm.mul %114, %112  : i32 loc(#loc)
    %116 = llvm.sub %115, %113  : i32 loc(#loc)
    %117 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %118 = llvm.sub %117, %113  : i32 loc(#loc)
    %119 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %120 = llvm.mul %119, %112  : i32 loc(#loc)
    %121 = llvm.sub %120, %113  : i32 loc(#loc)
    %122 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %123 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %124 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %125 = llvm.mul %124, %122  : i32 loc(#loc)
    %126 = llvm.sub %125, %123  : i32 loc(#loc)
    %127 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %128 = llvm.sub %127, %123  : i32 loc(#loc)
    %129 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %130 = llvm.mul %129, %122  : i32 loc(#loc)
    %131 = llvm.sub %130, %123  : i32 loc(#loc)
    %132 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %133 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %134 = llvm.extractelement %46[%132 : i32] : vector<2xi32> loc(#loc)
    %135 = llvm.extractelement %46[%133 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %81, %83, %86, %134, %135 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %136 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %137 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %138 = llvm.extractelement %91[%136 : i32] : vector<2xi32> loc(#loc)
    %139 = llvm.extractelement %91[%137 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %126, %128, %131, %138, %139 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %140 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %141 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %142 = llvm.extractelement %46[%140 : i32] : vector<2xi32> loc(#loc)
    %143 = llvm.add %142, %14  : i32 loc(#loc)
    %144 = llvm.insertelement %143, %46[%140 : i32] : vector<2xi32> loc(#loc)
    %145 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %146 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %147 = llvm.extractelement %91[%145 : i32] : vector<2xi32> loc(#loc)
    %148 = llvm.add %147, %14  : i32 loc(#loc)
    %149 = llvm.insertelement %148, %91[%145 : i32] : vector<2xi32> loc(#loc)
    %150 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %151 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %152 = llvm.extractelement %144[%150 : i32] : vector<2xi32> loc(#loc)
    %153 = llvm.extractelement %144[%151 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %71, %73, %76, %152, %153 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %154 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %155 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %156 = llvm.extractelement %149[%154 : i32] : vector<2xi32> loc(#loc)
    %157 = llvm.extractelement %149[%155 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %116, %118, %121, %156, %157 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %158 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %159 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %160 = llvm.extractelement %144[%158 : i32] : vector<2xi32> loc(#loc)
    %161 = llvm.add %160, %14  : i32 loc(#loc)
    %162 = llvm.insertelement %161, %144[%158 : i32] : vector<2xi32> loc(#loc)
    %163 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %164 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %165 = llvm.extractelement %149[%163 : i32] : vector<2xi32> loc(#loc)
    %166 = llvm.add %165, %14  : i32 loc(#loc)
    %167 = llvm.insertelement %166, %149[%163 : i32] : vector<2xi32> loc(#loc)
    %168 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %169 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %170 = llvm.extractelement %162[%168 : i32] : vector<2xi32> loc(#loc)
    %171 = llvm.extractelement %162[%169 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %61, %63, %66, %170, %171 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %172 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %173 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %174 = llvm.extractelement %167[%172 : i32] : vector<2xi32> loc(#loc)
    %175 = llvm.extractelement %167[%173 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %106, %108, %111, %174, %175 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %176 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %177 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %178 = llvm.extractelement %162[%176 : i32] : vector<2xi32> loc(#loc)
    %179 = llvm.add %178, %14  : i32 loc(#loc)
    %180 = llvm.insertelement %179, %162[%176 : i32] : vector<2xi32> loc(#loc)
    %181 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %182 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %183 = llvm.extractelement %167[%181 : i32] : vector<2xi32> loc(#loc)
    %184 = llvm.add %183, %14  : i32 loc(#loc)
    %185 = llvm.insertelement %184, %167[%181 : i32] : vector<2xi32> loc(#loc)
    %186 = llvm.sdiv %29, %9  : i32 loc(#loc)
    %187 = llvm.and %186, %4  : i32 loc(#loc)
    %188 = llvm.mul %187, %14  : i32 loc(#loc)
    %189 = llvm.add %188, %39  : i32 loc(#loc)
    %190 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %191 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %192 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %193 = llvm.insertelement %13, %190[%191 : i32] : vector<2xi32> loc(#loc)
    %194 = llvm.insertelement %189, %193[%192 : i32] : vector<2xi32> loc(#loc)
    %195 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %196 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %197 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %198 = llvm.mul %197, %195  : i32 loc(#loc)
    %199 = llvm.sub %198, %196  : i32 loc(#loc)
    %200 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %201 = llvm.sub %200, %196  : i32 loc(#loc)
    %202 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %203 = llvm.mul %202, %195  : i32 loc(#loc)
    %204 = llvm.sub %203, %196  : i32 loc(#loc)
    %205 = llvm.mul %38, %10  : i32 loc(#loc)
    %206 = llvm.sdiv %29, %8  : i32 loc(#loc)
    %207 = llvm.and %206, %3  : i32 loc(#loc)
    %208 = llvm.mul %207, %8  : i32 loc(#loc)
    %209 = llvm.and %29, %4  : i32 loc(#loc)
    %210 = llvm.mul %209, %14  : i32 loc(#loc)
    %211 = llvm.add %210, %205  : i32 loc(#loc)
    %212 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %213 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %214 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %215 = llvm.insertelement %211, %212[%213 : i32] : vector<2xi32> loc(#loc)
    %216 = llvm.insertelement %208, %215[%214 : i32] : vector<2xi32> loc(#loc)
    %217 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %218 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %219 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %220 = llvm.mul %219, %217  : i32 loc(#loc)
    %221 = llvm.sub %220, %218  : i32 loc(#loc)
    %222 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %223 = llvm.sub %222, %218  : i32 loc(#loc)
    %224 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %225 = llvm.mul %224, %217  : i32 loc(#loc)
    %226 = llvm.sub %225, %218  : i32 loc(#loc)
    %227 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %228 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %229 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %230 = llvm.mul %229, %227  : i32 loc(#loc)
    %231 = llvm.sub %230, %228  : i32 loc(#loc)
    %232 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %233 = llvm.sub %232, %228  : i32 loc(#loc)
    %234 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %235 = llvm.mul %234, %227  : i32 loc(#loc)
    %236 = llvm.sub %235, %228  : i32 loc(#loc)
    %237 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %238 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %239 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %240 = llvm.mul %239, %237  : i32 loc(#loc)
    %241 = llvm.sub %240, %238  : i32 loc(#loc)
    %242 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %243 = llvm.sub %242, %238  : i32 loc(#loc)
    %244 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %245 = llvm.mul %244, %237  : i32 loc(#loc)
    %246 = llvm.sub %245, %238  : i32 loc(#loc)
    %247 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %248 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %249 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %250 = llvm.mul %249, %247  : i32 loc(#loc)
    %251 = llvm.sub %250, %248  : i32 loc(#loc)
    %252 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %253 = llvm.sub %252, %248  : i32 loc(#loc)
    %254 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %255 = llvm.mul %254, %247  : i32 loc(#loc)
    %256 = llvm.sub %255, %248  : i32 loc(#loc)
    %257 = llvm.add %211, %17  : i32 loc(#loc)
    %258 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %259 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %260 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %261 = llvm.insertelement %257, %258[%259 : i32] : vector<2xi32> loc(#loc)
    %262 = llvm.insertelement %208, %261[%260 : i32] : vector<2xi32> loc(#loc)
    %263 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %264 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %265 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %266 = llvm.mul %265, %263  : i32 loc(#loc)
    %267 = llvm.sub %266, %264  : i32 loc(#loc)
    %268 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %269 = llvm.sub %268, %264  : i32 loc(#loc)
    %270 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %271 = llvm.mul %270, %263  : i32 loc(#loc)
    %272 = llvm.sub %271, %264  : i32 loc(#loc)
    %273 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %274 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %275 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %276 = llvm.mul %275, %273  : i32 loc(#loc)
    %277 = llvm.sub %276, %274  : i32 loc(#loc)
    %278 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %279 = llvm.sub %278, %274  : i32 loc(#loc)
    %280 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %281 = llvm.mul %280, %273  : i32 loc(#loc)
    %282 = llvm.sub %281, %274  : i32 loc(#loc)
    %283 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %284 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %285 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %286 = llvm.mul %285, %283  : i32 loc(#loc)
    %287 = llvm.sub %286, %284  : i32 loc(#loc)
    %288 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %289 = llvm.sub %288, %284  : i32 loc(#loc)
    %290 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %291 = llvm.mul %290, %283  : i32 loc(#loc)
    %292 = llvm.sub %291, %284  : i32 loc(#loc)
    %293 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %294 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %295 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %296 = llvm.mul %295, %293  : i32 loc(#loc)
    %297 = llvm.sub %296, %294  : i32 loc(#loc)
    %298 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %299 = llvm.sub %298, %294  : i32 loc(#loc)
    %300 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %301 = llvm.mul %300, %293  : i32 loc(#loc)
    %302 = llvm.sub %301, %294  : i32 loc(#loc)
    %303 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %304 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %305 = llvm.extractelement %216[%303 : i32] : vector<2xi32> loc(#loc)
    %306 = llvm.extractelement %216[%304 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %251, %253, %256, %305, %306 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %307 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %308 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %309 = llvm.extractelement %262[%307 : i32] : vector<2xi32> loc(#loc)
    %310 = llvm.extractelement %262[%308 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %297, %299, %302, %309, %310 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %311 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %312 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %313 = llvm.extractelement %216[%312 : i32] : vector<2xi32> loc(#loc)
    %314 = llvm.add %313, %14  : i32 loc(#loc)
    %315 = llvm.insertelement %314, %216[%312 : i32] : vector<2xi32> loc(#loc)
    %316 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %317 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %318 = llvm.extractelement %262[%317 : i32] : vector<2xi32> loc(#loc)
    %319 = llvm.add %318, %14  : i32 loc(#loc)
    %320 = llvm.insertelement %319, %262[%317 : i32] : vector<2xi32> loc(#loc)
    %321 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %322 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %323 = llvm.extractelement %315[%321 : i32] : vector<2xi32> loc(#loc)
    %324 = llvm.extractelement %315[%322 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %241, %243, %246, %323, %324 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %325 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %326 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %327 = llvm.extractelement %320[%325 : i32] : vector<2xi32> loc(#loc)
    %328 = llvm.extractelement %320[%326 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %287, %289, %292, %327, %328 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %329 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %330 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %331 = llvm.extractelement %315[%330 : i32] : vector<2xi32> loc(#loc)
    %332 = llvm.add %331, %14  : i32 loc(#loc)
    %333 = llvm.insertelement %332, %315[%330 : i32] : vector<2xi32> loc(#loc)
    %334 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %335 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %336 = llvm.extractelement %320[%335 : i32] : vector<2xi32> loc(#loc)
    %337 = llvm.add %336, %14  : i32 loc(#loc)
    %338 = llvm.insertelement %337, %320[%335 : i32] : vector<2xi32> loc(#loc)
    %339 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %340 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %341 = llvm.extractelement %333[%339 : i32] : vector<2xi32> loc(#loc)
    %342 = llvm.extractelement %333[%340 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %231, %233, %236, %341, %342 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %343 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %344 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %345 = llvm.extractelement %338[%343 : i32] : vector<2xi32> loc(#loc)
    %346 = llvm.extractelement %338[%344 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %277, %279, %282, %345, %346 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %347 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %348 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %349 = llvm.extractelement %333[%348 : i32] : vector<2xi32> loc(#loc)
    %350 = llvm.add %349, %14  : i32 loc(#loc)
    %351 = llvm.insertelement %350, %333[%348 : i32] : vector<2xi32> loc(#loc)
    %352 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %353 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %354 = llvm.extractelement %338[%353 : i32] : vector<2xi32> loc(#loc)
    %355 = llvm.add %354, %14  : i32 loc(#loc)
    %356 = llvm.insertelement %355, %338[%353 : i32] : vector<2xi32> loc(#loc)
    %357 = llvm.and %29, %3  : i32 loc(#loc)
    %358 = llvm.mul %357, %18  : i32 loc(#loc)
    %359 = llvm.add %358, %205  : i32 loc(#loc)
    %360 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %361 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %362 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %363 = llvm.insertelement %359, %360[%361 : i32] : vector<2xi32> loc(#loc)
    %364 = llvm.insertelement %13, %363[%362 : i32] : vector<2xi32> loc(#loc)
    %365 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %366 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %367 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %368 = llvm.mul %367, %365  : i32 loc(#loc)
    %369 = llvm.sub %368, %366  : i32 loc(#loc)
    %370 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %371 = llvm.sub %370, %366  : i32 loc(#loc)
    %372 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %373 = llvm.mul %372, %365  : i32 loc(#loc)
    %374 = llvm.sub %373, %366  : i32 loc(#loc)
    %375 = llvm.add %359, %14  : i32 loc(#loc)
    %376 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %377 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %378 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %379 = llvm.insertelement %375, %376[%377 : i32] : vector<2xi32> loc(#loc)
    %380 = llvm.insertelement %13, %379[%378 : i32] : vector<2xi32> loc(#loc)
    %381 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %382 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %383 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %384 = llvm.mul %383, %381  : i32 loc(#loc)
    %385 = llvm.sub %384, %382  : i32 loc(#loc)
    %386 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %387 = llvm.sub %386, %382  : i32 loc(#loc)
    %388 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %389 = llvm.mul %388, %381  : i32 loc(#loc)
    %390 = llvm.sub %389, %382  : i32 loc(#loc)
    llvm.br ^bb1(%13, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %15, %194, %364, %380, %180, %185, %351, %356 : i32, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>) loc(#loc)
  ^bb1(%391: i32 loc(unknown), %392: vector<8xf32> loc(unknown), %393: vector<8xf32> loc(unknown), %394: vector<8xf32> loc(unknown), %395: vector<8xf32> loc(unknown), %396: vector<8xf32> loc(unknown), %397: vector<8xf32> loc(unknown), %398: vector<8xf32> loc(unknown), %399: vector<8xf32> loc(unknown), %400: vector<8xf32> loc(unknown), %401: vector<8xf32> loc(unknown), %402: vector<8xf32> loc(unknown), %403: vector<8xf32> loc(unknown), %404: vector<8xf32> loc(unknown), %405: vector<8xf32> loc(unknown), %406: vector<8xf32> loc(unknown), %407: vector<8xf32> loc(unknown), %408: vector<2xi32> loc(unknown), %409: vector<2xi32> loc(unknown), %410: vector<2xi32> loc(unknown), %411: vector<2xi32> loc(unknown), %412: vector<2xi32> loc(unknown), %413: vector<2xi32> loc(unknown), %414: vector<2xi32> loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %415 = builtin.unrealized_conversion_cast %414 : vector<2xi32> to !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %416 = builtin.unrealized_conversion_cast %413 : vector<2xi32> to !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %417 = builtin.unrealized_conversion_cast %412 : vector<2xi32> to !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %418 = builtin.unrealized_conversion_cast %411 : vector<2xi32> to !tt.ptr<tensor<8x16xf16>, 1> loc(#loc)
    %419 = builtin.unrealized_conversion_cast %410 : vector<2xi32> to !tt.ptr<tensor<32x32xf16>, 1> loc(#loc)
    %420 = builtin.unrealized_conversion_cast %409 : vector<2xi32> to !tt.ptr<tensor<32x32xf16>, 1> loc(#loc)
    %421 = builtin.unrealized_conversion_cast %408 : vector<2xi32> to !tt.ptr<tensor<32x32xf16>, 1> loc(#loc)
    %422 = builtin.unrealized_conversion_cast %407 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %423 = builtin.unrealized_conversion_cast %406 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %424 = builtin.unrealized_conversion_cast %405 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %425 = builtin.unrealized_conversion_cast %404 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %426 = builtin.unrealized_conversion_cast %403 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %427 = builtin.unrealized_conversion_cast %402 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %428 = builtin.unrealized_conversion_cast %401 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %429 = builtin.unrealized_conversion_cast %400 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %430 = builtin.unrealized_conversion_cast %399 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %431 = builtin.unrealized_conversion_cast %398 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %432 = builtin.unrealized_conversion_cast %397 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %433 = builtin.unrealized_conversion_cast %396 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %434 = builtin.unrealized_conversion_cast %395 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %435 = builtin.unrealized_conversion_cast %394 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %436 = builtin.unrealized_conversion_cast %393 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %437 = builtin.unrealized_conversion_cast %392 : vector<8xf32> to tensor<8x16xf32> loc(#loc)
    %438 = llvm.icmp "slt" %391, %16 : i32 loc(#loc)
    llvm.cond_br %438, ^bb2, ^bb3 loc(#loc)
  ^bb2:  // pred: ^bb1
    genx.barrier loc(#loc)
    %439 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %440 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %441 = llvm.extractelement %408[%439 : i32] : vector<2xi32> loc(#loc)
    %442 = llvm.extractelement %408[%440 : i32] : vector<2xi32> loc(#loc)
    %443 = genx.matrix.2Dblockload %arg0, %199, %201, %204, %441, %442 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<64xi16> loc(#loc)
    %444 = llvm.bitcast %443 : vector<64xi16> to vector<64xf16> loc(#loc)
    %445 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %446 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %447 = llvm.extractelement %409[%445 : i32] : vector<2xi32> loc(#loc)
    %448 = llvm.extractelement %409[%446 : i32] : vector<2xi32> loc(#loc)
    %449 = genx.matrix.2Dblockload %arg1, %369, %371, %374, %447, %448 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = true} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<32xi32> loc(#loc)
    %450 = llvm.bitcast %449 : vector<32xi32> to vector<64xf16> loc(#loc)
    %451 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %452 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %453 = llvm.extractelement %410[%451 : i32] : vector<2xi32> loc(#loc)
    %454 = llvm.extractelement %410[%452 : i32] : vector<2xi32> loc(#loc)
    %455 = genx.matrix.2Dblockload %arg1, %385, %387, %390, %453, %454 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = true} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<32xi32> loc(#loc)
    %456 = llvm.bitcast %455 : vector<32xi32> to vector<64xf16> loc(#loc)
    %457 = llvm.bitcast %444 : vector<64xf16> to vector<64xi16> loc(#loc)
    %458 = llvm.shufflevector %457, %457 [0, 1, 2, 3, 4, 5, 6, 7] : vector<64xi16>  loc(#loc)
    %459 = llvm.bitcast %458 : vector<8xi16> to vector<8xf16> loc(#loc)
    %460 = llvm.bitcast %450 : vector<64xf16> to vector<32xi32> loc(#loc)
    %461 = llvm.shufflevector %460, %460 [0, 1, 2, 3, 4, 5, 6, 7] : vector<32xi32>  loc(#loc)
    %462 = llvm.bitcast %461 : vector<8xi32> to vector<16xf16> loc(#loc)
    %463 = llvm.bitcast %459 : vector<8xf16> to vector<8xi16> loc(#loc)
    %464 = llvm.bitcast %462 : vector<16xf16> to vector<8xi32> loc(#loc)
    %465 = genx.matrix.dpas %392, %463, %464 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %466 = llvm.shufflevector %457, %457 [32, 33, 34, 35, 36, 37, 38, 39] : vector<64xi16>  loc(#loc)
    %467 = llvm.bitcast %466 : vector<8xi16> to vector<8xf16> loc(#loc)
    %468 = llvm.shufflevector %460, %460 [8, 9, 10, 11, 12, 13, 14, 15] : vector<32xi32>  loc(#loc)
    %469 = llvm.bitcast %468 : vector<8xi32> to vector<16xf16> loc(#loc)
    %470 = llvm.bitcast %467 : vector<8xf16> to vector<8xi16> loc(#loc)
    %471 = llvm.bitcast %469 : vector<16xf16> to vector<8xi32> loc(#loc)
    %472 = genx.matrix.dpas %465, %470, %471 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %473 = llvm.shufflevector %457, %457 [8, 9, 10, 11, 12, 13, 14, 15] : vector<64xi16>  loc(#loc)
    %474 = llvm.bitcast %473 : vector<8xi16> to vector<8xf16> loc(#loc)
    %475 = llvm.bitcast %474 : vector<8xf16> to vector<8xi16> loc(#loc)
    %476 = llvm.bitcast %462 : vector<16xf16> to vector<8xi32> loc(#loc)
    %477 = genx.matrix.dpas %393, %475, %476 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %478 = llvm.shufflevector %457, %457 [40, 41, 42, 43, 44, 45, 46, 47] : vector<64xi16>  loc(#loc)
    %479 = llvm.bitcast %478 : vector<8xi16> to vector<8xf16> loc(#loc)
    %480 = llvm.bitcast %479 : vector<8xf16> to vector<8xi16> loc(#loc)
    %481 = llvm.bitcast %469 : vector<16xf16> to vector<8xi32> loc(#loc)
    %482 = genx.matrix.dpas %477, %480, %481 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %483 = llvm.shufflevector %457, %457 [16, 17, 18, 19, 20, 21, 22, 23] : vector<64xi16>  loc(#loc)
    %484 = llvm.bitcast %483 : vector<8xi16> to vector<8xf16> loc(#loc)
    %485 = llvm.bitcast %484 : vector<8xf16> to vector<8xi16> loc(#loc)
    %486 = llvm.bitcast %462 : vector<16xf16> to vector<8xi32> loc(#loc)
    %487 = genx.matrix.dpas %394, %485, %486 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %488 = llvm.shufflevector %457, %457 [48, 49, 50, 51, 52, 53, 54, 55] : vector<64xi16>  loc(#loc)
    %489 = llvm.bitcast %488 : vector<8xi16> to vector<8xf16> loc(#loc)
    %490 = llvm.bitcast %489 : vector<8xf16> to vector<8xi16> loc(#loc)
    %491 = llvm.bitcast %469 : vector<16xf16> to vector<8xi32> loc(#loc)
    %492 = genx.matrix.dpas %487, %490, %491 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %493 = llvm.shufflevector %457, %457 [24, 25, 26, 27, 28, 29, 30, 31] : vector<64xi16>  loc(#loc)
    %494 = llvm.bitcast %493 : vector<8xi16> to vector<8xf16> loc(#loc)
    %495 = llvm.bitcast %494 : vector<8xf16> to vector<8xi16> loc(#loc)
    %496 = llvm.bitcast %462 : vector<16xf16> to vector<8xi32> loc(#loc)
    %497 = genx.matrix.dpas %395, %495, %496 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %498 = llvm.shufflevector %457, %457 [56, 57, 58, 59, 60, 61, 62, 63] : vector<64xi16>  loc(#loc)
    %499 = llvm.bitcast %498 : vector<8xi16> to vector<8xf16> loc(#loc)
    %500 = llvm.bitcast %499 : vector<8xf16> to vector<8xi16> loc(#loc)
    %501 = llvm.bitcast %469 : vector<16xf16> to vector<8xi32> loc(#loc)
    %502 = genx.matrix.dpas %497, %500, %501 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %503 = llvm.shufflevector %460, %460 [16, 17, 18, 19, 20, 21, 22, 23] : vector<32xi32>  loc(#loc)
    %504 = llvm.bitcast %503 : vector<8xi32> to vector<16xf16> loc(#loc)
    %505 = llvm.bitcast %459 : vector<8xf16> to vector<8xi16> loc(#loc)
    %506 = llvm.bitcast %504 : vector<16xf16> to vector<8xi32> loc(#loc)
    %507 = genx.matrix.dpas %396, %505, %506 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %508 = llvm.shufflevector %460, %460 [24, 25, 26, 27, 28, 29, 30, 31] : vector<32xi32>  loc(#loc)
    %509 = llvm.bitcast %508 : vector<8xi32> to vector<16xf16> loc(#loc)
    %510 = llvm.bitcast %467 : vector<8xf16> to vector<8xi16> loc(#loc)
    %511 = llvm.bitcast %509 : vector<16xf16> to vector<8xi32> loc(#loc)
    %512 = genx.matrix.dpas %507, %510, %511 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %513 = llvm.bitcast %474 : vector<8xf16> to vector<8xi16> loc(#loc)
    %514 = llvm.bitcast %504 : vector<16xf16> to vector<8xi32> loc(#loc)
    %515 = genx.matrix.dpas %397, %513, %514 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %516 = llvm.bitcast %479 : vector<8xf16> to vector<8xi16> loc(#loc)
    %517 = llvm.bitcast %509 : vector<16xf16> to vector<8xi32> loc(#loc)
    %518 = genx.matrix.dpas %515, %516, %517 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %519 = llvm.bitcast %484 : vector<8xf16> to vector<8xi16> loc(#loc)
    %520 = llvm.bitcast %504 : vector<16xf16> to vector<8xi32> loc(#loc)
    %521 = genx.matrix.dpas %398, %519, %520 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %522 = llvm.bitcast %489 : vector<8xf16> to vector<8xi16> loc(#loc)
    %523 = llvm.bitcast %509 : vector<16xf16> to vector<8xi32> loc(#loc)
    %524 = genx.matrix.dpas %521, %522, %523 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %525 = llvm.bitcast %494 : vector<8xf16> to vector<8xi16> loc(#loc)
    %526 = llvm.bitcast %504 : vector<16xf16> to vector<8xi32> loc(#loc)
    %527 = genx.matrix.dpas %399, %525, %526 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %528 = llvm.bitcast %499 : vector<8xf16> to vector<8xi16> loc(#loc)
    %529 = llvm.bitcast %509 : vector<16xf16> to vector<8xi32> loc(#loc)
    %530 = genx.matrix.dpas %527, %528, %529 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %531 = llvm.bitcast %456 : vector<64xf16> to vector<32xi32> loc(#loc)
    %532 = llvm.shufflevector %531, %531 [0, 1, 2, 3, 4, 5, 6, 7] : vector<32xi32>  loc(#loc)
    %533 = llvm.bitcast %532 : vector<8xi32> to vector<16xf16> loc(#loc)
    %534 = llvm.bitcast %459 : vector<8xf16> to vector<8xi16> loc(#loc)
    %535 = llvm.bitcast %533 : vector<16xf16> to vector<8xi32> loc(#loc)
    %536 = genx.matrix.dpas %400, %534, %535 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %537 = llvm.shufflevector %531, %531 [8, 9, 10, 11, 12, 13, 14, 15] : vector<32xi32>  loc(#loc)
    %538 = llvm.bitcast %537 : vector<8xi32> to vector<16xf16> loc(#loc)
    %539 = llvm.bitcast %467 : vector<8xf16> to vector<8xi16> loc(#loc)
    %540 = llvm.bitcast %538 : vector<16xf16> to vector<8xi32> loc(#loc)
    %541 = genx.matrix.dpas %536, %539, %540 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %542 = llvm.bitcast %474 : vector<8xf16> to vector<8xi16> loc(#loc)
    %543 = llvm.bitcast %533 : vector<16xf16> to vector<8xi32> loc(#loc)
    %544 = genx.matrix.dpas %401, %542, %543 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %545 = llvm.bitcast %479 : vector<8xf16> to vector<8xi16> loc(#loc)
    %546 = llvm.bitcast %538 : vector<16xf16> to vector<8xi32> loc(#loc)
    %547 = genx.matrix.dpas %544, %545, %546 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %548 = llvm.bitcast %484 : vector<8xf16> to vector<8xi16> loc(#loc)
    %549 = llvm.bitcast %533 : vector<16xf16> to vector<8xi32> loc(#loc)
    %550 = genx.matrix.dpas %402, %548, %549 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %551 = llvm.bitcast %489 : vector<8xf16> to vector<8xi16> loc(#loc)
    %552 = llvm.bitcast %538 : vector<16xf16> to vector<8xi32> loc(#loc)
    %553 = genx.matrix.dpas %550, %551, %552 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %554 = llvm.bitcast %494 : vector<8xf16> to vector<8xi16> loc(#loc)
    %555 = llvm.bitcast %533 : vector<16xf16> to vector<8xi32> loc(#loc)
    %556 = genx.matrix.dpas %403, %554, %555 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %557 = llvm.bitcast %499 : vector<8xf16> to vector<8xi16> loc(#loc)
    %558 = llvm.bitcast %538 : vector<16xf16> to vector<8xi32> loc(#loc)
    %559 = genx.matrix.dpas %556, %557, %558 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %560 = llvm.shufflevector %531, %531 [16, 17, 18, 19, 20, 21, 22, 23] : vector<32xi32>  loc(#loc)
    %561 = llvm.bitcast %560 : vector<8xi32> to vector<16xf16> loc(#loc)
    %562 = llvm.bitcast %459 : vector<8xf16> to vector<8xi16> loc(#loc)
    %563 = llvm.bitcast %561 : vector<16xf16> to vector<8xi32> loc(#loc)
    %564 = genx.matrix.dpas %404, %562, %563 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %565 = llvm.shufflevector %531, %531 [24, 25, 26, 27, 28, 29, 30, 31] : vector<32xi32>  loc(#loc)
    %566 = llvm.bitcast %565 : vector<8xi32> to vector<16xf16> loc(#loc)
    %567 = llvm.bitcast %467 : vector<8xf16> to vector<8xi16> loc(#loc)
    %568 = llvm.bitcast %566 : vector<16xf16> to vector<8xi32> loc(#loc)
    %569 = genx.matrix.dpas %564, %567, %568 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %570 = llvm.bitcast %474 : vector<8xf16> to vector<8xi16> loc(#loc)
    %571 = llvm.bitcast %561 : vector<16xf16> to vector<8xi32> loc(#loc)
    %572 = genx.matrix.dpas %405, %570, %571 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %573 = llvm.bitcast %479 : vector<8xf16> to vector<8xi16> loc(#loc)
    %574 = llvm.bitcast %566 : vector<16xf16> to vector<8xi32> loc(#loc)
    %575 = genx.matrix.dpas %572, %573, %574 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %576 = llvm.bitcast %484 : vector<8xf16> to vector<8xi16> loc(#loc)
    %577 = llvm.bitcast %561 : vector<16xf16> to vector<8xi32> loc(#loc)
    %578 = genx.matrix.dpas %406, %576, %577 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %579 = llvm.bitcast %489 : vector<8xf16> to vector<8xi16> loc(#loc)
    %580 = llvm.bitcast %566 : vector<16xf16> to vector<8xi32> loc(#loc)
    %581 = genx.matrix.dpas %578, %579, %580 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %582 = llvm.bitcast %494 : vector<8xf16> to vector<8xi16> loc(#loc)
    %583 = llvm.bitcast %561 : vector<16xf16> to vector<8xi32> loc(#loc)
    %584 = genx.matrix.dpas %407, %582, %583 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %585 = llvm.bitcast %499 : vector<8xf16> to vector<8xi16> loc(#loc)
    %586 = llvm.bitcast %566 : vector<16xf16> to vector<8xi32> loc(#loc)
    %587 = genx.matrix.dpas %584, %585, %586 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %588 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %589 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %590 = llvm.extractelement %411[%588 : i32] : vector<2xi32> loc(#loc)
    %591 = llvm.extractelement %411[%589 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %51, %53, %56, %590, %591 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %592 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %593 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %594 = llvm.extractelement %412[%592 : i32] : vector<2xi32> loc(#loc)
    %595 = llvm.extractelement %412[%593 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %96, %98, %101, %594, %595 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %596 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %597 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %598 = llvm.extractelement %411[%596 : i32] : vector<2xi32> loc(#loc)
    %599 = llvm.add %598, %14  : i32 loc(#loc)
    %600 = llvm.insertelement %599, %411[%596 : i32] : vector<2xi32> loc(#loc)
    %601 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %602 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %603 = llvm.extractelement %412[%601 : i32] : vector<2xi32> loc(#loc)
    %604 = llvm.add %603, %14  : i32 loc(#loc)
    %605 = llvm.insertelement %604, %412[%601 : i32] : vector<2xi32> loc(#loc)
    %606 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %607 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %608 = llvm.extractelement %408[%606 : i32] : vector<2xi32> loc(#loc)
    %609 = llvm.add %608, %14  : i32 loc(#loc)
    %610 = llvm.insertelement %609, %408[%606 : i32] : vector<2xi32> loc(#loc)
    %611 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %612 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %613 = llvm.extractelement %413[%611 : i32] : vector<2xi32> loc(#loc)
    %614 = llvm.extractelement %413[%612 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %221, %223, %226, %613, %614 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %615 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %616 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %617 = llvm.extractelement %414[%615 : i32] : vector<2xi32> loc(#loc)
    %618 = llvm.extractelement %414[%616 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %267, %269, %272, %617, %618 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %619 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %620 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %621 = llvm.extractelement %413[%620 : i32] : vector<2xi32> loc(#loc)
    %622 = llvm.add %621, %14  : i32 loc(#loc)
    %623 = llvm.insertelement %622, %413[%620 : i32] : vector<2xi32> loc(#loc)
    %624 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %625 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %626 = llvm.extractelement %414[%625 : i32] : vector<2xi32> loc(#loc)
    %627 = llvm.add %626, %14  : i32 loc(#loc)
    %628 = llvm.insertelement %627, %414[%625 : i32] : vector<2xi32> loc(#loc)
    %629 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %630 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %631 = llvm.extractelement %409[%630 : i32] : vector<2xi32> loc(#loc)
    %632 = llvm.add %631, %14  : i32 loc(#loc)
    %633 = llvm.insertelement %632, %409[%630 : i32] : vector<2xi32> loc(#loc)
    %634 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %635 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %636 = llvm.extractelement %410[%635 : i32] : vector<2xi32> loc(#loc)
    %637 = llvm.add %636, %14  : i32 loc(#loc)
    %638 = llvm.insertelement %637, %410[%635 : i32] : vector<2xi32> loc(#loc)
    %639 = llvm.add %391, %14  : i32 loc(#loc)
    llvm.br ^bb1(%639, %472, %482, %492, %502, %512, %518, %524, %530, %541, %547, %553, %559, %569, %575, %581, %587, %610, %633, %638, %600, %605, %623, %628 : i32, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>) loc(#loc)
  ^bb3:  // pred: ^bb1
    %640 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %641 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %642 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %643 = llvm.insertelement %359, %640[%641 : i32] : vector<2xi32> loc(#loc)
    %644 = llvm.insertelement %189, %643[%642 : i32] : vector<2xi32> loc(#loc)
    %645 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %646 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %647 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %648 = llvm.mul %647, %645  : i32 loc(#loc)
    %649 = llvm.sub %648, %646  : i32 loc(#loc)
    %650 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %651 = llvm.sub %650, %646  : i32 loc(#loc)
    %652 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %653 = llvm.mul %652, %645  : i32 loc(#loc)
    %654 = llvm.sub %653, %646  : i32 loc(#loc)
    %655 = llvm.add %189, %8  : i32 loc(#loc)
    %656 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %657 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %658 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %659 = llvm.insertelement %359, %656[%657 : i32] : vector<2xi32> loc(#loc)
    %660 = llvm.insertelement %655, %659[%658 : i32] : vector<2xi32> loc(#loc)
    %661 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %662 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %663 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %664 = llvm.mul %663, %661  : i32 loc(#loc)
    %665 = llvm.sub %664, %662  : i32 loc(#loc)
    %666 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %667 = llvm.sub %666, %662  : i32 loc(#loc)
    %668 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %669 = llvm.mul %668, %661  : i32 loc(#loc)
    %670 = llvm.sub %669, %662  : i32 loc(#loc)
    %671 = llvm.add %189, %17  : i32 loc(#loc)
    %672 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %673 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %674 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %675 = llvm.insertelement %359, %672[%673 : i32] : vector<2xi32> loc(#loc)
    %676 = llvm.insertelement %671, %675[%674 : i32] : vector<2xi32> loc(#loc)
    %677 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %678 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %679 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %680 = llvm.mul %679, %677  : i32 loc(#loc)
    %681 = llvm.sub %680, %678  : i32 loc(#loc)
    %682 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %683 = llvm.sub %682, %678  : i32 loc(#loc)
    %684 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %685 = llvm.mul %684, %677  : i32 loc(#loc)
    %686 = llvm.sub %685, %678  : i32 loc(#loc)
    %687 = llvm.add %189, %7  : i32 loc(#loc)
    %688 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %689 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %690 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %691 = llvm.insertelement %359, %688[%689 : i32] : vector<2xi32> loc(#loc)
    %692 = llvm.insertelement %687, %691[%690 : i32] : vector<2xi32> loc(#loc)
    %693 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %694 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %695 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %696 = llvm.mul %695, %693  : i32 loc(#loc)
    %697 = llvm.sub %696, %694  : i32 loc(#loc)
    %698 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %699 = llvm.sub %698, %694  : i32 loc(#loc)
    %700 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %701 = llvm.mul %700, %693  : i32 loc(#loc)
    %702 = llvm.sub %701, %694  : i32 loc(#loc)
    %703 = llvm.add %359, %17  : i32 loc(#loc)
    %704 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %705 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %706 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %707 = llvm.insertelement %703, %704[%705 : i32] : vector<2xi32> loc(#loc)
    %708 = llvm.insertelement %189, %707[%706 : i32] : vector<2xi32> loc(#loc)
    %709 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %710 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %711 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %712 = llvm.mul %711, %709  : i32 loc(#loc)
    %713 = llvm.sub %712, %710  : i32 loc(#loc)
    %714 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %715 = llvm.sub %714, %710  : i32 loc(#loc)
    %716 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %717 = llvm.mul %716, %709  : i32 loc(#loc)
    %718 = llvm.sub %717, %710  : i32 loc(#loc)
    %719 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %720 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %721 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %722 = llvm.insertelement %703, %719[%720 : i32] : vector<2xi32> loc(#loc)
    %723 = llvm.insertelement %655, %722[%721 : i32] : vector<2xi32> loc(#loc)
    %724 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %725 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %726 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %727 = llvm.mul %726, %724  : i32 loc(#loc)
    %728 = llvm.sub %727, %725  : i32 loc(#loc)
    %729 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %730 = llvm.sub %729, %725  : i32 loc(#loc)
    %731 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %732 = llvm.mul %731, %724  : i32 loc(#loc)
    %733 = llvm.sub %732, %725  : i32 loc(#loc)
    %734 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %735 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %736 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %737 = llvm.insertelement %703, %734[%735 : i32] : vector<2xi32> loc(#loc)
    %738 = llvm.insertelement %671, %737[%736 : i32] : vector<2xi32> loc(#loc)
    %739 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %740 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %741 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %742 = llvm.mul %741, %739  : i32 loc(#loc)
    %743 = llvm.sub %742, %740  : i32 loc(#loc)
    %744 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %745 = llvm.sub %744, %740  : i32 loc(#loc)
    %746 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %747 = llvm.mul %746, %739  : i32 loc(#loc)
    %748 = llvm.sub %747, %740  : i32 loc(#loc)
    %749 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %750 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %751 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %752 = llvm.insertelement %703, %749[%750 : i32] : vector<2xi32> loc(#loc)
    %753 = llvm.insertelement %687, %752[%751 : i32] : vector<2xi32> loc(#loc)
    %754 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %755 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %756 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %757 = llvm.mul %756, %754  : i32 loc(#loc)
    %758 = llvm.sub %757, %755  : i32 loc(#loc)
    %759 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %760 = llvm.sub %759, %755  : i32 loc(#loc)
    %761 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %762 = llvm.mul %761, %754  : i32 loc(#loc)
    %763 = llvm.sub %762, %755  : i32 loc(#loc)
    %764 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %765 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %766 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %767 = llvm.insertelement %375, %764[%765 : i32] : vector<2xi32> loc(#loc)
    %768 = llvm.insertelement %189, %767[%766 : i32] : vector<2xi32> loc(#loc)
    %769 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %770 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %771 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %772 = llvm.mul %771, %769  : i32 loc(#loc)
    %773 = llvm.sub %772, %770  : i32 loc(#loc)
    %774 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %775 = llvm.sub %774, %770  : i32 loc(#loc)
    %776 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %777 = llvm.mul %776, %769  : i32 loc(#loc)
    %778 = llvm.sub %777, %770  : i32 loc(#loc)
    %779 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %780 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %781 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %782 = llvm.insertelement %375, %779[%780 : i32] : vector<2xi32> loc(#loc)
    %783 = llvm.insertelement %655, %782[%781 : i32] : vector<2xi32> loc(#loc)
    %784 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %785 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %786 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %787 = llvm.mul %786, %784  : i32 loc(#loc)
    %788 = llvm.sub %787, %785  : i32 loc(#loc)
    %789 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %790 = llvm.sub %789, %785  : i32 loc(#loc)
    %791 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %792 = llvm.mul %791, %784  : i32 loc(#loc)
    %793 = llvm.sub %792, %785  : i32 loc(#loc)
    %794 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %795 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %796 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %797 = llvm.insertelement %375, %794[%795 : i32] : vector<2xi32> loc(#loc)
    %798 = llvm.insertelement %671, %797[%796 : i32] : vector<2xi32> loc(#loc)
    %799 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %800 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %801 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %802 = llvm.mul %801, %799  : i32 loc(#loc)
    %803 = llvm.sub %802, %800  : i32 loc(#loc)
    %804 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %805 = llvm.sub %804, %800  : i32 loc(#loc)
    %806 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %807 = llvm.mul %806, %799  : i32 loc(#loc)
    %808 = llvm.sub %807, %800  : i32 loc(#loc)
    %809 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %810 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %811 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %812 = llvm.insertelement %375, %809[%810 : i32] : vector<2xi32> loc(#loc)
    %813 = llvm.insertelement %687, %812[%811 : i32] : vector<2xi32> loc(#loc)
    %814 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %815 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %816 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %817 = llvm.mul %816, %814  : i32 loc(#loc)
    %818 = llvm.sub %817, %815  : i32 loc(#loc)
    %819 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %820 = llvm.sub %819, %815  : i32 loc(#loc)
    %821 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %822 = llvm.mul %821, %814  : i32 loc(#loc)
    %823 = llvm.sub %822, %815  : i32 loc(#loc)
    %824 = llvm.add %359, %6  : i32 loc(#loc)
    %825 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %826 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %827 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %828 = llvm.insertelement %824, %825[%826 : i32] : vector<2xi32> loc(#loc)
    %829 = llvm.insertelement %189, %828[%827 : i32] : vector<2xi32> loc(#loc)
    %830 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %831 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %832 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %833 = llvm.mul %832, %830  : i32 loc(#loc)
    %834 = llvm.sub %833, %831  : i32 loc(#loc)
    %835 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %836 = llvm.sub %835, %831  : i32 loc(#loc)
    %837 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %838 = llvm.mul %837, %830  : i32 loc(#loc)
    %839 = llvm.sub %838, %831  : i32 loc(#loc)
    %840 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %841 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %842 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %843 = llvm.insertelement %824, %840[%841 : i32] : vector<2xi32> loc(#loc)
    %844 = llvm.insertelement %655, %843[%842 : i32] : vector<2xi32> loc(#loc)
    %845 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %846 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %847 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %848 = llvm.mul %847, %845  : i32 loc(#loc)
    %849 = llvm.sub %848, %846  : i32 loc(#loc)
    %850 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %851 = llvm.sub %850, %846  : i32 loc(#loc)
    %852 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %853 = llvm.mul %852, %845  : i32 loc(#loc)
    %854 = llvm.sub %853, %846  : i32 loc(#loc)
    %855 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %856 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %857 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %858 = llvm.insertelement %824, %855[%856 : i32] : vector<2xi32> loc(#loc)
    %859 = llvm.insertelement %671, %858[%857 : i32] : vector<2xi32> loc(#loc)
    %860 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %861 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %862 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %863 = llvm.mul %862, %860  : i32 loc(#loc)
    %864 = llvm.sub %863, %861  : i32 loc(#loc)
    %865 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %866 = llvm.sub %865, %861  : i32 loc(#loc)
    %867 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %868 = llvm.mul %867, %860  : i32 loc(#loc)
    %869 = llvm.sub %868, %861  : i32 loc(#loc)
    %870 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %871 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %872 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %873 = llvm.insertelement %824, %870[%871 : i32] : vector<2xi32> loc(#loc)
    %874 = llvm.insertelement %687, %873[%872 : i32] : vector<2xi32> loc(#loc)
    %875 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %876 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %877 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %878 = llvm.mul %877, %875  : i32 loc(#loc)
    %879 = llvm.sub %878, %876  : i32 loc(#loc)
    %880 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %881 = llvm.sub %880, %876  : i32 loc(#loc)
    %882 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %883 = llvm.mul %882, %875  : i32 loc(#loc)
    %884 = llvm.sub %883, %876  : i32 loc(#loc)
    %885 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %886 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %887 = llvm.extractelement %644[%885 : i32] : vector<2xi32> loc(#loc)
    %888 = llvm.extractelement %644[%886 : i32] : vector<2xi32> loc(#loc)
    %889 = llvm.bitcast %392 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %649, %651, %654, %887, %888, %889 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %890 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %891 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %892 = llvm.extractelement %660[%890 : i32] : vector<2xi32> loc(#loc)
    %893 = llvm.extractelement %660[%891 : i32] : vector<2xi32> loc(#loc)
    %894 = llvm.bitcast %393 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %665, %667, %670, %892, %893, %894 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %895 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %896 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %897 = llvm.extractelement %676[%895 : i32] : vector<2xi32> loc(#loc)
    %898 = llvm.extractelement %676[%896 : i32] : vector<2xi32> loc(#loc)
    %899 = llvm.bitcast %394 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %681, %683, %686, %897, %898, %899 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %900 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %901 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %902 = llvm.extractelement %692[%900 : i32] : vector<2xi32> loc(#loc)
    %903 = llvm.extractelement %692[%901 : i32] : vector<2xi32> loc(#loc)
    %904 = llvm.bitcast %395 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %697, %699, %702, %902, %903, %904 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %905 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %906 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %907 = llvm.extractelement %708[%905 : i32] : vector<2xi32> loc(#loc)
    %908 = llvm.extractelement %708[%906 : i32] : vector<2xi32> loc(#loc)
    %909 = llvm.bitcast %396 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %713, %715, %718, %907, %908, %909 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %910 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %911 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %912 = llvm.extractelement %723[%910 : i32] : vector<2xi32> loc(#loc)
    %913 = llvm.extractelement %723[%911 : i32] : vector<2xi32> loc(#loc)
    %914 = llvm.bitcast %397 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %728, %730, %733, %912, %913, %914 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %915 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %916 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %917 = llvm.extractelement %738[%915 : i32] : vector<2xi32> loc(#loc)
    %918 = llvm.extractelement %738[%916 : i32] : vector<2xi32> loc(#loc)
    %919 = llvm.bitcast %398 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %743, %745, %748, %917, %918, %919 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %920 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %921 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %922 = llvm.extractelement %753[%920 : i32] : vector<2xi32> loc(#loc)
    %923 = llvm.extractelement %753[%921 : i32] : vector<2xi32> loc(#loc)
    %924 = llvm.bitcast %399 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %758, %760, %763, %922, %923, %924 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %925 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %926 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %927 = llvm.extractelement %768[%925 : i32] : vector<2xi32> loc(#loc)
    %928 = llvm.extractelement %768[%926 : i32] : vector<2xi32> loc(#loc)
    %929 = llvm.bitcast %400 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %773, %775, %778, %927, %928, %929 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %930 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %931 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %932 = llvm.extractelement %783[%930 : i32] : vector<2xi32> loc(#loc)
    %933 = llvm.extractelement %783[%931 : i32] : vector<2xi32> loc(#loc)
    %934 = llvm.bitcast %401 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %788, %790, %793, %932, %933, %934 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %935 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %936 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %937 = llvm.extractelement %798[%935 : i32] : vector<2xi32> loc(#loc)
    %938 = llvm.extractelement %798[%936 : i32] : vector<2xi32> loc(#loc)
    %939 = llvm.bitcast %402 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %803, %805, %808, %937, %938, %939 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %940 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %941 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %942 = llvm.extractelement %813[%940 : i32] : vector<2xi32> loc(#loc)
    %943 = llvm.extractelement %813[%941 : i32] : vector<2xi32> loc(#loc)
    %944 = llvm.bitcast %403 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %818, %820, %823, %942, %943, %944 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %945 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %946 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %947 = llvm.extractelement %829[%945 : i32] : vector<2xi32> loc(#loc)
    %948 = llvm.extractelement %829[%946 : i32] : vector<2xi32> loc(#loc)
    %949 = llvm.bitcast %404 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %834, %836, %839, %947, %948, %949 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %950 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %951 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %952 = llvm.extractelement %844[%950 : i32] : vector<2xi32> loc(#loc)
    %953 = llvm.extractelement %844[%951 : i32] : vector<2xi32> loc(#loc)
    %954 = llvm.bitcast %405 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %849, %851, %854, %952, %953, %954 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %955 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %956 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %957 = llvm.extractelement %859[%955 : i32] : vector<2xi32> loc(#loc)
    %958 = llvm.extractelement %859[%956 : i32] : vector<2xi32> loc(#loc)
    %959 = llvm.bitcast %406 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %864, %866, %869, %957, %958, %959 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %960 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %961 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %962 = llvm.extractelement %874[%960 : i32] : vector<2xi32> loc(#loc)
    %963 = llvm.extractelement %874[%961 : i32] : vector<2xi32> loc(#loc)
    %964 = llvm.bitcast %407 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %879, %881, %884, %962, %963, %964 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    llvm.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before ArithToLLVMConversionPass (convert-arith-to-llvm) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, triton_gpu.shared = 0 : i32, "triton_gpu.threads-per-warp" = 16 : i32} {
  llvm.func @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {genx.intel_reqd_sub_group_size = [16 : i32], genx.kernel = 1 : i32, genx.max_work_group_size = [512 : i32, 1 : i32, 1 : i32], noinline = false} {
    %0 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %1 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %2 = llvm.mlir.constant(64 : i32) : i32 loc(#loc)
    %3 = llvm.mlir.constant(16 : i32) : i32 loc(#loc)
    %4 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %5 = llvm.mlir.constant(dense<0.000000e+00> : vector<8xf32>) : vector<8xf32> loc(#loc)
    %6 = llvm.mlir.constant(32 : i32) : i32 loc(#loc)
    %7 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %8 = llvm.mlir.constant(256 : i32) : i32 loc(#loc)
    %9 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %10 = llvm.mlir.constant(8 : i32) : i32 loc(#loc)
    %11 = llvm.mlir.constant(24 : i32) : i32 loc(#loc)
    %12 = llvm.mlir.constant(48 : i32) : i32 loc(#loc)
    %13 = llvm.mlir.constant(63 : i32) : i32 loc(#loc)
    %14 = llvm.mlir.constant(7 : i32) : i32 loc(#loc)
    %15 = llvm.mlir.constant(3 : i32) : i32 loc(#loc)
    %16 = genx.workitem.id.x : i32 loc(#loc)
    %17 = genx.workitem.id.y : i32 loc(#loc)
    %18 = genx.workitem.id.z : i32 loc(#loc)
    %19 = genx.workgroup.dim.x : i32 loc(#loc)
    %20 = genx.workgroup.dim.y : i32 loc(#loc)
    %21 = llvm.mul %18, %20  : i32 loc(#loc)
    %22 = llvm.add %21, %17  : i32 loc(#loc)
    %23 = llvm.mul %22, %19  : i32 loc(#loc)
    %24 = llvm.add %23, %16  : i32 loc(#loc)
    %25 = llvm.udiv %24, %3  : i32 loc(#loc)
    %26 = genx.workgroup.id.x : i32 loc(#loc)
    %27 = llvm.sdiv %26, %2  : i32 loc(#loc)
    %28 = llvm.mul %27, %9  : i32 loc(#loc)
    %29 = llvm.sub %3, %28  : i32 loc(#loc)
    %30 = llvm.intr.smin(%29, %9)  : (i32, i32) -> i32 loc(#loc)
    %31 = llvm.srem %26, %30  : i32 loc(#loc)
    %32 = llvm.add %28, %31  : i32 loc(#loc)
    %33 = llvm.and %26, %13  : i32 loc(#loc)
    %34 = llvm.sdiv %33, %30  : i32 loc(#loc)
    %35 = llvm.mul %32, %8  : i32 loc(#loc)
    %36 = llvm.mul %25, %10  : i32 loc(#loc)
    %37 = llvm.add %36, %35  : i32 loc(#loc)
    %38 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %39 = llvm.insertelement %7, %38[%7 : i32] : vector<2xi32> loc(#loc)
    %40 = llvm.insertelement %37, %39[%1 : i32] : vector<2xi32> loc(#loc)
    %41 = llvm.mul %4, %0  : i32 loc(#loc)
    %42 = llvm.sub %41, %1  : i32 loc(#loc)
    %43 = llvm.sub %4, %1  : i32 loc(#loc)
    %44 = llvm.mul %4, %0  : i32 loc(#loc)
    %45 = llvm.sub %44, %1  : i32 loc(#loc)
    %46 = llvm.mul %4, %0  : i32 loc(#loc)
    %47 = llvm.sub %46, %1  : i32 loc(#loc)
    %48 = llvm.sub %4, %1  : i32 loc(#loc)
    %49 = llvm.mul %4, %0  : i32 loc(#loc)
    %50 = llvm.sub %49, %1  : i32 loc(#loc)
    %51 = llvm.mul %4, %0  : i32 loc(#loc)
    %52 = llvm.sub %51, %1  : i32 loc(#loc)
    %53 = llvm.sub %4, %1  : i32 loc(#loc)
    %54 = llvm.mul %4, %0  : i32 loc(#loc)
    %55 = llvm.sub %54, %1  : i32 loc(#loc)
    %56 = llvm.mul %4, %0  : i32 loc(#loc)
    %57 = llvm.sub %56, %1  : i32 loc(#loc)
    %58 = llvm.sub %4, %1  : i32 loc(#loc)
    %59 = llvm.mul %4, %0  : i32 loc(#loc)
    %60 = llvm.sub %59, %1  : i32 loc(#loc)
    %61 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %62 = llvm.insertelement %3, %61[%7 : i32] : vector<2xi32> loc(#loc)
    %63 = llvm.insertelement %37, %62[%1 : i32] : vector<2xi32> loc(#loc)
    %64 = llvm.mul %4, %0  : i32 loc(#loc)
    %65 = llvm.sub %64, %1  : i32 loc(#loc)
    %66 = llvm.sub %4, %1  : i32 loc(#loc)
    %67 = llvm.mul %4, %0  : i32 loc(#loc)
    %68 = llvm.sub %67, %1  : i32 loc(#loc)
    %69 = llvm.mul %4, %0  : i32 loc(#loc)
    %70 = llvm.sub %69, %1  : i32 loc(#loc)
    %71 = llvm.sub %4, %1  : i32 loc(#loc)
    %72 = llvm.mul %4, %0  : i32 loc(#loc)
    %73 = llvm.sub %72, %1  : i32 loc(#loc)
    %74 = llvm.mul %4, %0  : i32 loc(#loc)
    %75 = llvm.sub %74, %1  : i32 loc(#loc)
    %76 = llvm.sub %4, %1  : i32 loc(#loc)
    %77 = llvm.mul %4, %0  : i32 loc(#loc)
    %78 = llvm.sub %77, %1  : i32 loc(#loc)
    %79 = llvm.mul %4, %0  : i32 loc(#loc)
    %80 = llvm.sub %79, %1  : i32 loc(#loc)
    %81 = llvm.sub %4, %1  : i32 loc(#loc)
    %82 = llvm.mul %4, %0  : i32 loc(#loc)
    %83 = llvm.sub %82, %1  : i32 loc(#loc)
    %84 = llvm.extractelement %40[%7 : i32] : vector<2xi32> loc(#loc)
    %85 = llvm.extractelement %40[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %57, %58, %60, %84, %85 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %86 = llvm.extractelement %63[%7 : i32] : vector<2xi32> loc(#loc)
    %87 = llvm.extractelement %63[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %80, %81, %83, %86, %87 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %88 = llvm.extractelement %40[%7 : i32] : vector<2xi32> loc(#loc)
    %89 = llvm.add %88, %6  : i32 loc(#loc)
    %90 = llvm.insertelement %89, %40[%7 : i32] : vector<2xi32> loc(#loc)
    %91 = llvm.extractelement %63[%7 : i32] : vector<2xi32> loc(#loc)
    %92 = llvm.add %91, %6  : i32 loc(#loc)
    %93 = llvm.insertelement %92, %63[%7 : i32] : vector<2xi32> loc(#loc)
    %94 = llvm.extractelement %90[%7 : i32] : vector<2xi32> loc(#loc)
    %95 = llvm.extractelement %90[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %52, %53, %55, %94, %95 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %96 = llvm.extractelement %93[%7 : i32] : vector<2xi32> loc(#loc)
    %97 = llvm.extractelement %93[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %75, %76, %78, %96, %97 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %98 = llvm.extractelement %90[%7 : i32] : vector<2xi32> loc(#loc)
    %99 = llvm.add %98, %6  : i32 loc(#loc)
    %100 = llvm.insertelement %99, %90[%7 : i32] : vector<2xi32> loc(#loc)
    %101 = llvm.extractelement %93[%7 : i32] : vector<2xi32> loc(#loc)
    %102 = llvm.add %101, %6  : i32 loc(#loc)
    %103 = llvm.insertelement %102, %93[%7 : i32] : vector<2xi32> loc(#loc)
    %104 = llvm.extractelement %100[%7 : i32] : vector<2xi32> loc(#loc)
    %105 = llvm.extractelement %100[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %47, %48, %50, %104, %105 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %106 = llvm.extractelement %103[%7 : i32] : vector<2xi32> loc(#loc)
    %107 = llvm.extractelement %103[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %70, %71, %73, %106, %107 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %108 = llvm.extractelement %100[%7 : i32] : vector<2xi32> loc(#loc)
    %109 = llvm.add %108, %6  : i32 loc(#loc)
    %110 = llvm.insertelement %109, %100[%7 : i32] : vector<2xi32> loc(#loc)
    %111 = llvm.extractelement %103[%7 : i32] : vector<2xi32> loc(#loc)
    %112 = llvm.add %111, %6  : i32 loc(#loc)
    %113 = llvm.insertelement %112, %103[%7 : i32] : vector<2xi32> loc(#loc)
    %114 = llvm.sdiv %25, %9  : i32 loc(#loc)
    %115 = llvm.and %114, %14  : i32 loc(#loc)
    %116 = llvm.mul %115, %6  : i32 loc(#loc)
    %117 = llvm.add %116, %35  : i32 loc(#loc)
    %118 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %119 = llvm.insertelement %7, %118[%7 : i32] : vector<2xi32> loc(#loc)
    %120 = llvm.insertelement %117, %119[%1 : i32] : vector<2xi32> loc(#loc)
    %121 = llvm.mul %4, %0  : i32 loc(#loc)
    %122 = llvm.sub %121, %1  : i32 loc(#loc)
    %123 = llvm.sub %4, %1  : i32 loc(#loc)
    %124 = llvm.mul %4, %0  : i32 loc(#loc)
    %125 = llvm.sub %124, %1  : i32 loc(#loc)
    %126 = llvm.mul %34, %8  : i32 loc(#loc)
    %127 = llvm.sdiv %25, %10  : i32 loc(#loc)
    %128 = llvm.and %127, %15  : i32 loc(#loc)
    %129 = llvm.mul %128, %10  : i32 loc(#loc)
    %130 = llvm.and %25, %14  : i32 loc(#loc)
    %131 = llvm.mul %130, %6  : i32 loc(#loc)
    %132 = llvm.add %131, %126  : i32 loc(#loc)
    %133 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %134 = llvm.insertelement %132, %133[%7 : i32] : vector<2xi32> loc(#loc)
    %135 = llvm.insertelement %129, %134[%1 : i32] : vector<2xi32> loc(#loc)
    %136 = llvm.mul %4, %0  : i32 loc(#loc)
    %137 = llvm.sub %136, %1  : i32 loc(#loc)
    %138 = llvm.sub %4, %1  : i32 loc(#loc)
    %139 = llvm.mul %4, %0  : i32 loc(#loc)
    %140 = llvm.sub %139, %1  : i32 loc(#loc)
    %141 = llvm.mul %4, %0  : i32 loc(#loc)
    %142 = llvm.sub %141, %1  : i32 loc(#loc)
    %143 = llvm.sub %4, %1  : i32 loc(#loc)
    %144 = llvm.mul %4, %0  : i32 loc(#loc)
    %145 = llvm.sub %144, %1  : i32 loc(#loc)
    %146 = llvm.mul %4, %0  : i32 loc(#loc)
    %147 = llvm.sub %146, %1  : i32 loc(#loc)
    %148 = llvm.sub %4, %1  : i32 loc(#loc)
    %149 = llvm.mul %4, %0  : i32 loc(#loc)
    %150 = llvm.sub %149, %1  : i32 loc(#loc)
    %151 = llvm.mul %4, %0  : i32 loc(#loc)
    %152 = llvm.sub %151, %1  : i32 loc(#loc)
    %153 = llvm.sub %4, %1  : i32 loc(#loc)
    %154 = llvm.mul %4, %0  : i32 loc(#loc)
    %155 = llvm.sub %154, %1  : i32 loc(#loc)
    %156 = llvm.add %132, %3  : i32 loc(#loc)
    %157 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %158 = llvm.insertelement %156, %157[%7 : i32] : vector<2xi32> loc(#loc)
    %159 = llvm.insertelement %129, %158[%1 : i32] : vector<2xi32> loc(#loc)
    %160 = llvm.mul %4, %0  : i32 loc(#loc)
    %161 = llvm.sub %160, %1  : i32 loc(#loc)
    %162 = llvm.sub %4, %1  : i32 loc(#loc)
    %163 = llvm.mul %4, %0  : i32 loc(#loc)
    %164 = llvm.sub %163, %1  : i32 loc(#loc)
    %165 = llvm.mul %4, %0  : i32 loc(#loc)
    %166 = llvm.sub %165, %1  : i32 loc(#loc)
    %167 = llvm.sub %4, %1  : i32 loc(#loc)
    %168 = llvm.mul %4, %0  : i32 loc(#loc)
    %169 = llvm.sub %168, %1  : i32 loc(#loc)
    %170 = llvm.mul %4, %0  : i32 loc(#loc)
    %171 = llvm.sub %170, %1  : i32 loc(#loc)
    %172 = llvm.sub %4, %1  : i32 loc(#loc)
    %173 = llvm.mul %4, %0  : i32 loc(#loc)
    %174 = llvm.sub %173, %1  : i32 loc(#loc)
    %175 = llvm.mul %4, %0  : i32 loc(#loc)
    %176 = llvm.sub %175, %1  : i32 loc(#loc)
    %177 = llvm.sub %4, %1  : i32 loc(#loc)
    %178 = llvm.mul %4, %0  : i32 loc(#loc)
    %179 = llvm.sub %178, %1  : i32 loc(#loc)
    %180 = llvm.extractelement %135[%7 : i32] : vector<2xi32> loc(#loc)
    %181 = llvm.extractelement %135[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %152, %153, %155, %180, %181 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %182 = llvm.extractelement %159[%7 : i32] : vector<2xi32> loc(#loc)
    %183 = llvm.extractelement %159[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %176, %177, %179, %182, %183 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %184 = llvm.extractelement %135[%1 : i32] : vector<2xi32> loc(#loc)
    %185 = llvm.add %184, %6  : i32 loc(#loc)
    %186 = llvm.insertelement %185, %135[%1 : i32] : vector<2xi32> loc(#loc)
    %187 = llvm.extractelement %159[%1 : i32] : vector<2xi32> loc(#loc)
    %188 = llvm.add %187, %6  : i32 loc(#loc)
    %189 = llvm.insertelement %188, %159[%1 : i32] : vector<2xi32> loc(#loc)
    %190 = llvm.extractelement %186[%7 : i32] : vector<2xi32> loc(#loc)
    %191 = llvm.extractelement %186[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %147, %148, %150, %190, %191 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %192 = llvm.extractelement %189[%7 : i32] : vector<2xi32> loc(#loc)
    %193 = llvm.extractelement %189[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %171, %172, %174, %192, %193 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %194 = llvm.extractelement %186[%1 : i32] : vector<2xi32> loc(#loc)
    %195 = llvm.add %194, %6  : i32 loc(#loc)
    %196 = llvm.insertelement %195, %186[%1 : i32] : vector<2xi32> loc(#loc)
    %197 = llvm.extractelement %189[%1 : i32] : vector<2xi32> loc(#loc)
    %198 = llvm.add %197, %6  : i32 loc(#loc)
    %199 = llvm.insertelement %198, %189[%1 : i32] : vector<2xi32> loc(#loc)
    %200 = llvm.extractelement %196[%7 : i32] : vector<2xi32> loc(#loc)
    %201 = llvm.extractelement %196[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %142, %143, %145, %200, %201 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %202 = llvm.extractelement %199[%7 : i32] : vector<2xi32> loc(#loc)
    %203 = llvm.extractelement %199[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %166, %167, %169, %202, %203 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %204 = llvm.extractelement %196[%1 : i32] : vector<2xi32> loc(#loc)
    %205 = llvm.add %204, %6  : i32 loc(#loc)
    %206 = llvm.insertelement %205, %196[%1 : i32] : vector<2xi32> loc(#loc)
    %207 = llvm.extractelement %199[%1 : i32] : vector<2xi32> loc(#loc)
    %208 = llvm.add %207, %6  : i32 loc(#loc)
    %209 = llvm.insertelement %208, %199[%1 : i32] : vector<2xi32> loc(#loc)
    %210 = llvm.and %25, %15  : i32 loc(#loc)
    %211 = llvm.mul %210, %2  : i32 loc(#loc)
    %212 = llvm.add %211, %126  : i32 loc(#loc)
    %213 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %214 = llvm.insertelement %212, %213[%7 : i32] : vector<2xi32> loc(#loc)
    %215 = llvm.insertelement %7, %214[%1 : i32] : vector<2xi32> loc(#loc)
    %216 = llvm.mul %4, %0  : i32 loc(#loc)
    %217 = llvm.sub %216, %1  : i32 loc(#loc)
    %218 = llvm.sub %4, %1  : i32 loc(#loc)
    %219 = llvm.mul %4, %0  : i32 loc(#loc)
    %220 = llvm.sub %219, %1  : i32 loc(#loc)
    %221 = llvm.add %212, %6  : i32 loc(#loc)
    %222 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %223 = llvm.insertelement %221, %222[%7 : i32] : vector<2xi32> loc(#loc)
    %224 = llvm.insertelement %7, %223[%1 : i32] : vector<2xi32> loc(#loc)
    %225 = llvm.mul %4, %0  : i32 loc(#loc)
    %226 = llvm.sub %225, %1  : i32 loc(#loc)
    %227 = llvm.sub %4, %1  : i32 loc(#loc)
    %228 = llvm.mul %4, %0  : i32 loc(#loc)
    %229 = llvm.sub %228, %1  : i32 loc(#loc)
    llvm.br ^bb1(%7, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %120, %215, %224, %110, %113, %206, %209 : i32, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>) loc(#loc)
  ^bb1(%230: i32 loc(unknown), %231: vector<8xf32> loc(unknown), %232: vector<8xf32> loc(unknown), %233: vector<8xf32> loc(unknown), %234: vector<8xf32> loc(unknown), %235: vector<8xf32> loc(unknown), %236: vector<8xf32> loc(unknown), %237: vector<8xf32> loc(unknown), %238: vector<8xf32> loc(unknown), %239: vector<8xf32> loc(unknown), %240: vector<8xf32> loc(unknown), %241: vector<8xf32> loc(unknown), %242: vector<8xf32> loc(unknown), %243: vector<8xf32> loc(unknown), %244: vector<8xf32> loc(unknown), %245: vector<8xf32> loc(unknown), %246: vector<8xf32> loc(unknown), %247: vector<2xi32> loc(unknown), %248: vector<2xi32> loc(unknown), %249: vector<2xi32> loc(unknown), %250: vector<2xi32> loc(unknown), %251: vector<2xi32> loc(unknown), %252: vector<2xi32> loc(unknown), %253: vector<2xi32> loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %254 = llvm.icmp "slt" %230, %4 : i32 loc(#loc)
    llvm.cond_br %254, ^bb2, ^bb3 loc(#loc)
  ^bb2:  // pred: ^bb1
    genx.barrier loc(#loc)
    %255 = llvm.extractelement %247[%7 : i32] : vector<2xi32> loc(#loc)
    %256 = llvm.extractelement %247[%1 : i32] : vector<2xi32> loc(#loc)
    %257 = genx.matrix.2Dblockload %arg0, %122, %123, %125, %255, %256 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<64xi16> loc(#loc)
    %258 = llvm.extractelement %248[%7 : i32] : vector<2xi32> loc(#loc)
    %259 = llvm.extractelement %248[%1 : i32] : vector<2xi32> loc(#loc)
    %260 = genx.matrix.2Dblockload %arg1, %217, %218, %220, %258, %259 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = true} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<32xi32> loc(#loc)
    %261 = llvm.extractelement %249[%7 : i32] : vector<2xi32> loc(#loc)
    %262 = llvm.extractelement %249[%1 : i32] : vector<2xi32> loc(#loc)
    %263 = genx.matrix.2Dblockload %arg1, %226, %227, %229, %261, %262 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = true} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<32xi32> loc(#loc)
    %264 = llvm.shufflevector %257, %257 [0, 1, 2, 3, 4, 5, 6, 7] : vector<64xi16>  loc(#loc)
    %265 = llvm.shufflevector %260, %260 [0, 1, 2, 3, 4, 5, 6, 7] : vector<32xi32>  loc(#loc)
    %266 = genx.matrix.dpas %231, %264, %265 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %267 = llvm.shufflevector %257, %257 [32, 33, 34, 35, 36, 37, 38, 39] : vector<64xi16>  loc(#loc)
    %268 = llvm.shufflevector %260, %260 [8, 9, 10, 11, 12, 13, 14, 15] : vector<32xi32>  loc(#loc)
    %269 = genx.matrix.dpas %266, %267, %268 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %270 = llvm.shufflevector %257, %257 [8, 9, 10, 11, 12, 13, 14, 15] : vector<64xi16>  loc(#loc)
    %271 = genx.matrix.dpas %232, %270, %265 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %272 = llvm.shufflevector %257, %257 [40, 41, 42, 43, 44, 45, 46, 47] : vector<64xi16>  loc(#loc)
    %273 = genx.matrix.dpas %271, %272, %268 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %274 = llvm.shufflevector %257, %257 [16, 17, 18, 19, 20, 21, 22, 23] : vector<64xi16>  loc(#loc)
    %275 = genx.matrix.dpas %233, %274, %265 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %276 = llvm.shufflevector %257, %257 [48, 49, 50, 51, 52, 53, 54, 55] : vector<64xi16>  loc(#loc)
    %277 = genx.matrix.dpas %275, %276, %268 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %278 = llvm.shufflevector %257, %257 [24, 25, 26, 27, 28, 29, 30, 31] : vector<64xi16>  loc(#loc)
    %279 = genx.matrix.dpas %234, %278, %265 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %280 = llvm.shufflevector %257, %257 [56, 57, 58, 59, 60, 61, 62, 63] : vector<64xi16>  loc(#loc)
    %281 = genx.matrix.dpas %279, %280, %268 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %282 = llvm.shufflevector %260, %260 [16, 17, 18, 19, 20, 21, 22, 23] : vector<32xi32>  loc(#loc)
    %283 = genx.matrix.dpas %235, %264, %282 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %284 = llvm.shufflevector %260, %260 [24, 25, 26, 27, 28, 29, 30, 31] : vector<32xi32>  loc(#loc)
    %285 = genx.matrix.dpas %283, %267, %284 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %286 = genx.matrix.dpas %236, %270, %282 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %287 = genx.matrix.dpas %286, %272, %284 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %288 = genx.matrix.dpas %237, %274, %282 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %289 = genx.matrix.dpas %288, %276, %284 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %290 = genx.matrix.dpas %238, %278, %282 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %291 = genx.matrix.dpas %290, %280, %284 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %292 = llvm.shufflevector %263, %263 [0, 1, 2, 3, 4, 5, 6, 7] : vector<32xi32>  loc(#loc)
    %293 = genx.matrix.dpas %239, %264, %292 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %294 = llvm.shufflevector %263, %263 [8, 9, 10, 11, 12, 13, 14, 15] : vector<32xi32>  loc(#loc)
    %295 = genx.matrix.dpas %293, %267, %294 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %296 = genx.matrix.dpas %240, %270, %292 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %297 = genx.matrix.dpas %296, %272, %294 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %298 = genx.matrix.dpas %241, %274, %292 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %299 = genx.matrix.dpas %298, %276, %294 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %300 = genx.matrix.dpas %242, %278, %292 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %301 = genx.matrix.dpas %300, %280, %294 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %302 = llvm.shufflevector %263, %263 [16, 17, 18, 19, 20, 21, 22, 23] : vector<32xi32>  loc(#loc)
    %303 = genx.matrix.dpas %243, %264, %302 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %304 = llvm.shufflevector %263, %263 [24, 25, 26, 27, 28, 29, 30, 31] : vector<32xi32>  loc(#loc)
    %305 = genx.matrix.dpas %303, %267, %304 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %306 = genx.matrix.dpas %244, %270, %302 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %307 = genx.matrix.dpas %306, %272, %304 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %308 = genx.matrix.dpas %245, %274, %302 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %309 = genx.matrix.dpas %308, %276, %304 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %310 = genx.matrix.dpas %246, %278, %302 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %311 = genx.matrix.dpas %310, %280, %304 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %312 = llvm.extractelement %250[%7 : i32] : vector<2xi32> loc(#loc)
    %313 = llvm.extractelement %250[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %42, %43, %45, %312, %313 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %314 = llvm.extractelement %251[%7 : i32] : vector<2xi32> loc(#loc)
    %315 = llvm.extractelement %251[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %65, %66, %68, %314, %315 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %316 = llvm.extractelement %250[%7 : i32] : vector<2xi32> loc(#loc)
    %317 = llvm.add %316, %6  : i32 loc(#loc)
    %318 = llvm.insertelement %317, %250[%7 : i32] : vector<2xi32> loc(#loc)
    %319 = llvm.extractelement %251[%7 : i32] : vector<2xi32> loc(#loc)
    %320 = llvm.add %319, %6  : i32 loc(#loc)
    %321 = llvm.insertelement %320, %251[%7 : i32] : vector<2xi32> loc(#loc)
    %322 = llvm.extractelement %247[%7 : i32] : vector<2xi32> loc(#loc)
    %323 = llvm.add %322, %6  : i32 loc(#loc)
    %324 = llvm.insertelement %323, %247[%7 : i32] : vector<2xi32> loc(#loc)
    %325 = llvm.extractelement %252[%7 : i32] : vector<2xi32> loc(#loc)
    %326 = llvm.extractelement %252[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %137, %138, %140, %325, %326 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %327 = llvm.extractelement %253[%7 : i32] : vector<2xi32> loc(#loc)
    %328 = llvm.extractelement %253[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %161, %162, %164, %327, %328 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %329 = llvm.extractelement %252[%1 : i32] : vector<2xi32> loc(#loc)
    %330 = llvm.add %329, %6  : i32 loc(#loc)
    %331 = llvm.insertelement %330, %252[%1 : i32] : vector<2xi32> loc(#loc)
    %332 = llvm.extractelement %253[%1 : i32] : vector<2xi32> loc(#loc)
    %333 = llvm.add %332, %6  : i32 loc(#loc)
    %334 = llvm.insertelement %333, %253[%1 : i32] : vector<2xi32> loc(#loc)
    %335 = llvm.extractelement %248[%1 : i32] : vector<2xi32> loc(#loc)
    %336 = llvm.add %335, %6  : i32 loc(#loc)
    %337 = llvm.insertelement %336, %248[%1 : i32] : vector<2xi32> loc(#loc)
    %338 = llvm.extractelement %249[%1 : i32] : vector<2xi32> loc(#loc)
    %339 = llvm.add %338, %6  : i32 loc(#loc)
    %340 = llvm.insertelement %339, %249[%1 : i32] : vector<2xi32> loc(#loc)
    %341 = llvm.add %230, %6  : i32 loc(#loc)
    llvm.br ^bb1(%341, %269, %273, %277, %281, %285, %287, %289, %291, %295, %297, %299, %301, %305, %307, %309, %311, %324, %337, %340, %318, %321, %331, %334 : i32, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>) loc(#loc)
  ^bb3:  // pred: ^bb1
    %342 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %343 = llvm.insertelement %212, %342[%7 : i32] : vector<2xi32> loc(#loc)
    %344 = llvm.insertelement %117, %343[%1 : i32] : vector<2xi32> loc(#loc)
    %345 = llvm.mul %4, %9  : i32 loc(#loc)
    %346 = llvm.sub %345, %1  : i32 loc(#loc)
    %347 = llvm.sub %4, %1  : i32 loc(#loc)
    %348 = llvm.mul %4, %9  : i32 loc(#loc)
    %349 = llvm.sub %348, %1  : i32 loc(#loc)
    %350 = llvm.add %117, %10  : i32 loc(#loc)
    %351 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %352 = llvm.insertelement %212, %351[%7 : i32] : vector<2xi32> loc(#loc)
    %353 = llvm.insertelement %350, %352[%1 : i32] : vector<2xi32> loc(#loc)
    %354 = llvm.mul %4, %9  : i32 loc(#loc)
    %355 = llvm.sub %354, %1  : i32 loc(#loc)
    %356 = llvm.sub %4, %1  : i32 loc(#loc)
    %357 = llvm.mul %4, %9  : i32 loc(#loc)
    %358 = llvm.sub %357, %1  : i32 loc(#loc)
    %359 = llvm.add %117, %3  : i32 loc(#loc)
    %360 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %361 = llvm.insertelement %212, %360[%7 : i32] : vector<2xi32> loc(#loc)
    %362 = llvm.insertelement %359, %361[%1 : i32] : vector<2xi32> loc(#loc)
    %363 = llvm.mul %4, %9  : i32 loc(#loc)
    %364 = llvm.sub %363, %1  : i32 loc(#loc)
    %365 = llvm.sub %4, %1  : i32 loc(#loc)
    %366 = llvm.mul %4, %9  : i32 loc(#loc)
    %367 = llvm.sub %366, %1  : i32 loc(#loc)
    %368 = llvm.add %117, %11  : i32 loc(#loc)
    %369 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %370 = llvm.insertelement %212, %369[%7 : i32] : vector<2xi32> loc(#loc)
    %371 = llvm.insertelement %368, %370[%1 : i32] : vector<2xi32> loc(#loc)
    %372 = llvm.mul %4, %9  : i32 loc(#loc)
    %373 = llvm.sub %372, %1  : i32 loc(#loc)
    %374 = llvm.sub %4, %1  : i32 loc(#loc)
    %375 = llvm.mul %4, %9  : i32 loc(#loc)
    %376 = llvm.sub %375, %1  : i32 loc(#loc)
    %377 = llvm.add %212, %3  : i32 loc(#loc)
    %378 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %379 = llvm.insertelement %377, %378[%7 : i32] : vector<2xi32> loc(#loc)
    %380 = llvm.insertelement %117, %379[%1 : i32] : vector<2xi32> loc(#loc)
    %381 = llvm.mul %4, %9  : i32 loc(#loc)
    %382 = llvm.sub %381, %1  : i32 loc(#loc)
    %383 = llvm.sub %4, %1  : i32 loc(#loc)
    %384 = llvm.mul %4, %9  : i32 loc(#loc)
    %385 = llvm.sub %384, %1  : i32 loc(#loc)
    %386 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %387 = llvm.insertelement %377, %386[%7 : i32] : vector<2xi32> loc(#loc)
    %388 = llvm.insertelement %350, %387[%1 : i32] : vector<2xi32> loc(#loc)
    %389 = llvm.mul %4, %9  : i32 loc(#loc)
    %390 = llvm.sub %389, %1  : i32 loc(#loc)
    %391 = llvm.sub %4, %1  : i32 loc(#loc)
    %392 = llvm.mul %4, %9  : i32 loc(#loc)
    %393 = llvm.sub %392, %1  : i32 loc(#loc)
    %394 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %395 = llvm.insertelement %377, %394[%7 : i32] : vector<2xi32> loc(#loc)
    %396 = llvm.insertelement %359, %395[%1 : i32] : vector<2xi32> loc(#loc)
    %397 = llvm.mul %4, %9  : i32 loc(#loc)
    %398 = llvm.sub %397, %1  : i32 loc(#loc)
    %399 = llvm.sub %4, %1  : i32 loc(#loc)
    %400 = llvm.mul %4, %9  : i32 loc(#loc)
    %401 = llvm.sub %400, %1  : i32 loc(#loc)
    %402 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %403 = llvm.insertelement %377, %402[%7 : i32] : vector<2xi32> loc(#loc)
    %404 = llvm.insertelement %368, %403[%1 : i32] : vector<2xi32> loc(#loc)
    %405 = llvm.mul %4, %9  : i32 loc(#loc)
    %406 = llvm.sub %405, %1  : i32 loc(#loc)
    %407 = llvm.sub %4, %1  : i32 loc(#loc)
    %408 = llvm.mul %4, %9  : i32 loc(#loc)
    %409 = llvm.sub %408, %1  : i32 loc(#loc)
    %410 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %411 = llvm.insertelement %221, %410[%7 : i32] : vector<2xi32> loc(#loc)
    %412 = llvm.insertelement %117, %411[%1 : i32] : vector<2xi32> loc(#loc)
    %413 = llvm.mul %4, %9  : i32 loc(#loc)
    %414 = llvm.sub %413, %1  : i32 loc(#loc)
    %415 = llvm.sub %4, %1  : i32 loc(#loc)
    %416 = llvm.mul %4, %9  : i32 loc(#loc)
    %417 = llvm.sub %416, %1  : i32 loc(#loc)
    %418 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %419 = llvm.insertelement %221, %418[%7 : i32] : vector<2xi32> loc(#loc)
    %420 = llvm.insertelement %350, %419[%1 : i32] : vector<2xi32> loc(#loc)
    %421 = llvm.mul %4, %9  : i32 loc(#loc)
    %422 = llvm.sub %421, %1  : i32 loc(#loc)
    %423 = llvm.sub %4, %1  : i32 loc(#loc)
    %424 = llvm.mul %4, %9  : i32 loc(#loc)
    %425 = llvm.sub %424, %1  : i32 loc(#loc)
    %426 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %427 = llvm.insertelement %221, %426[%7 : i32] : vector<2xi32> loc(#loc)
    %428 = llvm.insertelement %359, %427[%1 : i32] : vector<2xi32> loc(#loc)
    %429 = llvm.mul %4, %9  : i32 loc(#loc)
    %430 = llvm.sub %429, %1  : i32 loc(#loc)
    %431 = llvm.sub %4, %1  : i32 loc(#loc)
    %432 = llvm.mul %4, %9  : i32 loc(#loc)
    %433 = llvm.sub %432, %1  : i32 loc(#loc)
    %434 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %435 = llvm.insertelement %221, %434[%7 : i32] : vector<2xi32> loc(#loc)
    %436 = llvm.insertelement %368, %435[%1 : i32] : vector<2xi32> loc(#loc)
    %437 = llvm.mul %4, %9  : i32 loc(#loc)
    %438 = llvm.sub %437, %1  : i32 loc(#loc)
    %439 = llvm.sub %4, %1  : i32 loc(#loc)
    %440 = llvm.mul %4, %9  : i32 loc(#loc)
    %441 = llvm.sub %440, %1  : i32 loc(#loc)
    %442 = llvm.add %212, %12  : i32 loc(#loc)
    %443 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %444 = llvm.insertelement %442, %443[%7 : i32] : vector<2xi32> loc(#loc)
    %445 = llvm.insertelement %117, %444[%1 : i32] : vector<2xi32> loc(#loc)
    %446 = llvm.mul %4, %9  : i32 loc(#loc)
    %447 = llvm.sub %446, %1  : i32 loc(#loc)
    %448 = llvm.sub %4, %1  : i32 loc(#loc)
    %449 = llvm.mul %4, %9  : i32 loc(#loc)
    %450 = llvm.sub %449, %1  : i32 loc(#loc)
    %451 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %452 = llvm.insertelement %442, %451[%7 : i32] : vector<2xi32> loc(#loc)
    %453 = llvm.insertelement %350, %452[%1 : i32] : vector<2xi32> loc(#loc)
    %454 = llvm.mul %4, %9  : i32 loc(#loc)
    %455 = llvm.sub %454, %1  : i32 loc(#loc)
    %456 = llvm.sub %4, %1  : i32 loc(#loc)
    %457 = llvm.mul %4, %9  : i32 loc(#loc)
    %458 = llvm.sub %457, %1  : i32 loc(#loc)
    %459 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %460 = llvm.insertelement %442, %459[%7 : i32] : vector<2xi32> loc(#loc)
    %461 = llvm.insertelement %359, %460[%1 : i32] : vector<2xi32> loc(#loc)
    %462 = llvm.mul %4, %9  : i32 loc(#loc)
    %463 = llvm.sub %462, %1  : i32 loc(#loc)
    %464 = llvm.sub %4, %1  : i32 loc(#loc)
    %465 = llvm.mul %4, %9  : i32 loc(#loc)
    %466 = llvm.sub %465, %1  : i32 loc(#loc)
    %467 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %468 = llvm.insertelement %442, %467[%7 : i32] : vector<2xi32> loc(#loc)
    %469 = llvm.insertelement %368, %468[%1 : i32] : vector<2xi32> loc(#loc)
    %470 = llvm.mul %4, %9  : i32 loc(#loc)
    %471 = llvm.sub %470, %1  : i32 loc(#loc)
    %472 = llvm.sub %4, %1  : i32 loc(#loc)
    %473 = llvm.mul %4, %9  : i32 loc(#loc)
    %474 = llvm.sub %473, %1  : i32 loc(#loc)
    %475 = llvm.extractelement %344[%7 : i32] : vector<2xi32> loc(#loc)
    %476 = llvm.extractelement %344[%1 : i32] : vector<2xi32> loc(#loc)
    %477 = llvm.bitcast %231 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %346, %347, %349, %475, %476, %477 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %478 = llvm.extractelement %353[%7 : i32] : vector<2xi32> loc(#loc)
    %479 = llvm.extractelement %353[%1 : i32] : vector<2xi32> loc(#loc)
    %480 = llvm.bitcast %232 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %355, %356, %358, %478, %479, %480 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %481 = llvm.extractelement %362[%7 : i32] : vector<2xi32> loc(#loc)
    %482 = llvm.extractelement %362[%1 : i32] : vector<2xi32> loc(#loc)
    %483 = llvm.bitcast %233 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %364, %365, %367, %481, %482, %483 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %484 = llvm.extractelement %371[%7 : i32] : vector<2xi32> loc(#loc)
    %485 = llvm.extractelement %371[%1 : i32] : vector<2xi32> loc(#loc)
    %486 = llvm.bitcast %234 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %373, %374, %376, %484, %485, %486 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %487 = llvm.extractelement %380[%7 : i32] : vector<2xi32> loc(#loc)
    %488 = llvm.extractelement %380[%1 : i32] : vector<2xi32> loc(#loc)
    %489 = llvm.bitcast %235 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %382, %383, %385, %487, %488, %489 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %490 = llvm.extractelement %388[%7 : i32] : vector<2xi32> loc(#loc)
    %491 = llvm.extractelement %388[%1 : i32] : vector<2xi32> loc(#loc)
    %492 = llvm.bitcast %236 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %390, %391, %393, %490, %491, %492 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %493 = llvm.extractelement %396[%7 : i32] : vector<2xi32> loc(#loc)
    %494 = llvm.extractelement %396[%1 : i32] : vector<2xi32> loc(#loc)
    %495 = llvm.bitcast %237 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %398, %399, %401, %493, %494, %495 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %496 = llvm.extractelement %404[%7 : i32] : vector<2xi32> loc(#loc)
    %497 = llvm.extractelement %404[%1 : i32] : vector<2xi32> loc(#loc)
    %498 = llvm.bitcast %238 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %406, %407, %409, %496, %497, %498 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %499 = llvm.extractelement %412[%7 : i32] : vector<2xi32> loc(#loc)
    %500 = llvm.extractelement %412[%1 : i32] : vector<2xi32> loc(#loc)
    %501 = llvm.bitcast %239 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %414, %415, %417, %499, %500, %501 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %502 = llvm.extractelement %420[%7 : i32] : vector<2xi32> loc(#loc)
    %503 = llvm.extractelement %420[%1 : i32] : vector<2xi32> loc(#loc)
    %504 = llvm.bitcast %240 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %422, %423, %425, %502, %503, %504 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %505 = llvm.extractelement %428[%7 : i32] : vector<2xi32> loc(#loc)
    %506 = llvm.extractelement %428[%1 : i32] : vector<2xi32> loc(#loc)
    %507 = llvm.bitcast %241 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %430, %431, %433, %505, %506, %507 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %508 = llvm.extractelement %436[%7 : i32] : vector<2xi32> loc(#loc)
    %509 = llvm.extractelement %436[%1 : i32] : vector<2xi32> loc(#loc)
    %510 = llvm.bitcast %242 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %438, %439, %441, %508, %509, %510 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %511 = llvm.extractelement %445[%7 : i32] : vector<2xi32> loc(#loc)
    %512 = llvm.extractelement %445[%1 : i32] : vector<2xi32> loc(#loc)
    %513 = llvm.bitcast %243 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %447, %448, %450, %511, %512, %513 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %514 = llvm.extractelement %453[%7 : i32] : vector<2xi32> loc(#loc)
    %515 = llvm.extractelement %453[%1 : i32] : vector<2xi32> loc(#loc)
    %516 = llvm.bitcast %244 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %455, %456, %458, %514, %515, %516 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %517 = llvm.extractelement %461[%7 : i32] : vector<2xi32> loc(#loc)
    %518 = llvm.extractelement %461[%1 : i32] : vector<2xi32> loc(#loc)
    %519 = llvm.bitcast %245 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %463, %464, %466, %517, %518, %519 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %520 = llvm.extractelement %469[%7 : i32] : vector<2xi32> loc(#loc)
    %521 = llvm.extractelement %469[%1 : i32] : vector<2xi32> loc(#loc)
    %522 = llvm.bitcast %246 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %471, %472, %474, %520, %521, %522 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    llvm.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before Canonicalizer (canonicalize) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, triton_gpu.shared = 0 : i32, "triton_gpu.threads-per-warp" = 16 : i32} {
  llvm.func @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {genx.intel_reqd_sub_group_size = [16 : i32], genx.kernel = 1 : i32, genx.max_work_group_size = [512 : i32, 1 : i32, 1 : i32], noinline = false} {
    %0 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %1 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %2 = llvm.mlir.constant(64 : i32) : i32 loc(#loc)
    %3 = llvm.mlir.constant(16 : i32) : i32 loc(#loc)
    %4 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %5 = llvm.mlir.constant(dense<0.000000e+00> : vector<8xf32>) : vector<8xf32> loc(#loc)
    %6 = llvm.mlir.constant(32 : i32) : i32 loc(#loc)
    %7 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %8 = llvm.mlir.constant(256 : i32) : i32 loc(#loc)
    %9 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %10 = llvm.mlir.constant(8 : i32) : i32 loc(#loc)
    %11 = llvm.mlir.constant(24 : i32) : i32 loc(#loc)
    %12 = llvm.mlir.constant(48 : i32) : i32 loc(#loc)
    %13 = llvm.mlir.constant(63 : i32) : i32 loc(#loc)
    %14 = llvm.mlir.constant(7 : i32) : i32 loc(#loc)
    %15 = llvm.mlir.constant(3 : i32) : i32 loc(#loc)
    %16 = genx.workitem.id.x : i32 loc(#loc)
    %17 = genx.workitem.id.y : i32 loc(#loc)
    %18 = genx.workitem.id.z : i32 loc(#loc)
    %19 = genx.workgroup.dim.x : i32 loc(#loc)
    %20 = genx.workgroup.dim.y : i32 loc(#loc)
    %21 = llvm.mul %18, %20  : i32 loc(#loc)
    %22 = llvm.add %21, %17  : i32 loc(#loc)
    %23 = llvm.mul %22, %19  : i32 loc(#loc)
    %24 = llvm.add %23, %16  : i32 loc(#loc)
    %25 = llvm.udiv %24, %3  : i32 loc(#loc)
    %26 = genx.workgroup.id.x : i32 loc(#loc)
    %27 = llvm.sdiv %26, %2  : i32 loc(#loc)
    %28 = llvm.mul %27, %9  : i32 loc(#loc)
    %29 = llvm.sub %3, %28  : i32 loc(#loc)
    %30 = llvm.intr.smin(%29, %9)  : (i32, i32) -> i32 loc(#loc)
    %31 = llvm.srem %26, %30  : i32 loc(#loc)
    %32 = llvm.add %28, %31  : i32 loc(#loc)
    %33 = llvm.and %26, %13  : i32 loc(#loc)
    %34 = llvm.sdiv %33, %30  : i32 loc(#loc)
    %35 = llvm.mul %32, %8  : i32 loc(#loc)
    %36 = llvm.mul %25, %10  : i32 loc(#loc)
    %37 = llvm.add %36, %35  : i32 loc(#loc)
    %38 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %39 = llvm.insertelement %7, %38[%7 : i32] : vector<2xi32> loc(#loc)
    %40 = llvm.insertelement %37, %39[%1 : i32] : vector<2xi32> loc(#loc)
    %41 = llvm.mul %4, %0  : i32 loc(#loc)
    %42 = llvm.sub %41, %1  : i32 loc(#loc)
    %43 = llvm.sub %4, %1  : i32 loc(#loc)
    %44 = llvm.mul %4, %0  : i32 loc(#loc)
    %45 = llvm.sub %44, %1  : i32 loc(#loc)
    %46 = llvm.mul %4, %0  : i32 loc(#loc)
    %47 = llvm.sub %46, %1  : i32 loc(#loc)
    %48 = llvm.sub %4, %1  : i32 loc(#loc)
    %49 = llvm.mul %4, %0  : i32 loc(#loc)
    %50 = llvm.sub %49, %1  : i32 loc(#loc)
    %51 = llvm.mul %4, %0  : i32 loc(#loc)
    %52 = llvm.sub %51, %1  : i32 loc(#loc)
    %53 = llvm.sub %4, %1  : i32 loc(#loc)
    %54 = llvm.mul %4, %0  : i32 loc(#loc)
    %55 = llvm.sub %54, %1  : i32 loc(#loc)
    %56 = llvm.mul %4, %0  : i32 loc(#loc)
    %57 = llvm.sub %56, %1  : i32 loc(#loc)
    %58 = llvm.sub %4, %1  : i32 loc(#loc)
    %59 = llvm.mul %4, %0  : i32 loc(#loc)
    %60 = llvm.sub %59, %1  : i32 loc(#loc)
    %61 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %62 = llvm.insertelement %3, %61[%7 : i32] : vector<2xi32> loc(#loc)
    %63 = llvm.insertelement %37, %62[%1 : i32] : vector<2xi32> loc(#loc)
    %64 = llvm.mul %4, %0  : i32 loc(#loc)
    %65 = llvm.sub %64, %1  : i32 loc(#loc)
    %66 = llvm.sub %4, %1  : i32 loc(#loc)
    %67 = llvm.mul %4, %0  : i32 loc(#loc)
    %68 = llvm.sub %67, %1  : i32 loc(#loc)
    %69 = llvm.mul %4, %0  : i32 loc(#loc)
    %70 = llvm.sub %69, %1  : i32 loc(#loc)
    %71 = llvm.sub %4, %1  : i32 loc(#loc)
    %72 = llvm.mul %4, %0  : i32 loc(#loc)
    %73 = llvm.sub %72, %1  : i32 loc(#loc)
    %74 = llvm.mul %4, %0  : i32 loc(#loc)
    %75 = llvm.sub %74, %1  : i32 loc(#loc)
    %76 = llvm.sub %4, %1  : i32 loc(#loc)
    %77 = llvm.mul %4, %0  : i32 loc(#loc)
    %78 = llvm.sub %77, %1  : i32 loc(#loc)
    %79 = llvm.mul %4, %0  : i32 loc(#loc)
    %80 = llvm.sub %79, %1  : i32 loc(#loc)
    %81 = llvm.sub %4, %1  : i32 loc(#loc)
    %82 = llvm.mul %4, %0  : i32 loc(#loc)
    %83 = llvm.sub %82, %1  : i32 loc(#loc)
    %84 = llvm.extractelement %40[%7 : i32] : vector<2xi32> loc(#loc)
    %85 = llvm.extractelement %40[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %57, %58, %60, %84, %85 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %86 = llvm.extractelement %63[%7 : i32] : vector<2xi32> loc(#loc)
    %87 = llvm.extractelement %63[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %80, %81, %83, %86, %87 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %88 = llvm.extractelement %40[%7 : i32] : vector<2xi32> loc(#loc)
    %89 = llvm.add %88, %6  : i32 loc(#loc)
    %90 = llvm.insertelement %89, %40[%7 : i32] : vector<2xi32> loc(#loc)
    %91 = llvm.extractelement %63[%7 : i32] : vector<2xi32> loc(#loc)
    %92 = llvm.add %91, %6  : i32 loc(#loc)
    %93 = llvm.insertelement %92, %63[%7 : i32] : vector<2xi32> loc(#loc)
    %94 = llvm.extractelement %90[%7 : i32] : vector<2xi32> loc(#loc)
    %95 = llvm.extractelement %90[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %52, %53, %55, %94, %95 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %96 = llvm.extractelement %93[%7 : i32] : vector<2xi32> loc(#loc)
    %97 = llvm.extractelement %93[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %75, %76, %78, %96, %97 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %98 = llvm.extractelement %90[%7 : i32] : vector<2xi32> loc(#loc)
    %99 = llvm.add %98, %6  : i32 loc(#loc)
    %100 = llvm.insertelement %99, %90[%7 : i32] : vector<2xi32> loc(#loc)
    %101 = llvm.extractelement %93[%7 : i32] : vector<2xi32> loc(#loc)
    %102 = llvm.add %101, %6  : i32 loc(#loc)
    %103 = llvm.insertelement %102, %93[%7 : i32] : vector<2xi32> loc(#loc)
    %104 = llvm.extractelement %100[%7 : i32] : vector<2xi32> loc(#loc)
    %105 = llvm.extractelement %100[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %47, %48, %50, %104, %105 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %106 = llvm.extractelement %103[%7 : i32] : vector<2xi32> loc(#loc)
    %107 = llvm.extractelement %103[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %70, %71, %73, %106, %107 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %108 = llvm.extractelement %100[%7 : i32] : vector<2xi32> loc(#loc)
    %109 = llvm.add %108, %6  : i32 loc(#loc)
    %110 = llvm.insertelement %109, %100[%7 : i32] : vector<2xi32> loc(#loc)
    %111 = llvm.extractelement %103[%7 : i32] : vector<2xi32> loc(#loc)
    %112 = llvm.add %111, %6  : i32 loc(#loc)
    %113 = llvm.insertelement %112, %103[%7 : i32] : vector<2xi32> loc(#loc)
    %114 = llvm.sdiv %25, %9  : i32 loc(#loc)
    %115 = llvm.and %114, %14  : i32 loc(#loc)
    %116 = llvm.mul %115, %6  : i32 loc(#loc)
    %117 = llvm.add %116, %35  : i32 loc(#loc)
    %118 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %119 = llvm.insertelement %7, %118[%7 : i32] : vector<2xi32> loc(#loc)
    %120 = llvm.insertelement %117, %119[%1 : i32] : vector<2xi32> loc(#loc)
    %121 = llvm.mul %4, %0  : i32 loc(#loc)
    %122 = llvm.sub %121, %1  : i32 loc(#loc)
    %123 = llvm.sub %4, %1  : i32 loc(#loc)
    %124 = llvm.mul %4, %0  : i32 loc(#loc)
    %125 = llvm.sub %124, %1  : i32 loc(#loc)
    %126 = llvm.mul %34, %8  : i32 loc(#loc)
    %127 = llvm.sdiv %25, %10  : i32 loc(#loc)
    %128 = llvm.and %127, %15  : i32 loc(#loc)
    %129 = llvm.mul %128, %10  : i32 loc(#loc)
    %130 = llvm.and %25, %14  : i32 loc(#loc)
    %131 = llvm.mul %130, %6  : i32 loc(#loc)
    %132 = llvm.add %131, %126  : i32 loc(#loc)
    %133 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %134 = llvm.insertelement %132, %133[%7 : i32] : vector<2xi32> loc(#loc)
    %135 = llvm.insertelement %129, %134[%1 : i32] : vector<2xi32> loc(#loc)
    %136 = llvm.mul %4, %0  : i32 loc(#loc)
    %137 = llvm.sub %136, %1  : i32 loc(#loc)
    %138 = llvm.sub %4, %1  : i32 loc(#loc)
    %139 = llvm.mul %4, %0  : i32 loc(#loc)
    %140 = llvm.sub %139, %1  : i32 loc(#loc)
    %141 = llvm.mul %4, %0  : i32 loc(#loc)
    %142 = llvm.sub %141, %1  : i32 loc(#loc)
    %143 = llvm.sub %4, %1  : i32 loc(#loc)
    %144 = llvm.mul %4, %0  : i32 loc(#loc)
    %145 = llvm.sub %144, %1  : i32 loc(#loc)
    %146 = llvm.mul %4, %0  : i32 loc(#loc)
    %147 = llvm.sub %146, %1  : i32 loc(#loc)
    %148 = llvm.sub %4, %1  : i32 loc(#loc)
    %149 = llvm.mul %4, %0  : i32 loc(#loc)
    %150 = llvm.sub %149, %1  : i32 loc(#loc)
    %151 = llvm.mul %4, %0  : i32 loc(#loc)
    %152 = llvm.sub %151, %1  : i32 loc(#loc)
    %153 = llvm.sub %4, %1  : i32 loc(#loc)
    %154 = llvm.mul %4, %0  : i32 loc(#loc)
    %155 = llvm.sub %154, %1  : i32 loc(#loc)
    %156 = llvm.add %132, %3  : i32 loc(#loc)
    %157 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %158 = llvm.insertelement %156, %157[%7 : i32] : vector<2xi32> loc(#loc)
    %159 = llvm.insertelement %129, %158[%1 : i32] : vector<2xi32> loc(#loc)
    %160 = llvm.mul %4, %0  : i32 loc(#loc)
    %161 = llvm.sub %160, %1  : i32 loc(#loc)
    %162 = llvm.sub %4, %1  : i32 loc(#loc)
    %163 = llvm.mul %4, %0  : i32 loc(#loc)
    %164 = llvm.sub %163, %1  : i32 loc(#loc)
    %165 = llvm.mul %4, %0  : i32 loc(#loc)
    %166 = llvm.sub %165, %1  : i32 loc(#loc)
    %167 = llvm.sub %4, %1  : i32 loc(#loc)
    %168 = llvm.mul %4, %0  : i32 loc(#loc)
    %169 = llvm.sub %168, %1  : i32 loc(#loc)
    %170 = llvm.mul %4, %0  : i32 loc(#loc)
    %171 = llvm.sub %170, %1  : i32 loc(#loc)
    %172 = llvm.sub %4, %1  : i32 loc(#loc)
    %173 = llvm.mul %4, %0  : i32 loc(#loc)
    %174 = llvm.sub %173, %1  : i32 loc(#loc)
    %175 = llvm.mul %4, %0  : i32 loc(#loc)
    %176 = llvm.sub %175, %1  : i32 loc(#loc)
    %177 = llvm.sub %4, %1  : i32 loc(#loc)
    %178 = llvm.mul %4, %0  : i32 loc(#loc)
    %179 = llvm.sub %178, %1  : i32 loc(#loc)
    %180 = llvm.extractelement %135[%7 : i32] : vector<2xi32> loc(#loc)
    %181 = llvm.extractelement %135[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %152, %153, %155, %180, %181 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %182 = llvm.extractelement %159[%7 : i32] : vector<2xi32> loc(#loc)
    %183 = llvm.extractelement %159[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %176, %177, %179, %182, %183 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %184 = llvm.extractelement %135[%1 : i32] : vector<2xi32> loc(#loc)
    %185 = llvm.add %184, %6  : i32 loc(#loc)
    %186 = llvm.insertelement %185, %135[%1 : i32] : vector<2xi32> loc(#loc)
    %187 = llvm.extractelement %159[%1 : i32] : vector<2xi32> loc(#loc)
    %188 = llvm.add %187, %6  : i32 loc(#loc)
    %189 = llvm.insertelement %188, %159[%1 : i32] : vector<2xi32> loc(#loc)
    %190 = llvm.extractelement %186[%7 : i32] : vector<2xi32> loc(#loc)
    %191 = llvm.extractelement %186[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %147, %148, %150, %190, %191 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %192 = llvm.extractelement %189[%7 : i32] : vector<2xi32> loc(#loc)
    %193 = llvm.extractelement %189[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %171, %172, %174, %192, %193 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %194 = llvm.extractelement %186[%1 : i32] : vector<2xi32> loc(#loc)
    %195 = llvm.add %194, %6  : i32 loc(#loc)
    %196 = llvm.insertelement %195, %186[%1 : i32] : vector<2xi32> loc(#loc)
    %197 = llvm.extractelement %189[%1 : i32] : vector<2xi32> loc(#loc)
    %198 = llvm.add %197, %6  : i32 loc(#loc)
    %199 = llvm.insertelement %198, %189[%1 : i32] : vector<2xi32> loc(#loc)
    %200 = llvm.extractelement %196[%7 : i32] : vector<2xi32> loc(#loc)
    %201 = llvm.extractelement %196[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %142, %143, %145, %200, %201 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %202 = llvm.extractelement %199[%7 : i32] : vector<2xi32> loc(#loc)
    %203 = llvm.extractelement %199[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %166, %167, %169, %202, %203 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %204 = llvm.extractelement %196[%1 : i32] : vector<2xi32> loc(#loc)
    %205 = llvm.add %204, %6  : i32 loc(#loc)
    %206 = llvm.insertelement %205, %196[%1 : i32] : vector<2xi32> loc(#loc)
    %207 = llvm.extractelement %199[%1 : i32] : vector<2xi32> loc(#loc)
    %208 = llvm.add %207, %6  : i32 loc(#loc)
    %209 = llvm.insertelement %208, %199[%1 : i32] : vector<2xi32> loc(#loc)
    %210 = llvm.and %25, %15  : i32 loc(#loc)
    %211 = llvm.mul %210, %2  : i32 loc(#loc)
    %212 = llvm.add %211, %126  : i32 loc(#loc)
    %213 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %214 = llvm.insertelement %212, %213[%7 : i32] : vector<2xi32> loc(#loc)
    %215 = llvm.insertelement %7, %214[%1 : i32] : vector<2xi32> loc(#loc)
    %216 = llvm.mul %4, %0  : i32 loc(#loc)
    %217 = llvm.sub %216, %1  : i32 loc(#loc)
    %218 = llvm.sub %4, %1  : i32 loc(#loc)
    %219 = llvm.mul %4, %0  : i32 loc(#loc)
    %220 = llvm.sub %219, %1  : i32 loc(#loc)
    %221 = llvm.add %212, %6  : i32 loc(#loc)
    %222 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %223 = llvm.insertelement %221, %222[%7 : i32] : vector<2xi32> loc(#loc)
    %224 = llvm.insertelement %7, %223[%1 : i32] : vector<2xi32> loc(#loc)
    %225 = llvm.mul %4, %0  : i32 loc(#loc)
    %226 = llvm.sub %225, %1  : i32 loc(#loc)
    %227 = llvm.sub %4, %1  : i32 loc(#loc)
    %228 = llvm.mul %4, %0  : i32 loc(#loc)
    %229 = llvm.sub %228, %1  : i32 loc(#loc)
    llvm.br ^bb1(%7, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %120, %215, %224, %110, %113, %206, %209 : i32, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>) loc(#loc)
  ^bb1(%230: i32 loc(unknown), %231: vector<8xf32> loc(unknown), %232: vector<8xf32> loc(unknown), %233: vector<8xf32> loc(unknown), %234: vector<8xf32> loc(unknown), %235: vector<8xf32> loc(unknown), %236: vector<8xf32> loc(unknown), %237: vector<8xf32> loc(unknown), %238: vector<8xf32> loc(unknown), %239: vector<8xf32> loc(unknown), %240: vector<8xf32> loc(unknown), %241: vector<8xf32> loc(unknown), %242: vector<8xf32> loc(unknown), %243: vector<8xf32> loc(unknown), %244: vector<8xf32> loc(unknown), %245: vector<8xf32> loc(unknown), %246: vector<8xf32> loc(unknown), %247: vector<2xi32> loc(unknown), %248: vector<2xi32> loc(unknown), %249: vector<2xi32> loc(unknown), %250: vector<2xi32> loc(unknown), %251: vector<2xi32> loc(unknown), %252: vector<2xi32> loc(unknown), %253: vector<2xi32> loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %254 = llvm.icmp "slt" %230, %4 : i32 loc(#loc)
    llvm.cond_br %254, ^bb2, ^bb3 loc(#loc)
  ^bb2:  // pred: ^bb1
    genx.barrier loc(#loc)
    %255 = llvm.extractelement %247[%7 : i32] : vector<2xi32> loc(#loc)
    %256 = llvm.extractelement %247[%1 : i32] : vector<2xi32> loc(#loc)
    %257 = genx.matrix.2Dblockload %arg0, %122, %123, %125, %255, %256 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<64xi16> loc(#loc)
    %258 = llvm.extractelement %248[%7 : i32] : vector<2xi32> loc(#loc)
    %259 = llvm.extractelement %248[%1 : i32] : vector<2xi32> loc(#loc)
    %260 = genx.matrix.2Dblockload %arg1, %217, %218, %220, %258, %259 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = true} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<32xi32> loc(#loc)
    %261 = llvm.extractelement %249[%7 : i32] : vector<2xi32> loc(#loc)
    %262 = llvm.extractelement %249[%1 : i32] : vector<2xi32> loc(#loc)
    %263 = genx.matrix.2Dblockload %arg1, %226, %227, %229, %261, %262 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = true} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<32xi32> loc(#loc)
    %264 = llvm.shufflevector %257, %257 [0, 1, 2, 3, 4, 5, 6, 7] : vector<64xi16>  loc(#loc)
    %265 = llvm.shufflevector %260, %260 [0, 1, 2, 3, 4, 5, 6, 7] : vector<32xi32>  loc(#loc)
    %266 = genx.matrix.dpas %231, %264, %265 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %267 = llvm.shufflevector %257, %257 [32, 33, 34, 35, 36, 37, 38, 39] : vector<64xi16>  loc(#loc)
    %268 = llvm.shufflevector %260, %260 [8, 9, 10, 11, 12, 13, 14, 15] : vector<32xi32>  loc(#loc)
    %269 = genx.matrix.dpas %266, %267, %268 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %270 = llvm.shufflevector %257, %257 [8, 9, 10, 11, 12, 13, 14, 15] : vector<64xi16>  loc(#loc)
    %271 = genx.matrix.dpas %232, %270, %265 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %272 = llvm.shufflevector %257, %257 [40, 41, 42, 43, 44, 45, 46, 47] : vector<64xi16>  loc(#loc)
    %273 = genx.matrix.dpas %271, %272, %268 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %274 = llvm.shufflevector %257, %257 [16, 17, 18, 19, 20, 21, 22, 23] : vector<64xi16>  loc(#loc)
    %275 = genx.matrix.dpas %233, %274, %265 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %276 = llvm.shufflevector %257, %257 [48, 49, 50, 51, 52, 53, 54, 55] : vector<64xi16>  loc(#loc)
    %277 = genx.matrix.dpas %275, %276, %268 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %278 = llvm.shufflevector %257, %257 [24, 25, 26, 27, 28, 29, 30, 31] : vector<64xi16>  loc(#loc)
    %279 = genx.matrix.dpas %234, %278, %265 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %280 = llvm.shufflevector %257, %257 [56, 57, 58, 59, 60, 61, 62, 63] : vector<64xi16>  loc(#loc)
    %281 = genx.matrix.dpas %279, %280, %268 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %282 = llvm.shufflevector %260, %260 [16, 17, 18, 19, 20, 21, 22, 23] : vector<32xi32>  loc(#loc)
    %283 = genx.matrix.dpas %235, %264, %282 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %284 = llvm.shufflevector %260, %260 [24, 25, 26, 27, 28, 29, 30, 31] : vector<32xi32>  loc(#loc)
    %285 = genx.matrix.dpas %283, %267, %284 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %286 = genx.matrix.dpas %236, %270, %282 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %287 = genx.matrix.dpas %286, %272, %284 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %288 = genx.matrix.dpas %237, %274, %282 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %289 = genx.matrix.dpas %288, %276, %284 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %290 = genx.matrix.dpas %238, %278, %282 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %291 = genx.matrix.dpas %290, %280, %284 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %292 = llvm.shufflevector %263, %263 [0, 1, 2, 3, 4, 5, 6, 7] : vector<32xi32>  loc(#loc)
    %293 = genx.matrix.dpas %239, %264, %292 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %294 = llvm.shufflevector %263, %263 [8, 9, 10, 11, 12, 13, 14, 15] : vector<32xi32>  loc(#loc)
    %295 = genx.matrix.dpas %293, %267, %294 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %296 = genx.matrix.dpas %240, %270, %292 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %297 = genx.matrix.dpas %296, %272, %294 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %298 = genx.matrix.dpas %241, %274, %292 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %299 = genx.matrix.dpas %298, %276, %294 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %300 = genx.matrix.dpas %242, %278, %292 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %301 = genx.matrix.dpas %300, %280, %294 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %302 = llvm.shufflevector %263, %263 [16, 17, 18, 19, 20, 21, 22, 23] : vector<32xi32>  loc(#loc)
    %303 = genx.matrix.dpas %243, %264, %302 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %304 = llvm.shufflevector %263, %263 [24, 25, 26, 27, 28, 29, 30, 31] : vector<32xi32>  loc(#loc)
    %305 = genx.matrix.dpas %303, %267, %304 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %306 = genx.matrix.dpas %244, %270, %302 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %307 = genx.matrix.dpas %306, %272, %304 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %308 = genx.matrix.dpas %245, %274, %302 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %309 = genx.matrix.dpas %308, %276, %304 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %310 = genx.matrix.dpas %246, %278, %302 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %311 = genx.matrix.dpas %310, %280, %304 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %312 = llvm.extractelement %250[%7 : i32] : vector<2xi32> loc(#loc)
    %313 = llvm.extractelement %250[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %42, %43, %45, %312, %313 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %314 = llvm.extractelement %251[%7 : i32] : vector<2xi32> loc(#loc)
    %315 = llvm.extractelement %251[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %65, %66, %68, %314, %315 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %316 = llvm.extractelement %250[%7 : i32] : vector<2xi32> loc(#loc)
    %317 = llvm.add %316, %6  : i32 loc(#loc)
    %318 = llvm.insertelement %317, %250[%7 : i32] : vector<2xi32> loc(#loc)
    %319 = llvm.extractelement %251[%7 : i32] : vector<2xi32> loc(#loc)
    %320 = llvm.add %319, %6  : i32 loc(#loc)
    %321 = llvm.insertelement %320, %251[%7 : i32] : vector<2xi32> loc(#loc)
    %322 = llvm.extractelement %247[%7 : i32] : vector<2xi32> loc(#loc)
    %323 = llvm.add %322, %6  : i32 loc(#loc)
    %324 = llvm.insertelement %323, %247[%7 : i32] : vector<2xi32> loc(#loc)
    %325 = llvm.extractelement %252[%7 : i32] : vector<2xi32> loc(#loc)
    %326 = llvm.extractelement %252[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %137, %138, %140, %325, %326 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %327 = llvm.extractelement %253[%7 : i32] : vector<2xi32> loc(#loc)
    %328 = llvm.extractelement %253[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %161, %162, %164, %327, %328 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %329 = llvm.extractelement %252[%1 : i32] : vector<2xi32> loc(#loc)
    %330 = llvm.add %329, %6  : i32 loc(#loc)
    %331 = llvm.insertelement %330, %252[%1 : i32] : vector<2xi32> loc(#loc)
    %332 = llvm.extractelement %253[%1 : i32] : vector<2xi32> loc(#loc)
    %333 = llvm.add %332, %6  : i32 loc(#loc)
    %334 = llvm.insertelement %333, %253[%1 : i32] : vector<2xi32> loc(#loc)
    %335 = llvm.extractelement %248[%1 : i32] : vector<2xi32> loc(#loc)
    %336 = llvm.add %335, %6  : i32 loc(#loc)
    %337 = llvm.insertelement %336, %248[%1 : i32] : vector<2xi32> loc(#loc)
    %338 = llvm.extractelement %249[%1 : i32] : vector<2xi32> loc(#loc)
    %339 = llvm.add %338, %6  : i32 loc(#loc)
    %340 = llvm.insertelement %339, %249[%1 : i32] : vector<2xi32> loc(#loc)
    %341 = llvm.add %230, %6  : i32 loc(#loc)
    llvm.br ^bb1(%341, %269, %273, %277, %281, %285, %287, %289, %291, %295, %297, %299, %301, %305, %307, %309, %311, %324, %337, %340, %318, %321, %331, %334 : i32, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>) loc(#loc)
  ^bb3:  // pred: ^bb1
    %342 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %343 = llvm.insertelement %212, %342[%7 : i32] : vector<2xi32> loc(#loc)
    %344 = llvm.insertelement %117, %343[%1 : i32] : vector<2xi32> loc(#loc)
    %345 = llvm.mul %4, %9  : i32 loc(#loc)
    %346 = llvm.sub %345, %1  : i32 loc(#loc)
    %347 = llvm.sub %4, %1  : i32 loc(#loc)
    %348 = llvm.mul %4, %9  : i32 loc(#loc)
    %349 = llvm.sub %348, %1  : i32 loc(#loc)
    %350 = llvm.add %117, %10  : i32 loc(#loc)
    %351 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %352 = llvm.insertelement %212, %351[%7 : i32] : vector<2xi32> loc(#loc)
    %353 = llvm.insertelement %350, %352[%1 : i32] : vector<2xi32> loc(#loc)
    %354 = llvm.mul %4, %9  : i32 loc(#loc)
    %355 = llvm.sub %354, %1  : i32 loc(#loc)
    %356 = llvm.sub %4, %1  : i32 loc(#loc)
    %357 = llvm.mul %4, %9  : i32 loc(#loc)
    %358 = llvm.sub %357, %1  : i32 loc(#loc)
    %359 = llvm.add %117, %3  : i32 loc(#loc)
    %360 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %361 = llvm.insertelement %212, %360[%7 : i32] : vector<2xi32> loc(#loc)
    %362 = llvm.insertelement %359, %361[%1 : i32] : vector<2xi32> loc(#loc)
    %363 = llvm.mul %4, %9  : i32 loc(#loc)
    %364 = llvm.sub %363, %1  : i32 loc(#loc)
    %365 = llvm.sub %4, %1  : i32 loc(#loc)
    %366 = llvm.mul %4, %9  : i32 loc(#loc)
    %367 = llvm.sub %366, %1  : i32 loc(#loc)
    %368 = llvm.add %117, %11  : i32 loc(#loc)
    %369 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %370 = llvm.insertelement %212, %369[%7 : i32] : vector<2xi32> loc(#loc)
    %371 = llvm.insertelement %368, %370[%1 : i32] : vector<2xi32> loc(#loc)
    %372 = llvm.mul %4, %9  : i32 loc(#loc)
    %373 = llvm.sub %372, %1  : i32 loc(#loc)
    %374 = llvm.sub %4, %1  : i32 loc(#loc)
    %375 = llvm.mul %4, %9  : i32 loc(#loc)
    %376 = llvm.sub %375, %1  : i32 loc(#loc)
    %377 = llvm.add %212, %3  : i32 loc(#loc)
    %378 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %379 = llvm.insertelement %377, %378[%7 : i32] : vector<2xi32> loc(#loc)
    %380 = llvm.insertelement %117, %379[%1 : i32] : vector<2xi32> loc(#loc)
    %381 = llvm.mul %4, %9  : i32 loc(#loc)
    %382 = llvm.sub %381, %1  : i32 loc(#loc)
    %383 = llvm.sub %4, %1  : i32 loc(#loc)
    %384 = llvm.mul %4, %9  : i32 loc(#loc)
    %385 = llvm.sub %384, %1  : i32 loc(#loc)
    %386 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %387 = llvm.insertelement %377, %386[%7 : i32] : vector<2xi32> loc(#loc)
    %388 = llvm.insertelement %350, %387[%1 : i32] : vector<2xi32> loc(#loc)
    %389 = llvm.mul %4, %9  : i32 loc(#loc)
    %390 = llvm.sub %389, %1  : i32 loc(#loc)
    %391 = llvm.sub %4, %1  : i32 loc(#loc)
    %392 = llvm.mul %4, %9  : i32 loc(#loc)
    %393 = llvm.sub %392, %1  : i32 loc(#loc)
    %394 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %395 = llvm.insertelement %377, %394[%7 : i32] : vector<2xi32> loc(#loc)
    %396 = llvm.insertelement %359, %395[%1 : i32] : vector<2xi32> loc(#loc)
    %397 = llvm.mul %4, %9  : i32 loc(#loc)
    %398 = llvm.sub %397, %1  : i32 loc(#loc)
    %399 = llvm.sub %4, %1  : i32 loc(#loc)
    %400 = llvm.mul %4, %9  : i32 loc(#loc)
    %401 = llvm.sub %400, %1  : i32 loc(#loc)
    %402 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %403 = llvm.insertelement %377, %402[%7 : i32] : vector<2xi32> loc(#loc)
    %404 = llvm.insertelement %368, %403[%1 : i32] : vector<2xi32> loc(#loc)
    %405 = llvm.mul %4, %9  : i32 loc(#loc)
    %406 = llvm.sub %405, %1  : i32 loc(#loc)
    %407 = llvm.sub %4, %1  : i32 loc(#loc)
    %408 = llvm.mul %4, %9  : i32 loc(#loc)
    %409 = llvm.sub %408, %1  : i32 loc(#loc)
    %410 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %411 = llvm.insertelement %221, %410[%7 : i32] : vector<2xi32> loc(#loc)
    %412 = llvm.insertelement %117, %411[%1 : i32] : vector<2xi32> loc(#loc)
    %413 = llvm.mul %4, %9  : i32 loc(#loc)
    %414 = llvm.sub %413, %1  : i32 loc(#loc)
    %415 = llvm.sub %4, %1  : i32 loc(#loc)
    %416 = llvm.mul %4, %9  : i32 loc(#loc)
    %417 = llvm.sub %416, %1  : i32 loc(#loc)
    %418 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %419 = llvm.insertelement %221, %418[%7 : i32] : vector<2xi32> loc(#loc)
    %420 = llvm.insertelement %350, %419[%1 : i32] : vector<2xi32> loc(#loc)
    %421 = llvm.mul %4, %9  : i32 loc(#loc)
    %422 = llvm.sub %421, %1  : i32 loc(#loc)
    %423 = llvm.sub %4, %1  : i32 loc(#loc)
    %424 = llvm.mul %4, %9  : i32 loc(#loc)
    %425 = llvm.sub %424, %1  : i32 loc(#loc)
    %426 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %427 = llvm.insertelement %221, %426[%7 : i32] : vector<2xi32> loc(#loc)
    %428 = llvm.insertelement %359, %427[%1 : i32] : vector<2xi32> loc(#loc)
    %429 = llvm.mul %4, %9  : i32 loc(#loc)
    %430 = llvm.sub %429, %1  : i32 loc(#loc)
    %431 = llvm.sub %4, %1  : i32 loc(#loc)
    %432 = llvm.mul %4, %9  : i32 loc(#loc)
    %433 = llvm.sub %432, %1  : i32 loc(#loc)
    %434 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %435 = llvm.insertelement %221, %434[%7 : i32] : vector<2xi32> loc(#loc)
    %436 = llvm.insertelement %368, %435[%1 : i32] : vector<2xi32> loc(#loc)
    %437 = llvm.mul %4, %9  : i32 loc(#loc)
    %438 = llvm.sub %437, %1  : i32 loc(#loc)
    %439 = llvm.sub %4, %1  : i32 loc(#loc)
    %440 = llvm.mul %4, %9  : i32 loc(#loc)
    %441 = llvm.sub %440, %1  : i32 loc(#loc)
    %442 = llvm.add %212, %12  : i32 loc(#loc)
    %443 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %444 = llvm.insertelement %442, %443[%7 : i32] : vector<2xi32> loc(#loc)
    %445 = llvm.insertelement %117, %444[%1 : i32] : vector<2xi32> loc(#loc)
    %446 = llvm.mul %4, %9  : i32 loc(#loc)
    %447 = llvm.sub %446, %1  : i32 loc(#loc)
    %448 = llvm.sub %4, %1  : i32 loc(#loc)
    %449 = llvm.mul %4, %9  : i32 loc(#loc)
    %450 = llvm.sub %449, %1  : i32 loc(#loc)
    %451 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %452 = llvm.insertelement %442, %451[%7 : i32] : vector<2xi32> loc(#loc)
    %453 = llvm.insertelement %350, %452[%1 : i32] : vector<2xi32> loc(#loc)
    %454 = llvm.mul %4, %9  : i32 loc(#loc)
    %455 = llvm.sub %454, %1  : i32 loc(#loc)
    %456 = llvm.sub %4, %1  : i32 loc(#loc)
    %457 = llvm.mul %4, %9  : i32 loc(#loc)
    %458 = llvm.sub %457, %1  : i32 loc(#loc)
    %459 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %460 = llvm.insertelement %442, %459[%7 : i32] : vector<2xi32> loc(#loc)
    %461 = llvm.insertelement %359, %460[%1 : i32] : vector<2xi32> loc(#loc)
    %462 = llvm.mul %4, %9  : i32 loc(#loc)
    %463 = llvm.sub %462, %1  : i32 loc(#loc)
    %464 = llvm.sub %4, %1  : i32 loc(#loc)
    %465 = llvm.mul %4, %9  : i32 loc(#loc)
    %466 = llvm.sub %465, %1  : i32 loc(#loc)
    %467 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %468 = llvm.insertelement %442, %467[%7 : i32] : vector<2xi32> loc(#loc)
    %469 = llvm.insertelement %368, %468[%1 : i32] : vector<2xi32> loc(#loc)
    %470 = llvm.mul %4, %9  : i32 loc(#loc)
    %471 = llvm.sub %470, %1  : i32 loc(#loc)
    %472 = llvm.sub %4, %1  : i32 loc(#loc)
    %473 = llvm.mul %4, %9  : i32 loc(#loc)
    %474 = llvm.sub %473, %1  : i32 loc(#loc)
    %475 = llvm.extractelement %344[%7 : i32] : vector<2xi32> loc(#loc)
    %476 = llvm.extractelement %344[%1 : i32] : vector<2xi32> loc(#loc)
    %477 = llvm.bitcast %231 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %346, %347, %349, %475, %476, %477 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %478 = llvm.extractelement %353[%7 : i32] : vector<2xi32> loc(#loc)
    %479 = llvm.extractelement %353[%1 : i32] : vector<2xi32> loc(#loc)
    %480 = llvm.bitcast %232 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %355, %356, %358, %478, %479, %480 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %481 = llvm.extractelement %362[%7 : i32] : vector<2xi32> loc(#loc)
    %482 = llvm.extractelement %362[%1 : i32] : vector<2xi32> loc(#loc)
    %483 = llvm.bitcast %233 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %364, %365, %367, %481, %482, %483 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %484 = llvm.extractelement %371[%7 : i32] : vector<2xi32> loc(#loc)
    %485 = llvm.extractelement %371[%1 : i32] : vector<2xi32> loc(#loc)
    %486 = llvm.bitcast %234 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %373, %374, %376, %484, %485, %486 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %487 = llvm.extractelement %380[%7 : i32] : vector<2xi32> loc(#loc)
    %488 = llvm.extractelement %380[%1 : i32] : vector<2xi32> loc(#loc)
    %489 = llvm.bitcast %235 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %382, %383, %385, %487, %488, %489 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %490 = llvm.extractelement %388[%7 : i32] : vector<2xi32> loc(#loc)
    %491 = llvm.extractelement %388[%1 : i32] : vector<2xi32> loc(#loc)
    %492 = llvm.bitcast %236 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %390, %391, %393, %490, %491, %492 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %493 = llvm.extractelement %396[%7 : i32] : vector<2xi32> loc(#loc)
    %494 = llvm.extractelement %396[%1 : i32] : vector<2xi32> loc(#loc)
    %495 = llvm.bitcast %237 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %398, %399, %401, %493, %494, %495 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %496 = llvm.extractelement %404[%7 : i32] : vector<2xi32> loc(#loc)
    %497 = llvm.extractelement %404[%1 : i32] : vector<2xi32> loc(#loc)
    %498 = llvm.bitcast %238 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %406, %407, %409, %496, %497, %498 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %499 = llvm.extractelement %412[%7 : i32] : vector<2xi32> loc(#loc)
    %500 = llvm.extractelement %412[%1 : i32] : vector<2xi32> loc(#loc)
    %501 = llvm.bitcast %239 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %414, %415, %417, %499, %500, %501 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %502 = llvm.extractelement %420[%7 : i32] : vector<2xi32> loc(#loc)
    %503 = llvm.extractelement %420[%1 : i32] : vector<2xi32> loc(#loc)
    %504 = llvm.bitcast %240 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %422, %423, %425, %502, %503, %504 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %505 = llvm.extractelement %428[%7 : i32] : vector<2xi32> loc(#loc)
    %506 = llvm.extractelement %428[%1 : i32] : vector<2xi32> loc(#loc)
    %507 = llvm.bitcast %241 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %430, %431, %433, %505, %506, %507 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %508 = llvm.extractelement %436[%7 : i32] : vector<2xi32> loc(#loc)
    %509 = llvm.extractelement %436[%1 : i32] : vector<2xi32> loc(#loc)
    %510 = llvm.bitcast %242 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %438, %439, %441, %508, %509, %510 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %511 = llvm.extractelement %445[%7 : i32] : vector<2xi32> loc(#loc)
    %512 = llvm.extractelement %445[%1 : i32] : vector<2xi32> loc(#loc)
    %513 = llvm.bitcast %243 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %447, %448, %450, %511, %512, %513 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %514 = llvm.extractelement %453[%7 : i32] : vector<2xi32> loc(#loc)
    %515 = llvm.extractelement %453[%1 : i32] : vector<2xi32> loc(#loc)
    %516 = llvm.bitcast %244 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %455, %456, %458, %514, %515, %516 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %517 = llvm.extractelement %461[%7 : i32] : vector<2xi32> loc(#loc)
    %518 = llvm.extractelement %461[%1 : i32] : vector<2xi32> loc(#loc)
    %519 = llvm.bitcast %245 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %463, %464, %466, %517, %518, %519 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %520 = llvm.extractelement %469[%7 : i32] : vector<2xi32> loc(#loc)
    %521 = llvm.extractelement %469[%1 : i32] : vector<2xi32> loc(#loc)
    %522 = llvm.bitcast %246 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %471, %472, %474, %520, %521, %522 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    llvm.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before CSE (cse) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, triton_gpu.shared = 0 : i32, "triton_gpu.threads-per-warp" = 16 : i32} {
  llvm.func @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {genx.intel_reqd_sub_group_size = [16 : i32], genx.kernel = 1 : i32, genx.max_work_group_size = [512 : i32, 1 : i32, 1 : i32], noinline = false} {
    %0 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %1 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %2 = llvm.mlir.constant(64 : i32) : i32 loc(#loc)
    %3 = llvm.mlir.constant(16 : i32) : i32 loc(#loc)
    %4 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %5 = llvm.mlir.constant(dense<0.000000e+00> : vector<8xf32>) : vector<8xf32> loc(#loc)
    %6 = llvm.mlir.constant(32 : i32) : i32 loc(#loc)
    %7 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %8 = llvm.mlir.constant(256 : i32) : i32 loc(#loc)
    %9 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %10 = llvm.mlir.constant(8 : i32) : i32 loc(#loc)
    %11 = llvm.mlir.constant(24 : i32) : i32 loc(#loc)
    %12 = llvm.mlir.constant(48 : i32) : i32 loc(#loc)
    %13 = llvm.mlir.constant(63 : i32) : i32 loc(#loc)
    %14 = llvm.mlir.constant(7 : i32) : i32 loc(#loc)
    %15 = llvm.mlir.constant(3 : i32) : i32 loc(#loc)
    %16 = genx.workitem.id.x : i32 loc(#loc)
    %17 = genx.workitem.id.y : i32 loc(#loc)
    %18 = genx.workitem.id.z : i32 loc(#loc)
    %19 = genx.workgroup.dim.x : i32 loc(#loc)
    %20 = genx.workgroup.dim.y : i32 loc(#loc)
    %21 = llvm.mul %18, %20  : i32 loc(#loc)
    %22 = llvm.add %21, %17  : i32 loc(#loc)
    %23 = llvm.mul %22, %19  : i32 loc(#loc)
    %24 = llvm.add %23, %16  : i32 loc(#loc)
    %25 = llvm.udiv %24, %3  : i32 loc(#loc)
    %26 = genx.workgroup.id.x : i32 loc(#loc)
    %27 = llvm.sdiv %26, %2  : i32 loc(#loc)
    %28 = llvm.mul %27, %9  : i32 loc(#loc)
    %29 = llvm.sub %3, %28  : i32 loc(#loc)
    %30 = llvm.intr.smin(%29, %9)  : (i32, i32) -> i32 loc(#loc)
    %31 = llvm.srem %26, %30  : i32 loc(#loc)
    %32 = llvm.add %28, %31  : i32 loc(#loc)
    %33 = llvm.and %26, %13  : i32 loc(#loc)
    %34 = llvm.sdiv %33, %30  : i32 loc(#loc)
    %35 = llvm.mul %32, %8  : i32 loc(#loc)
    %36 = llvm.mul %25, %10  : i32 loc(#loc)
    %37 = llvm.add %36, %35  : i32 loc(#loc)
    %38 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %39 = llvm.insertelement %7, %38[%7 : i32] : vector<2xi32> loc(#loc)
    %40 = llvm.insertelement %37, %39[%1 : i32] : vector<2xi32> loc(#loc)
    %41 = llvm.mul %4, %0  : i32 loc(#loc)
    %42 = llvm.sub %41, %1  : i32 loc(#loc)
    %43 = llvm.sub %4, %1  : i32 loc(#loc)
    %44 = llvm.mul %4, %0  : i32 loc(#loc)
    %45 = llvm.sub %44, %1  : i32 loc(#loc)
    %46 = llvm.mul %4, %0  : i32 loc(#loc)
    %47 = llvm.sub %46, %1  : i32 loc(#loc)
    %48 = llvm.sub %4, %1  : i32 loc(#loc)
    %49 = llvm.mul %4, %0  : i32 loc(#loc)
    %50 = llvm.sub %49, %1  : i32 loc(#loc)
    %51 = llvm.mul %4, %0  : i32 loc(#loc)
    %52 = llvm.sub %51, %1  : i32 loc(#loc)
    %53 = llvm.sub %4, %1  : i32 loc(#loc)
    %54 = llvm.mul %4, %0  : i32 loc(#loc)
    %55 = llvm.sub %54, %1  : i32 loc(#loc)
    %56 = llvm.mul %4, %0  : i32 loc(#loc)
    %57 = llvm.sub %56, %1  : i32 loc(#loc)
    %58 = llvm.sub %4, %1  : i32 loc(#loc)
    %59 = llvm.mul %4, %0  : i32 loc(#loc)
    %60 = llvm.sub %59, %1  : i32 loc(#loc)
    %61 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %62 = llvm.insertelement %3, %61[%7 : i32] : vector<2xi32> loc(#loc)
    %63 = llvm.insertelement %37, %62[%1 : i32] : vector<2xi32> loc(#loc)
    %64 = llvm.mul %4, %0  : i32 loc(#loc)
    %65 = llvm.sub %64, %1  : i32 loc(#loc)
    %66 = llvm.sub %4, %1  : i32 loc(#loc)
    %67 = llvm.mul %4, %0  : i32 loc(#loc)
    %68 = llvm.sub %67, %1  : i32 loc(#loc)
    %69 = llvm.mul %4, %0  : i32 loc(#loc)
    %70 = llvm.sub %69, %1  : i32 loc(#loc)
    %71 = llvm.sub %4, %1  : i32 loc(#loc)
    %72 = llvm.mul %4, %0  : i32 loc(#loc)
    %73 = llvm.sub %72, %1  : i32 loc(#loc)
    %74 = llvm.mul %4, %0  : i32 loc(#loc)
    %75 = llvm.sub %74, %1  : i32 loc(#loc)
    %76 = llvm.sub %4, %1  : i32 loc(#loc)
    %77 = llvm.mul %4, %0  : i32 loc(#loc)
    %78 = llvm.sub %77, %1  : i32 loc(#loc)
    %79 = llvm.mul %4, %0  : i32 loc(#loc)
    %80 = llvm.sub %79, %1  : i32 loc(#loc)
    %81 = llvm.sub %4, %1  : i32 loc(#loc)
    %82 = llvm.mul %4, %0  : i32 loc(#loc)
    %83 = llvm.sub %82, %1  : i32 loc(#loc)
    %84 = llvm.extractelement %40[%7 : i32] : vector<2xi32> loc(#loc)
    %85 = llvm.extractelement %40[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %57, %58, %60, %84, %85 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %86 = llvm.extractelement %63[%7 : i32] : vector<2xi32> loc(#loc)
    %87 = llvm.extractelement %63[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %80, %81, %83, %86, %87 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %88 = llvm.extractelement %40[%7 : i32] : vector<2xi32> loc(#loc)
    %89 = llvm.add %88, %6  : i32 loc(#loc)
    %90 = llvm.insertelement %89, %40[%7 : i32] : vector<2xi32> loc(#loc)
    %91 = llvm.extractelement %63[%7 : i32] : vector<2xi32> loc(#loc)
    %92 = llvm.add %91, %6  : i32 loc(#loc)
    %93 = llvm.insertelement %92, %63[%7 : i32] : vector<2xi32> loc(#loc)
    %94 = llvm.extractelement %90[%7 : i32] : vector<2xi32> loc(#loc)
    %95 = llvm.extractelement %90[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %52, %53, %55, %94, %95 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %96 = llvm.extractelement %93[%7 : i32] : vector<2xi32> loc(#loc)
    %97 = llvm.extractelement %93[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %75, %76, %78, %96, %97 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %98 = llvm.extractelement %90[%7 : i32] : vector<2xi32> loc(#loc)
    %99 = llvm.add %98, %6  : i32 loc(#loc)
    %100 = llvm.insertelement %99, %90[%7 : i32] : vector<2xi32> loc(#loc)
    %101 = llvm.extractelement %93[%7 : i32] : vector<2xi32> loc(#loc)
    %102 = llvm.add %101, %6  : i32 loc(#loc)
    %103 = llvm.insertelement %102, %93[%7 : i32] : vector<2xi32> loc(#loc)
    %104 = llvm.extractelement %100[%7 : i32] : vector<2xi32> loc(#loc)
    %105 = llvm.extractelement %100[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %47, %48, %50, %104, %105 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %106 = llvm.extractelement %103[%7 : i32] : vector<2xi32> loc(#loc)
    %107 = llvm.extractelement %103[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %70, %71, %73, %106, %107 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %108 = llvm.extractelement %100[%7 : i32] : vector<2xi32> loc(#loc)
    %109 = llvm.add %108, %6  : i32 loc(#loc)
    %110 = llvm.insertelement %109, %100[%7 : i32] : vector<2xi32> loc(#loc)
    %111 = llvm.extractelement %103[%7 : i32] : vector<2xi32> loc(#loc)
    %112 = llvm.add %111, %6  : i32 loc(#loc)
    %113 = llvm.insertelement %112, %103[%7 : i32] : vector<2xi32> loc(#loc)
    %114 = llvm.sdiv %25, %9  : i32 loc(#loc)
    %115 = llvm.and %114, %14  : i32 loc(#loc)
    %116 = llvm.mul %115, %6  : i32 loc(#loc)
    %117 = llvm.add %116, %35  : i32 loc(#loc)
    %118 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %119 = llvm.insertelement %7, %118[%7 : i32] : vector<2xi32> loc(#loc)
    %120 = llvm.insertelement %117, %119[%1 : i32] : vector<2xi32> loc(#loc)
    %121 = llvm.mul %4, %0  : i32 loc(#loc)
    %122 = llvm.sub %121, %1  : i32 loc(#loc)
    %123 = llvm.sub %4, %1  : i32 loc(#loc)
    %124 = llvm.mul %4, %0  : i32 loc(#loc)
    %125 = llvm.sub %124, %1  : i32 loc(#loc)
    %126 = llvm.mul %34, %8  : i32 loc(#loc)
    %127 = llvm.sdiv %25, %10  : i32 loc(#loc)
    %128 = llvm.and %127, %15  : i32 loc(#loc)
    %129 = llvm.mul %128, %10  : i32 loc(#loc)
    %130 = llvm.and %25, %14  : i32 loc(#loc)
    %131 = llvm.mul %130, %6  : i32 loc(#loc)
    %132 = llvm.add %131, %126  : i32 loc(#loc)
    %133 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %134 = llvm.insertelement %132, %133[%7 : i32] : vector<2xi32> loc(#loc)
    %135 = llvm.insertelement %129, %134[%1 : i32] : vector<2xi32> loc(#loc)
    %136 = llvm.mul %4, %0  : i32 loc(#loc)
    %137 = llvm.sub %136, %1  : i32 loc(#loc)
    %138 = llvm.sub %4, %1  : i32 loc(#loc)
    %139 = llvm.mul %4, %0  : i32 loc(#loc)
    %140 = llvm.sub %139, %1  : i32 loc(#loc)
    %141 = llvm.mul %4, %0  : i32 loc(#loc)
    %142 = llvm.sub %141, %1  : i32 loc(#loc)
    %143 = llvm.sub %4, %1  : i32 loc(#loc)
    %144 = llvm.mul %4, %0  : i32 loc(#loc)
    %145 = llvm.sub %144, %1  : i32 loc(#loc)
    %146 = llvm.mul %4, %0  : i32 loc(#loc)
    %147 = llvm.sub %146, %1  : i32 loc(#loc)
    %148 = llvm.sub %4, %1  : i32 loc(#loc)
    %149 = llvm.mul %4, %0  : i32 loc(#loc)
    %150 = llvm.sub %149, %1  : i32 loc(#loc)
    %151 = llvm.mul %4, %0  : i32 loc(#loc)
    %152 = llvm.sub %151, %1  : i32 loc(#loc)
    %153 = llvm.sub %4, %1  : i32 loc(#loc)
    %154 = llvm.mul %4, %0  : i32 loc(#loc)
    %155 = llvm.sub %154, %1  : i32 loc(#loc)
    %156 = llvm.add %132, %3  : i32 loc(#loc)
    %157 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %158 = llvm.insertelement %156, %157[%7 : i32] : vector<2xi32> loc(#loc)
    %159 = llvm.insertelement %129, %158[%1 : i32] : vector<2xi32> loc(#loc)
    %160 = llvm.mul %4, %0  : i32 loc(#loc)
    %161 = llvm.sub %160, %1  : i32 loc(#loc)
    %162 = llvm.sub %4, %1  : i32 loc(#loc)
    %163 = llvm.mul %4, %0  : i32 loc(#loc)
    %164 = llvm.sub %163, %1  : i32 loc(#loc)
    %165 = llvm.mul %4, %0  : i32 loc(#loc)
    %166 = llvm.sub %165, %1  : i32 loc(#loc)
    %167 = llvm.sub %4, %1  : i32 loc(#loc)
    %168 = llvm.mul %4, %0  : i32 loc(#loc)
    %169 = llvm.sub %168, %1  : i32 loc(#loc)
    %170 = llvm.mul %4, %0  : i32 loc(#loc)
    %171 = llvm.sub %170, %1  : i32 loc(#loc)
    %172 = llvm.sub %4, %1  : i32 loc(#loc)
    %173 = llvm.mul %4, %0  : i32 loc(#loc)
    %174 = llvm.sub %173, %1  : i32 loc(#loc)
    %175 = llvm.mul %4, %0  : i32 loc(#loc)
    %176 = llvm.sub %175, %1  : i32 loc(#loc)
    %177 = llvm.sub %4, %1  : i32 loc(#loc)
    %178 = llvm.mul %4, %0  : i32 loc(#loc)
    %179 = llvm.sub %178, %1  : i32 loc(#loc)
    %180 = llvm.extractelement %135[%7 : i32] : vector<2xi32> loc(#loc)
    %181 = llvm.extractelement %135[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %152, %153, %155, %180, %181 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %182 = llvm.extractelement %159[%7 : i32] : vector<2xi32> loc(#loc)
    %183 = llvm.extractelement %159[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %176, %177, %179, %182, %183 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %184 = llvm.extractelement %135[%1 : i32] : vector<2xi32> loc(#loc)
    %185 = llvm.add %184, %6  : i32 loc(#loc)
    %186 = llvm.insertelement %185, %135[%1 : i32] : vector<2xi32> loc(#loc)
    %187 = llvm.extractelement %159[%1 : i32] : vector<2xi32> loc(#loc)
    %188 = llvm.add %187, %6  : i32 loc(#loc)
    %189 = llvm.insertelement %188, %159[%1 : i32] : vector<2xi32> loc(#loc)
    %190 = llvm.extractelement %186[%7 : i32] : vector<2xi32> loc(#loc)
    %191 = llvm.extractelement %186[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %147, %148, %150, %190, %191 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %192 = llvm.extractelement %189[%7 : i32] : vector<2xi32> loc(#loc)
    %193 = llvm.extractelement %189[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %171, %172, %174, %192, %193 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %194 = llvm.extractelement %186[%1 : i32] : vector<2xi32> loc(#loc)
    %195 = llvm.add %194, %6  : i32 loc(#loc)
    %196 = llvm.insertelement %195, %186[%1 : i32] : vector<2xi32> loc(#loc)
    %197 = llvm.extractelement %189[%1 : i32] : vector<2xi32> loc(#loc)
    %198 = llvm.add %197, %6  : i32 loc(#loc)
    %199 = llvm.insertelement %198, %189[%1 : i32] : vector<2xi32> loc(#loc)
    %200 = llvm.extractelement %196[%7 : i32] : vector<2xi32> loc(#loc)
    %201 = llvm.extractelement %196[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %142, %143, %145, %200, %201 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %202 = llvm.extractelement %199[%7 : i32] : vector<2xi32> loc(#loc)
    %203 = llvm.extractelement %199[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %166, %167, %169, %202, %203 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %204 = llvm.extractelement %196[%1 : i32] : vector<2xi32> loc(#loc)
    %205 = llvm.add %204, %6  : i32 loc(#loc)
    %206 = llvm.insertelement %205, %196[%1 : i32] : vector<2xi32> loc(#loc)
    %207 = llvm.extractelement %199[%1 : i32] : vector<2xi32> loc(#loc)
    %208 = llvm.add %207, %6  : i32 loc(#loc)
    %209 = llvm.insertelement %208, %199[%1 : i32] : vector<2xi32> loc(#loc)
    %210 = llvm.and %25, %15  : i32 loc(#loc)
    %211 = llvm.mul %210, %2  : i32 loc(#loc)
    %212 = llvm.add %211, %126  : i32 loc(#loc)
    %213 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %214 = llvm.insertelement %212, %213[%7 : i32] : vector<2xi32> loc(#loc)
    %215 = llvm.insertelement %7, %214[%1 : i32] : vector<2xi32> loc(#loc)
    %216 = llvm.mul %4, %0  : i32 loc(#loc)
    %217 = llvm.sub %216, %1  : i32 loc(#loc)
    %218 = llvm.sub %4, %1  : i32 loc(#loc)
    %219 = llvm.mul %4, %0  : i32 loc(#loc)
    %220 = llvm.sub %219, %1  : i32 loc(#loc)
    %221 = llvm.add %212, %6  : i32 loc(#loc)
    %222 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %223 = llvm.insertelement %221, %222[%7 : i32] : vector<2xi32> loc(#loc)
    %224 = llvm.insertelement %7, %223[%1 : i32] : vector<2xi32> loc(#loc)
    %225 = llvm.mul %4, %0  : i32 loc(#loc)
    %226 = llvm.sub %225, %1  : i32 loc(#loc)
    %227 = llvm.sub %4, %1  : i32 loc(#loc)
    %228 = llvm.mul %4, %0  : i32 loc(#loc)
    %229 = llvm.sub %228, %1  : i32 loc(#loc)
    llvm.br ^bb1(%7, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %120, %215, %224, %110, %113, %206, %209 : i32, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>) loc(#loc)
  ^bb1(%230: i32 loc(unknown), %231: vector<8xf32> loc(unknown), %232: vector<8xf32> loc(unknown), %233: vector<8xf32> loc(unknown), %234: vector<8xf32> loc(unknown), %235: vector<8xf32> loc(unknown), %236: vector<8xf32> loc(unknown), %237: vector<8xf32> loc(unknown), %238: vector<8xf32> loc(unknown), %239: vector<8xf32> loc(unknown), %240: vector<8xf32> loc(unknown), %241: vector<8xf32> loc(unknown), %242: vector<8xf32> loc(unknown), %243: vector<8xf32> loc(unknown), %244: vector<8xf32> loc(unknown), %245: vector<8xf32> loc(unknown), %246: vector<8xf32> loc(unknown), %247: vector<2xi32> loc(unknown), %248: vector<2xi32> loc(unknown), %249: vector<2xi32> loc(unknown), %250: vector<2xi32> loc(unknown), %251: vector<2xi32> loc(unknown), %252: vector<2xi32> loc(unknown), %253: vector<2xi32> loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %254 = llvm.icmp "slt" %230, %4 : i32 loc(#loc)
    llvm.cond_br %254, ^bb2, ^bb3 loc(#loc)
  ^bb2:  // pred: ^bb1
    genx.barrier loc(#loc)
    %255 = llvm.extractelement %247[%7 : i32] : vector<2xi32> loc(#loc)
    %256 = llvm.extractelement %247[%1 : i32] : vector<2xi32> loc(#loc)
    %257 = genx.matrix.2Dblockload %arg0, %122, %123, %125, %255, %256 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<64xi16> loc(#loc)
    %258 = llvm.extractelement %248[%7 : i32] : vector<2xi32> loc(#loc)
    %259 = llvm.extractelement %248[%1 : i32] : vector<2xi32> loc(#loc)
    %260 = genx.matrix.2Dblockload %arg1, %217, %218, %220, %258, %259 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = true} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<32xi32> loc(#loc)
    %261 = llvm.extractelement %249[%7 : i32] : vector<2xi32> loc(#loc)
    %262 = llvm.extractelement %249[%1 : i32] : vector<2xi32> loc(#loc)
    %263 = genx.matrix.2Dblockload %arg1, %226, %227, %229, %261, %262 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = true} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<32xi32> loc(#loc)
    %264 = llvm.shufflevector %257, %257 [0, 1, 2, 3, 4, 5, 6, 7] : vector<64xi16>  loc(#loc)
    %265 = llvm.shufflevector %260, %260 [0, 1, 2, 3, 4, 5, 6, 7] : vector<32xi32>  loc(#loc)
    %266 = genx.matrix.dpas %231, %264, %265 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %267 = llvm.shufflevector %257, %257 [32, 33, 34, 35, 36, 37, 38, 39] : vector<64xi16>  loc(#loc)
    %268 = llvm.shufflevector %260, %260 [8, 9, 10, 11, 12, 13, 14, 15] : vector<32xi32>  loc(#loc)
    %269 = genx.matrix.dpas %266, %267, %268 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %270 = llvm.shufflevector %257, %257 [8, 9, 10, 11, 12, 13, 14, 15] : vector<64xi16>  loc(#loc)
    %271 = genx.matrix.dpas %232, %270, %265 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %272 = llvm.shufflevector %257, %257 [40, 41, 42, 43, 44, 45, 46, 47] : vector<64xi16>  loc(#loc)
    %273 = genx.matrix.dpas %271, %272, %268 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %274 = llvm.shufflevector %257, %257 [16, 17, 18, 19, 20, 21, 22, 23] : vector<64xi16>  loc(#loc)
    %275 = genx.matrix.dpas %233, %274, %265 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %276 = llvm.shufflevector %257, %257 [48, 49, 50, 51, 52, 53, 54, 55] : vector<64xi16>  loc(#loc)
    %277 = genx.matrix.dpas %275, %276, %268 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %278 = llvm.shufflevector %257, %257 [24, 25, 26, 27, 28, 29, 30, 31] : vector<64xi16>  loc(#loc)
    %279 = genx.matrix.dpas %234, %278, %265 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %280 = llvm.shufflevector %257, %257 [56, 57, 58, 59, 60, 61, 62, 63] : vector<64xi16>  loc(#loc)
    %281 = genx.matrix.dpas %279, %280, %268 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %282 = llvm.shufflevector %260, %260 [16, 17, 18, 19, 20, 21, 22, 23] : vector<32xi32>  loc(#loc)
    %283 = genx.matrix.dpas %235, %264, %282 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %284 = llvm.shufflevector %260, %260 [24, 25, 26, 27, 28, 29, 30, 31] : vector<32xi32>  loc(#loc)
    %285 = genx.matrix.dpas %283, %267, %284 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %286 = genx.matrix.dpas %236, %270, %282 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %287 = genx.matrix.dpas %286, %272, %284 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %288 = genx.matrix.dpas %237, %274, %282 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %289 = genx.matrix.dpas %288, %276, %284 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %290 = genx.matrix.dpas %238, %278, %282 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %291 = genx.matrix.dpas %290, %280, %284 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %292 = llvm.shufflevector %263, %263 [0, 1, 2, 3, 4, 5, 6, 7] : vector<32xi32>  loc(#loc)
    %293 = genx.matrix.dpas %239, %264, %292 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %294 = llvm.shufflevector %263, %263 [8, 9, 10, 11, 12, 13, 14, 15] : vector<32xi32>  loc(#loc)
    %295 = genx.matrix.dpas %293, %267, %294 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %296 = genx.matrix.dpas %240, %270, %292 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %297 = genx.matrix.dpas %296, %272, %294 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %298 = genx.matrix.dpas %241, %274, %292 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %299 = genx.matrix.dpas %298, %276, %294 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %300 = genx.matrix.dpas %242, %278, %292 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %301 = genx.matrix.dpas %300, %280, %294 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %302 = llvm.shufflevector %263, %263 [16, 17, 18, 19, 20, 21, 22, 23] : vector<32xi32>  loc(#loc)
    %303 = genx.matrix.dpas %243, %264, %302 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %304 = llvm.shufflevector %263, %263 [24, 25, 26, 27, 28, 29, 30, 31] : vector<32xi32>  loc(#loc)
    %305 = genx.matrix.dpas %303, %267, %304 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %306 = genx.matrix.dpas %244, %270, %302 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %307 = genx.matrix.dpas %306, %272, %304 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %308 = genx.matrix.dpas %245, %274, %302 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %309 = genx.matrix.dpas %308, %276, %304 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %310 = genx.matrix.dpas %246, %278, %302 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %311 = genx.matrix.dpas %310, %280, %304 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %312 = llvm.extractelement %250[%7 : i32] : vector<2xi32> loc(#loc)
    %313 = llvm.extractelement %250[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %42, %43, %45, %312, %313 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %314 = llvm.extractelement %251[%7 : i32] : vector<2xi32> loc(#loc)
    %315 = llvm.extractelement %251[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %65, %66, %68, %314, %315 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %316 = llvm.extractelement %250[%7 : i32] : vector<2xi32> loc(#loc)
    %317 = llvm.add %316, %6  : i32 loc(#loc)
    %318 = llvm.insertelement %317, %250[%7 : i32] : vector<2xi32> loc(#loc)
    %319 = llvm.extractelement %251[%7 : i32] : vector<2xi32> loc(#loc)
    %320 = llvm.add %319, %6  : i32 loc(#loc)
    %321 = llvm.insertelement %320, %251[%7 : i32] : vector<2xi32> loc(#loc)
    %322 = llvm.extractelement %247[%7 : i32] : vector<2xi32> loc(#loc)
    %323 = llvm.add %322, %6  : i32 loc(#loc)
    %324 = llvm.insertelement %323, %247[%7 : i32] : vector<2xi32> loc(#loc)
    %325 = llvm.extractelement %252[%7 : i32] : vector<2xi32> loc(#loc)
    %326 = llvm.extractelement %252[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %137, %138, %140, %325, %326 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %327 = llvm.extractelement %253[%7 : i32] : vector<2xi32> loc(#loc)
    %328 = llvm.extractelement %253[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %161, %162, %164, %327, %328 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %329 = llvm.extractelement %252[%1 : i32] : vector<2xi32> loc(#loc)
    %330 = llvm.add %329, %6  : i32 loc(#loc)
    %331 = llvm.insertelement %330, %252[%1 : i32] : vector<2xi32> loc(#loc)
    %332 = llvm.extractelement %253[%1 : i32] : vector<2xi32> loc(#loc)
    %333 = llvm.add %332, %6  : i32 loc(#loc)
    %334 = llvm.insertelement %333, %253[%1 : i32] : vector<2xi32> loc(#loc)
    %335 = llvm.extractelement %248[%1 : i32] : vector<2xi32> loc(#loc)
    %336 = llvm.add %335, %6  : i32 loc(#loc)
    %337 = llvm.insertelement %336, %248[%1 : i32] : vector<2xi32> loc(#loc)
    %338 = llvm.extractelement %249[%1 : i32] : vector<2xi32> loc(#loc)
    %339 = llvm.add %338, %6  : i32 loc(#loc)
    %340 = llvm.insertelement %339, %249[%1 : i32] : vector<2xi32> loc(#loc)
    %341 = llvm.add %230, %6  : i32 loc(#loc)
    llvm.br ^bb1(%341, %269, %273, %277, %281, %285, %287, %289, %291, %295, %297, %299, %301, %305, %307, %309, %311, %324, %337, %340, %318, %321, %331, %334 : i32, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>) loc(#loc)
  ^bb3:  // pred: ^bb1
    %342 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %343 = llvm.insertelement %212, %342[%7 : i32] : vector<2xi32> loc(#loc)
    %344 = llvm.insertelement %117, %343[%1 : i32] : vector<2xi32> loc(#loc)
    %345 = llvm.mul %4, %9  : i32 loc(#loc)
    %346 = llvm.sub %345, %1  : i32 loc(#loc)
    %347 = llvm.sub %4, %1  : i32 loc(#loc)
    %348 = llvm.mul %4, %9  : i32 loc(#loc)
    %349 = llvm.sub %348, %1  : i32 loc(#loc)
    %350 = llvm.add %117, %10  : i32 loc(#loc)
    %351 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %352 = llvm.insertelement %212, %351[%7 : i32] : vector<2xi32> loc(#loc)
    %353 = llvm.insertelement %350, %352[%1 : i32] : vector<2xi32> loc(#loc)
    %354 = llvm.mul %4, %9  : i32 loc(#loc)
    %355 = llvm.sub %354, %1  : i32 loc(#loc)
    %356 = llvm.sub %4, %1  : i32 loc(#loc)
    %357 = llvm.mul %4, %9  : i32 loc(#loc)
    %358 = llvm.sub %357, %1  : i32 loc(#loc)
    %359 = llvm.add %117, %3  : i32 loc(#loc)
    %360 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %361 = llvm.insertelement %212, %360[%7 : i32] : vector<2xi32> loc(#loc)
    %362 = llvm.insertelement %359, %361[%1 : i32] : vector<2xi32> loc(#loc)
    %363 = llvm.mul %4, %9  : i32 loc(#loc)
    %364 = llvm.sub %363, %1  : i32 loc(#loc)
    %365 = llvm.sub %4, %1  : i32 loc(#loc)
    %366 = llvm.mul %4, %9  : i32 loc(#loc)
    %367 = llvm.sub %366, %1  : i32 loc(#loc)
    %368 = llvm.add %117, %11  : i32 loc(#loc)
    %369 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %370 = llvm.insertelement %212, %369[%7 : i32] : vector<2xi32> loc(#loc)
    %371 = llvm.insertelement %368, %370[%1 : i32] : vector<2xi32> loc(#loc)
    %372 = llvm.mul %4, %9  : i32 loc(#loc)
    %373 = llvm.sub %372, %1  : i32 loc(#loc)
    %374 = llvm.sub %4, %1  : i32 loc(#loc)
    %375 = llvm.mul %4, %9  : i32 loc(#loc)
    %376 = llvm.sub %375, %1  : i32 loc(#loc)
    %377 = llvm.add %212, %3  : i32 loc(#loc)
    %378 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %379 = llvm.insertelement %377, %378[%7 : i32] : vector<2xi32> loc(#loc)
    %380 = llvm.insertelement %117, %379[%1 : i32] : vector<2xi32> loc(#loc)
    %381 = llvm.mul %4, %9  : i32 loc(#loc)
    %382 = llvm.sub %381, %1  : i32 loc(#loc)
    %383 = llvm.sub %4, %1  : i32 loc(#loc)
    %384 = llvm.mul %4, %9  : i32 loc(#loc)
    %385 = llvm.sub %384, %1  : i32 loc(#loc)
    %386 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %387 = llvm.insertelement %377, %386[%7 : i32] : vector<2xi32> loc(#loc)
    %388 = llvm.insertelement %350, %387[%1 : i32] : vector<2xi32> loc(#loc)
    %389 = llvm.mul %4, %9  : i32 loc(#loc)
    %390 = llvm.sub %389, %1  : i32 loc(#loc)
    %391 = llvm.sub %4, %1  : i32 loc(#loc)
    %392 = llvm.mul %4, %9  : i32 loc(#loc)
    %393 = llvm.sub %392, %1  : i32 loc(#loc)
    %394 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %395 = llvm.insertelement %377, %394[%7 : i32] : vector<2xi32> loc(#loc)
    %396 = llvm.insertelement %359, %395[%1 : i32] : vector<2xi32> loc(#loc)
    %397 = llvm.mul %4, %9  : i32 loc(#loc)
    %398 = llvm.sub %397, %1  : i32 loc(#loc)
    %399 = llvm.sub %4, %1  : i32 loc(#loc)
    %400 = llvm.mul %4, %9  : i32 loc(#loc)
    %401 = llvm.sub %400, %1  : i32 loc(#loc)
    %402 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %403 = llvm.insertelement %377, %402[%7 : i32] : vector<2xi32> loc(#loc)
    %404 = llvm.insertelement %368, %403[%1 : i32] : vector<2xi32> loc(#loc)
    %405 = llvm.mul %4, %9  : i32 loc(#loc)
    %406 = llvm.sub %405, %1  : i32 loc(#loc)
    %407 = llvm.sub %4, %1  : i32 loc(#loc)
    %408 = llvm.mul %4, %9  : i32 loc(#loc)
    %409 = llvm.sub %408, %1  : i32 loc(#loc)
    %410 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %411 = llvm.insertelement %221, %410[%7 : i32] : vector<2xi32> loc(#loc)
    %412 = llvm.insertelement %117, %411[%1 : i32] : vector<2xi32> loc(#loc)
    %413 = llvm.mul %4, %9  : i32 loc(#loc)
    %414 = llvm.sub %413, %1  : i32 loc(#loc)
    %415 = llvm.sub %4, %1  : i32 loc(#loc)
    %416 = llvm.mul %4, %9  : i32 loc(#loc)
    %417 = llvm.sub %416, %1  : i32 loc(#loc)
    %418 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %419 = llvm.insertelement %221, %418[%7 : i32] : vector<2xi32> loc(#loc)
    %420 = llvm.insertelement %350, %419[%1 : i32] : vector<2xi32> loc(#loc)
    %421 = llvm.mul %4, %9  : i32 loc(#loc)
    %422 = llvm.sub %421, %1  : i32 loc(#loc)
    %423 = llvm.sub %4, %1  : i32 loc(#loc)
    %424 = llvm.mul %4, %9  : i32 loc(#loc)
    %425 = llvm.sub %424, %1  : i32 loc(#loc)
    %426 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %427 = llvm.insertelement %221, %426[%7 : i32] : vector<2xi32> loc(#loc)
    %428 = llvm.insertelement %359, %427[%1 : i32] : vector<2xi32> loc(#loc)
    %429 = llvm.mul %4, %9  : i32 loc(#loc)
    %430 = llvm.sub %429, %1  : i32 loc(#loc)
    %431 = llvm.sub %4, %1  : i32 loc(#loc)
    %432 = llvm.mul %4, %9  : i32 loc(#loc)
    %433 = llvm.sub %432, %1  : i32 loc(#loc)
    %434 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %435 = llvm.insertelement %221, %434[%7 : i32] : vector<2xi32> loc(#loc)
    %436 = llvm.insertelement %368, %435[%1 : i32] : vector<2xi32> loc(#loc)
    %437 = llvm.mul %4, %9  : i32 loc(#loc)
    %438 = llvm.sub %437, %1  : i32 loc(#loc)
    %439 = llvm.sub %4, %1  : i32 loc(#loc)
    %440 = llvm.mul %4, %9  : i32 loc(#loc)
    %441 = llvm.sub %440, %1  : i32 loc(#loc)
    %442 = llvm.add %212, %12  : i32 loc(#loc)
    %443 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %444 = llvm.insertelement %442, %443[%7 : i32] : vector<2xi32> loc(#loc)
    %445 = llvm.insertelement %117, %444[%1 : i32] : vector<2xi32> loc(#loc)
    %446 = llvm.mul %4, %9  : i32 loc(#loc)
    %447 = llvm.sub %446, %1  : i32 loc(#loc)
    %448 = llvm.sub %4, %1  : i32 loc(#loc)
    %449 = llvm.mul %4, %9  : i32 loc(#loc)
    %450 = llvm.sub %449, %1  : i32 loc(#loc)
    %451 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %452 = llvm.insertelement %442, %451[%7 : i32] : vector<2xi32> loc(#loc)
    %453 = llvm.insertelement %350, %452[%1 : i32] : vector<2xi32> loc(#loc)
    %454 = llvm.mul %4, %9  : i32 loc(#loc)
    %455 = llvm.sub %454, %1  : i32 loc(#loc)
    %456 = llvm.sub %4, %1  : i32 loc(#loc)
    %457 = llvm.mul %4, %9  : i32 loc(#loc)
    %458 = llvm.sub %457, %1  : i32 loc(#loc)
    %459 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %460 = llvm.insertelement %442, %459[%7 : i32] : vector<2xi32> loc(#loc)
    %461 = llvm.insertelement %359, %460[%1 : i32] : vector<2xi32> loc(#loc)
    %462 = llvm.mul %4, %9  : i32 loc(#loc)
    %463 = llvm.sub %462, %1  : i32 loc(#loc)
    %464 = llvm.sub %4, %1  : i32 loc(#loc)
    %465 = llvm.mul %4, %9  : i32 loc(#loc)
    %466 = llvm.sub %465, %1  : i32 loc(#loc)
    %467 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %468 = llvm.insertelement %442, %467[%7 : i32] : vector<2xi32> loc(#loc)
    %469 = llvm.insertelement %368, %468[%1 : i32] : vector<2xi32> loc(#loc)
    %470 = llvm.mul %4, %9  : i32 loc(#loc)
    %471 = llvm.sub %470, %1  : i32 loc(#loc)
    %472 = llvm.sub %4, %1  : i32 loc(#loc)
    %473 = llvm.mul %4, %9  : i32 loc(#loc)
    %474 = llvm.sub %473, %1  : i32 loc(#loc)
    %475 = llvm.extractelement %344[%7 : i32] : vector<2xi32> loc(#loc)
    %476 = llvm.extractelement %344[%1 : i32] : vector<2xi32> loc(#loc)
    %477 = llvm.bitcast %231 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %346, %347, %349, %475, %476, %477 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %478 = llvm.extractelement %353[%7 : i32] : vector<2xi32> loc(#loc)
    %479 = llvm.extractelement %353[%1 : i32] : vector<2xi32> loc(#loc)
    %480 = llvm.bitcast %232 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %355, %356, %358, %478, %479, %480 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %481 = llvm.extractelement %362[%7 : i32] : vector<2xi32> loc(#loc)
    %482 = llvm.extractelement %362[%1 : i32] : vector<2xi32> loc(#loc)
    %483 = llvm.bitcast %233 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %364, %365, %367, %481, %482, %483 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %484 = llvm.extractelement %371[%7 : i32] : vector<2xi32> loc(#loc)
    %485 = llvm.extractelement %371[%1 : i32] : vector<2xi32> loc(#loc)
    %486 = llvm.bitcast %234 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %373, %374, %376, %484, %485, %486 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %487 = llvm.extractelement %380[%7 : i32] : vector<2xi32> loc(#loc)
    %488 = llvm.extractelement %380[%1 : i32] : vector<2xi32> loc(#loc)
    %489 = llvm.bitcast %235 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %382, %383, %385, %487, %488, %489 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %490 = llvm.extractelement %388[%7 : i32] : vector<2xi32> loc(#loc)
    %491 = llvm.extractelement %388[%1 : i32] : vector<2xi32> loc(#loc)
    %492 = llvm.bitcast %236 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %390, %391, %393, %490, %491, %492 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %493 = llvm.extractelement %396[%7 : i32] : vector<2xi32> loc(#loc)
    %494 = llvm.extractelement %396[%1 : i32] : vector<2xi32> loc(#loc)
    %495 = llvm.bitcast %237 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %398, %399, %401, %493, %494, %495 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %496 = llvm.extractelement %404[%7 : i32] : vector<2xi32> loc(#loc)
    %497 = llvm.extractelement %404[%1 : i32] : vector<2xi32> loc(#loc)
    %498 = llvm.bitcast %238 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %406, %407, %409, %496, %497, %498 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %499 = llvm.extractelement %412[%7 : i32] : vector<2xi32> loc(#loc)
    %500 = llvm.extractelement %412[%1 : i32] : vector<2xi32> loc(#loc)
    %501 = llvm.bitcast %239 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %414, %415, %417, %499, %500, %501 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %502 = llvm.extractelement %420[%7 : i32] : vector<2xi32> loc(#loc)
    %503 = llvm.extractelement %420[%1 : i32] : vector<2xi32> loc(#loc)
    %504 = llvm.bitcast %240 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %422, %423, %425, %502, %503, %504 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %505 = llvm.extractelement %428[%7 : i32] : vector<2xi32> loc(#loc)
    %506 = llvm.extractelement %428[%1 : i32] : vector<2xi32> loc(#loc)
    %507 = llvm.bitcast %241 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %430, %431, %433, %505, %506, %507 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %508 = llvm.extractelement %436[%7 : i32] : vector<2xi32> loc(#loc)
    %509 = llvm.extractelement %436[%1 : i32] : vector<2xi32> loc(#loc)
    %510 = llvm.bitcast %242 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %438, %439, %441, %508, %509, %510 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %511 = llvm.extractelement %445[%7 : i32] : vector<2xi32> loc(#loc)
    %512 = llvm.extractelement %445[%1 : i32] : vector<2xi32> loc(#loc)
    %513 = llvm.bitcast %243 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %447, %448, %450, %511, %512, %513 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %514 = llvm.extractelement %453[%7 : i32] : vector<2xi32> loc(#loc)
    %515 = llvm.extractelement %453[%1 : i32] : vector<2xi32> loc(#loc)
    %516 = llvm.bitcast %244 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %455, %456, %458, %514, %515, %516 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %517 = llvm.extractelement %461[%7 : i32] : vector<2xi32> loc(#loc)
    %518 = llvm.extractelement %461[%1 : i32] : vector<2xi32> loc(#loc)
    %519 = llvm.bitcast %245 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %463, %464, %466, %517, %518, %519 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %520 = llvm.extractelement %469[%7 : i32] : vector<2xi32> loc(#loc)
    %521 = llvm.extractelement %469[%1 : i32] : vector<2xi32> loc(#loc)
    %522 = llvm.bitcast %246 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %471, %472, %474, %520, %521, %522 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    llvm.return loc(#loc)
  } loc(#loc)
} loc(#loc)


// -----// IR Dump Before SymbolDCE (symbol-dce) ('builtin.module' operation) //----- //
#loc = loc(unknown)
module attributes {"triton_gpu.compute-capability" = 90 : i32, "triton_gpu.num-ctas" = 1 : i32, "triton_gpu.num-warps" = 32 : i32, triton_gpu.shared = 0 : i32, "triton_gpu.threads-per-warp" = 16 : i32} {
  llvm.func @matmul_kernel_with_block_pointers_0d1d2d3d4d5d(%arg0: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg1: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg2: !llvm.ptr<1> {tt.divisibility = 16 : i32} loc(unknown), %arg3: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg4: i32 {tt.divisibility = 16 : i32} loc(unknown), %arg5: i32 {tt.divisibility = 16 : i32} loc(unknown)) attributes {genx.intel_reqd_sub_group_size = [16 : i32], genx.kernel = 1 : i32, genx.max_work_group_size = [512 : i32, 1 : i32, 1 : i32], noinline = false} {
    %0 = llvm.mlir.constant(2 : i32) : i32 loc(#loc)
    %1 = llvm.mlir.constant(1 : i32) : i32 loc(#loc)
    %2 = llvm.mlir.constant(64 : i32) : i32 loc(#loc)
    %3 = llvm.mlir.constant(16 : i32) : i32 loc(#loc)
    %4 = llvm.mlir.constant(4096 : i32) : i32 loc(#loc)
    %5 = llvm.mlir.constant(dense<0.000000e+00> : vector<8xf32>) : vector<8xf32> loc(#loc)
    %6 = llvm.mlir.constant(32 : i32) : i32 loc(#loc)
    %7 = llvm.mlir.constant(0 : i32) : i32 loc(#loc)
    %8 = llvm.mlir.constant(256 : i32) : i32 loc(#loc)
    %9 = llvm.mlir.constant(4 : i32) : i32 loc(#loc)
    %10 = llvm.mlir.constant(8 : i32) : i32 loc(#loc)
    %11 = llvm.mlir.constant(24 : i32) : i32 loc(#loc)
    %12 = llvm.mlir.constant(48 : i32) : i32 loc(#loc)
    %13 = llvm.mlir.constant(63 : i32) : i32 loc(#loc)
    %14 = llvm.mlir.constant(7 : i32) : i32 loc(#loc)
    %15 = llvm.mlir.constant(3 : i32) : i32 loc(#loc)
    %16 = genx.workitem.id.x : i32 loc(#loc)
    %17 = genx.workitem.id.y : i32 loc(#loc)
    %18 = genx.workitem.id.z : i32 loc(#loc)
    %19 = genx.workgroup.dim.x : i32 loc(#loc)
    %20 = genx.workgroup.dim.y : i32 loc(#loc)
    %21 = llvm.mul %18, %20  : i32 loc(#loc)
    %22 = llvm.add %21, %17  : i32 loc(#loc)
    %23 = llvm.mul %22, %19  : i32 loc(#loc)
    %24 = llvm.add %23, %16  : i32 loc(#loc)
    %25 = llvm.udiv %24, %3  : i32 loc(#loc)
    %26 = genx.workgroup.id.x : i32 loc(#loc)
    %27 = llvm.sdiv %26, %2  : i32 loc(#loc)
    %28 = llvm.mul %27, %9  : i32 loc(#loc)
    %29 = llvm.sub %3, %28  : i32 loc(#loc)
    %30 = llvm.intr.smin(%29, %9)  : (i32, i32) -> i32 loc(#loc)
    %31 = llvm.srem %26, %30  : i32 loc(#loc)
    %32 = llvm.add %28, %31  : i32 loc(#loc)
    %33 = llvm.and %26, %13  : i32 loc(#loc)
    %34 = llvm.sdiv %33, %30  : i32 loc(#loc)
    %35 = llvm.mul %32, %8  : i32 loc(#loc)
    %36 = llvm.mul %25, %10  : i32 loc(#loc)
    %37 = llvm.add %36, %35  : i32 loc(#loc)
    %38 = llvm.mlir.undef : vector<2xi32> loc(#loc)
    %39 = llvm.insertelement %7, %38[%7 : i32] : vector<2xi32> loc(#loc)
    %40 = llvm.insertelement %37, %39[%1 : i32] : vector<2xi32> loc(#loc)
    %41 = llvm.mul %4, %0  : i32 loc(#loc)
    %42 = llvm.sub %41, %1  : i32 loc(#loc)
    %43 = llvm.sub %4, %1  : i32 loc(#loc)
    %44 = llvm.insertelement %3, %38[%7 : i32] : vector<2xi32> loc(#loc)
    %45 = llvm.insertelement %37, %44[%1 : i32] : vector<2xi32> loc(#loc)
    %46 = llvm.extractelement %40[%7 : i32] : vector<2xi32> loc(#loc)
    %47 = llvm.extractelement %40[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %42, %43, %42, %46, %47 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %48 = llvm.extractelement %45[%7 : i32] : vector<2xi32> loc(#loc)
    %49 = llvm.extractelement %45[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %42, %43, %42, %48, %49 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %50 = llvm.add %46, %6  : i32 loc(#loc)
    %51 = llvm.insertelement %50, %40[%7 : i32] : vector<2xi32> loc(#loc)
    %52 = llvm.add %48, %6  : i32 loc(#loc)
    %53 = llvm.insertelement %52, %45[%7 : i32] : vector<2xi32> loc(#loc)
    %54 = llvm.extractelement %51[%7 : i32] : vector<2xi32> loc(#loc)
    %55 = llvm.extractelement %51[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %42, %43, %42, %54, %55 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %56 = llvm.extractelement %53[%7 : i32] : vector<2xi32> loc(#loc)
    %57 = llvm.extractelement %53[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %42, %43, %42, %56, %57 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %58 = llvm.add %54, %6  : i32 loc(#loc)
    %59 = llvm.insertelement %58, %51[%7 : i32] : vector<2xi32> loc(#loc)
    %60 = llvm.add %56, %6  : i32 loc(#loc)
    %61 = llvm.insertelement %60, %53[%7 : i32] : vector<2xi32> loc(#loc)
    %62 = llvm.extractelement %59[%7 : i32] : vector<2xi32> loc(#loc)
    %63 = llvm.extractelement %59[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %42, %43, %42, %62, %63 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %64 = llvm.extractelement %61[%7 : i32] : vector<2xi32> loc(#loc)
    %65 = llvm.extractelement %61[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %42, %43, %42, %64, %65 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %66 = llvm.add %62, %6  : i32 loc(#loc)
    %67 = llvm.insertelement %66, %59[%7 : i32] : vector<2xi32> loc(#loc)
    %68 = llvm.add %64, %6  : i32 loc(#loc)
    %69 = llvm.insertelement %68, %61[%7 : i32] : vector<2xi32> loc(#loc)
    %70 = llvm.sdiv %25, %9  : i32 loc(#loc)
    %71 = llvm.and %70, %14  : i32 loc(#loc)
    %72 = llvm.mul %71, %6  : i32 loc(#loc)
    %73 = llvm.add %72, %35  : i32 loc(#loc)
    %74 = llvm.insertelement %73, %39[%1 : i32] : vector<2xi32> loc(#loc)
    %75 = llvm.mul %34, %8  : i32 loc(#loc)
    %76 = llvm.sdiv %25, %10  : i32 loc(#loc)
    %77 = llvm.and %76, %15  : i32 loc(#loc)
    %78 = llvm.mul %77, %10  : i32 loc(#loc)
    %79 = llvm.and %25, %14  : i32 loc(#loc)
    %80 = llvm.mul %79, %6  : i32 loc(#loc)
    %81 = llvm.add %80, %75  : i32 loc(#loc)
    %82 = llvm.insertelement %81, %38[%7 : i32] : vector<2xi32> loc(#loc)
    %83 = llvm.insertelement %78, %82[%1 : i32] : vector<2xi32> loc(#loc)
    %84 = llvm.add %81, %3  : i32 loc(#loc)
    %85 = llvm.insertelement %84, %38[%7 : i32] : vector<2xi32> loc(#loc)
    %86 = llvm.insertelement %78, %85[%1 : i32] : vector<2xi32> loc(#loc)
    %87 = llvm.extractelement %83[%7 : i32] : vector<2xi32> loc(#loc)
    %88 = llvm.extractelement %83[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %42, %43, %42, %87, %88 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %89 = llvm.extractelement %86[%7 : i32] : vector<2xi32> loc(#loc)
    %90 = llvm.extractelement %86[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %42, %43, %42, %89, %90 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %91 = llvm.add %88, %6  : i32 loc(#loc)
    %92 = llvm.insertelement %91, %83[%1 : i32] : vector<2xi32> loc(#loc)
    %93 = llvm.add %90, %6  : i32 loc(#loc)
    %94 = llvm.insertelement %93, %86[%1 : i32] : vector<2xi32> loc(#loc)
    %95 = llvm.extractelement %92[%7 : i32] : vector<2xi32> loc(#loc)
    %96 = llvm.extractelement %92[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %42, %43, %42, %95, %96 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %97 = llvm.extractelement %94[%7 : i32] : vector<2xi32> loc(#loc)
    %98 = llvm.extractelement %94[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %42, %43, %42, %97, %98 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %99 = llvm.add %96, %6  : i32 loc(#loc)
    %100 = llvm.insertelement %99, %92[%1 : i32] : vector<2xi32> loc(#loc)
    %101 = llvm.add %98, %6  : i32 loc(#loc)
    %102 = llvm.insertelement %101, %94[%1 : i32] : vector<2xi32> loc(#loc)
    %103 = llvm.extractelement %100[%7 : i32] : vector<2xi32> loc(#loc)
    %104 = llvm.extractelement %100[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %42, %43, %42, %103, %104 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %105 = llvm.extractelement %102[%7 : i32] : vector<2xi32> loc(#loc)
    %106 = llvm.extractelement %102[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %42, %43, %42, %105, %106 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %107 = llvm.add %104, %6  : i32 loc(#loc)
    %108 = llvm.insertelement %107, %100[%1 : i32] : vector<2xi32> loc(#loc)
    %109 = llvm.add %106, %6  : i32 loc(#loc)
    %110 = llvm.insertelement %109, %102[%1 : i32] : vector<2xi32> loc(#loc)
    %111 = llvm.and %25, %15  : i32 loc(#loc)
    %112 = llvm.mul %111, %2  : i32 loc(#loc)
    %113 = llvm.add %112, %75  : i32 loc(#loc)
    %114 = llvm.insertelement %113, %38[%7 : i32] : vector<2xi32> loc(#loc)
    %115 = llvm.insertelement %7, %114[%1 : i32] : vector<2xi32> loc(#loc)
    %116 = llvm.add %113, %6  : i32 loc(#loc)
    %117 = llvm.insertelement %116, %38[%7 : i32] : vector<2xi32> loc(#loc)
    %118 = llvm.insertelement %7, %117[%1 : i32] : vector<2xi32> loc(#loc)
    llvm.br ^bb1(%7, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %5, %74, %115, %118, %67, %69, %108, %110 : i32, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>) loc(#loc)
  ^bb1(%119: i32 loc(unknown), %120: vector<8xf32> loc(unknown), %121: vector<8xf32> loc(unknown), %122: vector<8xf32> loc(unknown), %123: vector<8xf32> loc(unknown), %124: vector<8xf32> loc(unknown), %125: vector<8xf32> loc(unknown), %126: vector<8xf32> loc(unknown), %127: vector<8xf32> loc(unknown), %128: vector<8xf32> loc(unknown), %129: vector<8xf32> loc(unknown), %130: vector<8xf32> loc(unknown), %131: vector<8xf32> loc(unknown), %132: vector<8xf32> loc(unknown), %133: vector<8xf32> loc(unknown), %134: vector<8xf32> loc(unknown), %135: vector<8xf32> loc(unknown), %136: vector<2xi32> loc(unknown), %137: vector<2xi32> loc(unknown), %138: vector<2xi32> loc(unknown), %139: vector<2xi32> loc(unknown), %140: vector<2xi32> loc(unknown), %141: vector<2xi32> loc(unknown), %142: vector<2xi32> loc(unknown)):  // 2 preds: ^bb0, ^bb2
    %143 = llvm.icmp "slt" %119, %4 : i32 loc(#loc)
    llvm.cond_br %143, ^bb2, ^bb3 loc(#loc)
  ^bb2:  // pred: ^bb1
    genx.barrier loc(#loc)
    %144 = llvm.extractelement %136[%7 : i32] : vector<2xi32> loc(#loc)
    %145 = llvm.extractelement %136[%1 : i32] : vector<2xi32> loc(#loc)
    %146 = genx.matrix.2Dblockload %arg0, %42, %43, %42, %144, %145 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<64xi16> loc(#loc)
    %147 = llvm.extractelement %137[%7 : i32] : vector<2xi32> loc(#loc)
    %148 = llvm.extractelement %137[%1 : i32] : vector<2xi32> loc(#loc)
    %149 = genx.matrix.2Dblockload %arg1, %42, %43, %42, %147, %148 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = true} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<32xi32> loc(#loc)
    %150 = llvm.extractelement %138[%7 : i32] : vector<2xi32> loc(#loc)
    %151 = llvm.extractelement %138[%1 : i32] : vector<2xi32> loc(#loc)
    %152 = genx.matrix.2Dblockload %arg1, %42, %43, %42, %150, %151 {elem_size_in_bits = 16 : i32, tile_height = 32 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 2 : i32, vnni_transform = true} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) -> vector<32xi32> loc(#loc)
    %153 = llvm.shufflevector %146, %146 [0, 1, 2, 3, 4, 5, 6, 7] : vector<64xi16>  loc(#loc)
    %154 = llvm.shufflevector %149, %149 [0, 1, 2, 3, 4, 5, 6, 7] : vector<32xi32>  loc(#loc)
    %155 = genx.matrix.dpas %120, %153, %154 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %156 = llvm.shufflevector %146, %146 [32, 33, 34, 35, 36, 37, 38, 39] : vector<64xi16>  loc(#loc)
    %157 = llvm.shufflevector %149, %149 [8, 9, 10, 11, 12, 13, 14, 15] : vector<32xi32>  loc(#loc)
    %158 = genx.matrix.dpas %155, %156, %157 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %159 = llvm.shufflevector %146, %146 [8, 9, 10, 11, 12, 13, 14, 15] : vector<64xi16>  loc(#loc)
    %160 = genx.matrix.dpas %121, %159, %154 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %161 = llvm.shufflevector %146, %146 [40, 41, 42, 43, 44, 45, 46, 47] : vector<64xi16>  loc(#loc)
    %162 = genx.matrix.dpas %160, %161, %157 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %163 = llvm.shufflevector %146, %146 [16, 17, 18, 19, 20, 21, 22, 23] : vector<64xi16>  loc(#loc)
    %164 = genx.matrix.dpas %122, %163, %154 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %165 = llvm.shufflevector %146, %146 [48, 49, 50, 51, 52, 53, 54, 55] : vector<64xi16>  loc(#loc)
    %166 = genx.matrix.dpas %164, %165, %157 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %167 = llvm.shufflevector %146, %146 [24, 25, 26, 27, 28, 29, 30, 31] : vector<64xi16>  loc(#loc)
    %168 = genx.matrix.dpas %123, %167, %154 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %169 = llvm.shufflevector %146, %146 [56, 57, 58, 59, 60, 61, 62, 63] : vector<64xi16>  loc(#loc)
    %170 = genx.matrix.dpas %168, %169, %157 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %171 = llvm.shufflevector %149, %149 [16, 17, 18, 19, 20, 21, 22, 23] : vector<32xi32>  loc(#loc)
    %172 = genx.matrix.dpas %124, %153, %171 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %173 = llvm.shufflevector %149, %149 [24, 25, 26, 27, 28, 29, 30, 31] : vector<32xi32>  loc(#loc)
    %174 = genx.matrix.dpas %172, %156, %173 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %175 = genx.matrix.dpas %125, %159, %171 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %176 = genx.matrix.dpas %175, %161, %173 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %177 = genx.matrix.dpas %126, %163, %171 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %178 = genx.matrix.dpas %177, %165, %173 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %179 = genx.matrix.dpas %127, %167, %171 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %180 = genx.matrix.dpas %179, %169, %173 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %181 = llvm.shufflevector %152, %152 [0, 1, 2, 3, 4, 5, 6, 7] : vector<32xi32>  loc(#loc)
    %182 = genx.matrix.dpas %128, %153, %181 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %183 = llvm.shufflevector %152, %152 [8, 9, 10, 11, 12, 13, 14, 15] : vector<32xi32>  loc(#loc)
    %184 = genx.matrix.dpas %182, %156, %183 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %185 = genx.matrix.dpas %129, %159, %181 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %186 = genx.matrix.dpas %185, %161, %183 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %187 = genx.matrix.dpas %130, %163, %181 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %188 = genx.matrix.dpas %187, %165, %183 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %189 = genx.matrix.dpas %131, %167, %181 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %190 = genx.matrix.dpas %189, %169, %183 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %191 = llvm.shufflevector %152, %152 [16, 17, 18, 19, 20, 21, 22, 23] : vector<32xi32>  loc(#loc)
    %192 = genx.matrix.dpas %132, %153, %191 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %193 = llvm.shufflevector %152, %152 [24, 25, 26, 27, 28, 29, 30, 31] : vector<32xi32>  loc(#loc)
    %194 = genx.matrix.dpas %192, %156, %193 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %195 = genx.matrix.dpas %133, %159, %191 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %196 = genx.matrix.dpas %195, %161, %193 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %197 = genx.matrix.dpas %134, %163, %191 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %198 = genx.matrix.dpas %197, %165, %193 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %199 = genx.matrix.dpas %135, %167, %191 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %200 = genx.matrix.dpas %199, %169, %193 {pa = #genx.precision_type<FP16>, pb = #genx.precision_type<FP16>, rc = 8 : i32} : (vector<8xf32>, vector<8xi16>, vector<8xi32>) -> vector<8xf32> loc(#loc)
    %201 = llvm.extractelement %139[%7 : i32] : vector<2xi32> loc(#loc)
    %202 = llvm.extractelement %139[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %42, %43, %42, %201, %202 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %203 = llvm.extractelement %140[%7 : i32] : vector<2xi32> loc(#loc)
    %204 = llvm.extractelement %140[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg0, %42, %43, %42, %203, %204 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %205 = llvm.add %201, %6  : i32 loc(#loc)
    %206 = llvm.insertelement %205, %139[%7 : i32] : vector<2xi32> loc(#loc)
    %207 = llvm.add %203, %6  : i32 loc(#loc)
    %208 = llvm.insertelement %207, %140[%7 : i32] : vector<2xi32> loc(#loc)
    %209 = llvm.add %144, %6  : i32 loc(#loc)
    %210 = llvm.insertelement %209, %136[%7 : i32] : vector<2xi32> loc(#loc)
    %211 = llvm.extractelement %141[%7 : i32] : vector<2xi32> loc(#loc)
    %212 = llvm.extractelement %141[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %42, %43, %42, %211, %212 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %213 = llvm.extractelement %142[%7 : i32] : vector<2xi32> loc(#loc)
    %214 = llvm.extractelement %142[%1 : i32] : vector<2xi32> loc(#loc)
    genx.matrix.2Dblockprefetch %arg1, %42, %43, %42, %213, %214 {elem_size_in_bits = 16 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32) loc(#loc)
    %215 = llvm.add %212, %6  : i32 loc(#loc)
    %216 = llvm.insertelement %215, %141[%1 : i32] : vector<2xi32> loc(#loc)
    %217 = llvm.add %214, %6  : i32 loc(#loc)
    %218 = llvm.insertelement %217, %142[%1 : i32] : vector<2xi32> loc(#loc)
    %219 = llvm.add %148, %6  : i32 loc(#loc)
    %220 = llvm.insertelement %219, %137[%1 : i32] : vector<2xi32> loc(#loc)
    %221 = llvm.add %151, %6  : i32 loc(#loc)
    %222 = llvm.insertelement %221, %138[%1 : i32] : vector<2xi32> loc(#loc)
    %223 = llvm.add %119, %6  : i32 loc(#loc)
    llvm.br ^bb1(%223, %158, %162, %166, %170, %174, %176, %178, %180, %184, %186, %188, %190, %194, %196, %198, %200, %210, %220, %222, %206, %208, %216, %218 : i32, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<8xf32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>, vector<2xi32>) loc(#loc)
  ^bb3:  // pred: ^bb1
    %224 = llvm.insertelement %73, %114[%1 : i32] : vector<2xi32> loc(#loc)
    %225 = llvm.mul %4, %9  : i32 loc(#loc)
    %226 = llvm.sub %225, %1  : i32 loc(#loc)
    %227 = llvm.add %73, %10  : i32 loc(#loc)
    %228 = llvm.insertelement %227, %114[%1 : i32] : vector<2xi32> loc(#loc)
    %229 = llvm.add %73, %3  : i32 loc(#loc)
    %230 = llvm.insertelement %229, %114[%1 : i32] : vector<2xi32> loc(#loc)
    %231 = llvm.add %73, %11  : i32 loc(#loc)
    %232 = llvm.insertelement %231, %114[%1 : i32] : vector<2xi32> loc(#loc)
    %233 = llvm.add %113, %3  : i32 loc(#loc)
    %234 = llvm.insertelement %233, %38[%7 : i32] : vector<2xi32> loc(#loc)
    %235 = llvm.insertelement %73, %234[%1 : i32] : vector<2xi32> loc(#loc)
    %236 = llvm.insertelement %227, %234[%1 : i32] : vector<2xi32> loc(#loc)
    %237 = llvm.insertelement %229, %234[%1 : i32] : vector<2xi32> loc(#loc)
    %238 = llvm.insertelement %231, %234[%1 : i32] : vector<2xi32> loc(#loc)
    %239 = llvm.insertelement %73, %117[%1 : i32] : vector<2xi32> loc(#loc)
    %240 = llvm.insertelement %227, %117[%1 : i32] : vector<2xi32> loc(#loc)
    %241 = llvm.insertelement %229, %117[%1 : i32] : vector<2xi32> loc(#loc)
    %242 = llvm.insertelement %231, %117[%1 : i32] : vector<2xi32> loc(#loc)
    %243 = llvm.add %113, %12  : i32 loc(#loc)
    %244 = llvm.insertelement %243, %38[%7 : i32] : vector<2xi32> loc(#loc)
    %245 = llvm.insertelement %73, %244[%1 : i32] : vector<2xi32> loc(#loc)
    %246 = llvm.insertelement %227, %244[%1 : i32] : vector<2xi32> loc(#loc)
    %247 = llvm.insertelement %229, %244[%1 : i32] : vector<2xi32> loc(#loc)
    %248 = llvm.insertelement %231, %244[%1 : i32] : vector<2xi32> loc(#loc)
    %249 = llvm.extractelement %224[%7 : i32] : vector<2xi32> loc(#loc)
    %250 = llvm.extractelement %224[%1 : i32] : vector<2xi32> loc(#loc)
    %251 = llvm.bitcast %120 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %249, %250, %251 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %252 = llvm.extractelement %228[%7 : i32] : vector<2xi32> loc(#loc)
    %253 = llvm.extractelement %228[%1 : i32] : vector<2xi32> loc(#loc)
    %254 = llvm.bitcast %121 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %252, %253, %254 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %255 = llvm.extractelement %230[%7 : i32] : vector<2xi32> loc(#loc)
    %256 = llvm.extractelement %230[%1 : i32] : vector<2xi32> loc(#loc)
    %257 = llvm.bitcast %122 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %255, %256, %257 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %258 = llvm.extractelement %232[%7 : i32] : vector<2xi32> loc(#loc)
    %259 = llvm.extractelement %232[%1 : i32] : vector<2xi32> loc(#loc)
    %260 = llvm.bitcast %123 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %258, %259, %260 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %261 = llvm.extractelement %235[%7 : i32] : vector<2xi32> loc(#loc)
    %262 = llvm.extractelement %235[%1 : i32] : vector<2xi32> loc(#loc)
    %263 = llvm.bitcast %124 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %261, %262, %263 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %264 = llvm.extractelement %236[%7 : i32] : vector<2xi32> loc(#loc)
    %265 = llvm.extractelement %236[%1 : i32] : vector<2xi32> loc(#loc)
    %266 = llvm.bitcast %125 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %264, %265, %266 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %267 = llvm.extractelement %237[%7 : i32] : vector<2xi32> loc(#loc)
    %268 = llvm.extractelement %237[%1 : i32] : vector<2xi32> loc(#loc)
    %269 = llvm.bitcast %126 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %267, %268, %269 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %270 = llvm.extractelement %238[%7 : i32] : vector<2xi32> loc(#loc)
    %271 = llvm.extractelement %238[%1 : i32] : vector<2xi32> loc(#loc)
    %272 = llvm.bitcast %127 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %270, %271, %272 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %273 = llvm.extractelement %239[%7 : i32] : vector<2xi32> loc(#loc)
    %274 = llvm.extractelement %239[%1 : i32] : vector<2xi32> loc(#loc)
    %275 = llvm.bitcast %128 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %273, %274, %275 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %276 = llvm.extractelement %240[%7 : i32] : vector<2xi32> loc(#loc)
    %277 = llvm.extractelement %240[%1 : i32] : vector<2xi32> loc(#loc)
    %278 = llvm.bitcast %129 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %276, %277, %278 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %279 = llvm.extractelement %241[%7 : i32] : vector<2xi32> loc(#loc)
    %280 = llvm.extractelement %241[%1 : i32] : vector<2xi32> loc(#loc)
    %281 = llvm.bitcast %130 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %279, %280, %281 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %282 = llvm.extractelement %242[%7 : i32] : vector<2xi32> loc(#loc)
    %283 = llvm.extractelement %242[%1 : i32] : vector<2xi32> loc(#loc)
    %284 = llvm.bitcast %131 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %282, %283, %284 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %285 = llvm.extractelement %245[%7 : i32] : vector<2xi32> loc(#loc)
    %286 = llvm.extractelement %245[%1 : i32] : vector<2xi32> loc(#loc)
    %287 = llvm.bitcast %132 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %285, %286, %287 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %288 = llvm.extractelement %246[%7 : i32] : vector<2xi32> loc(#loc)
    %289 = llvm.extractelement %246[%1 : i32] : vector<2xi32> loc(#loc)
    %290 = llvm.bitcast %133 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %288, %289, %290 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %291 = llvm.extractelement %247[%7 : i32] : vector<2xi32> loc(#loc)
    %292 = llvm.extractelement %247[%1 : i32] : vector<2xi32> loc(#loc)
    %293 = llvm.bitcast %134 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %291, %292, %293 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    %294 = llvm.extractelement %248[%7 : i32] : vector<2xi32> loc(#loc)
    %295 = llvm.extractelement %248[%1 : i32] : vector<2xi32> loc(#loc)
    %296 = llvm.bitcast %135 : vector<8xf32> to vector<8xi32> loc(#loc)
    genx.matrix.2Dblockstore %arg2, %226, %43, %226, %294, %295, %296 {elem_size_in_bits = 32 : i32, tile_height = 8 : i32, tile_width = 16 : i32, transpose = false, v_blocks = 1 : i32, vnni_transform = false} : (!llvm.ptr<1>, i32, i32, i32, i32, i32, vector<8xi32>) loc(#loc)
    llvm.return loc(#loc)
  } loc(#loc)
} loc(#loc)


python: /home/jovyan/igc-llvm-update/igc/IGC/GenISAIntrinsics/LlvmTypesMapping.cpp:174: llvm::Type* IGC::PointerType::GetType(llvm::LLVMContext&) const: Assertion `pElementType != nullptr' failed.
